"""
æ¸¬è©¦æ•¸æ“šé‡å°æ¨¡å‹æº–ç¢ºåº¦çš„å½±éŸ¿
Test: æ›´å¤šæ•¸æ“šæ˜¯å¦è®“ XGBoost æ›´æº–ç¢ºï¼Ÿ
"""
import sys
import io

if sys.platform == 'win32':
    try:
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
        sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')
    except:
        pass

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
import xgboost as xgb
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import json
import os
from datetime import datetime
import psycopg2
from psycopg2.extras import RealDictCursor

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
from feature_engineering import create_comprehensive_features

def get_db_connection():
    """é€£æ¥åˆ° Railway Production Database"""
    password = os.environ.get('PGPASSWORD') or os.environ.get('DATABASE_PASSWORD') or 'nIdJPREHqkBdMgUifrazOsVlWbxsmDGq'

    return psycopg2.connect(
        host=os.environ.get('PGHOST', 'tramway.proxy.rlwy.net'),
        port=int(os.environ.get('PGPORT', '45703')),
        user=os.environ.get('PGUSER', 'postgres'),
        password=password,
        database=os.environ.get('PGDATABASE', 'railway'),
        sslmode='require'
    )

def check_data_range():
    """æª¢æŸ¥æ•¸æ“šåº«ä¸­çš„æ•¸æ“šç¯„åœ"""
    print("ğŸ“Š æª¢æŸ¥æ•¸æ“šåº«æ•¸æ“šç¯„åœ...")

    try:
        conn = get_db_connection()
        cur = conn.cursor(cursor_factory=RealDictCursor)

        cur.execute("""
            SELECT
                MIN(date) as first_date,
                MAX(date) as last_date,
                COUNT(*) as total_days,
                MIN(patient_count) as min_count,
                MAX(patient_count) as max_count,
                AVG(patient_count) as avg_count
            FROM actual_data
        """)

        result = cur.fetchone()

        print(f"\n   é¦–æ—¥: {result['first_date']}")
        print(f"   æœ«æ—¥: {result['last_date']}")
        print(f"   ç¸½å¤©æ•¸: {result['total_days']}")
        print(f"   å°±è¨ºç¯„åœ: {result['min_count']} - {result['max_count']}")
        print(f"   å¹³å‡å°±è¨º: {result['avg_count']:.1f}")

        cur.close()
        conn.close()

        return result

    except Exception as e:
        print(f"   âŒ æŸ¥è©¢å¤±æ•—: {e}")
        return None

def load_full_data_from_db():
    """å¾æ•¸æ“šåº«åŠ è¼‰å®Œæ•´æ•¸æ“š"""
    try:
        conn = get_db_connection()
        cur = conn.cursor(cursor_factory=RealDictCursor)

        cur.execute("""
            SELECT date as "Date", patient_count as "Attendance"
            FROM actual_data
            ORDER BY date
        """)

        rows = cur.fetchall()
        df = pd.DataFrame(rows)

        cur.close()
        conn.close()

        return df

    except Exception as e:
        print(f"   âŒ æ•¸æ“šåº«é€£æ¥å¤±æ•—: {e}")
        return None

def calculate_metrics(y_true, y_pred):
    mae = mean_absolute_error(y_true, y_pred)
    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100
    r2 = r2_score(y_true, y_pred)
    return {'mae': mae, 'rmse': rmse, 'mape': mape, 'r2': r2}

def test_with_different_data_sizes(df, feature_cols):
    """æ¸¬è©¦ä¸åŒæ•¸æ“šé‡çš„å½±éŸ¿"""

    results = {}

    # æ¸¬è©¦ä¸åŒæ•¸æ“šé‡
    data_sizes = [
        ('500 å¤©', 500),
        ('1000 å¤©', 1000),
        ('2000 å¤©', 2000),
        ('3000 å¤©', 3000),
        ('å…¨éƒ¨æ•¸æ“š', len(df))
    ]

    for size_name, size in data_sizes:
        if size > len(df):
            continue

        print(f"\n{'=' * 80}")
        print(f"ğŸ“Š æ¸¬è©¦æ•¸æ“šé‡: {size_name} ({size} å¤©)")
        print("=" * 80)

        # ä½¿ç”¨æœ€è¿‘çš„ N å¤©æ•¸æ“š
        df_subset = df.tail(size).copy()

        # 80/20 åˆ†å‰²
        split_idx = int(len(df_subset) * 0.8)
        train_data = df_subset[:split_idx]
        test_data = df_subset[split_idx:]

        X_train = train_data[feature_cols].fillna(0)
        y_train = train_data['Attendance'].values
        X_test = test_data[feature_cols].fillna(0)
        y_test = test_data['Attendance'].values

        print(f"   è¨“ç·´é›†: {len(train_data)} å¤©")
        print(f"   æ¸¬è©¦é›†: {len(test_data)} å¤©")

        # Random Forest
        rf = RandomForestRegressor(
            n_estimators=200,
            max_depth=12,
            min_samples_split=10,
            random_state=42,
            n_jobs=-1
        )
        rf.fit(X_train, y_train)
        rf_pred = rf.predict(X_test)
        rf_metrics = calculate_metrics(y_test, rf_pred)

        # XGBoost
        xgb_model = xgb.XGBRegressor(
            n_estimators=500,
            max_depth=8,
            learning_rate=0.05,
            random_state=42
        )
        xgb_model.fit(X_train, y_train)
        xgb_pred = xgb_model.predict(X_test)
        xgb_metrics = calculate_metrics(y_test, xgb_pred)

        print(f"\n   Random Forest:")
        print(f"      MAE:  {rf_metrics['mae']:.2f}")
        print(f"      MAPE: {rf_metrics['mape']:.2f}%")
        print(f"      RÂ²:   {rf_metrics['r2']:.4f}")

        print(f"\n   XGBoost:")
        print(f"      MAE:  {xgb_metrics['mae']:.2f}")
        print(f"      MAPE: {xgb_metrics['mape']:.2f}%")
        print(f"      RÂ²:   {xgb_metrics['r2']:.4f}")

        winner = "RF" if rf_metrics['mae'] < xgb_metrics['mae'] else "XGB"
        gap = abs(rf_metrics['mae'] - xgb_metrics['mae'])

        print(f"\n   å‹è€…: {winner} (é ˜å…ˆ {gap:.2f})")

        results[size_name] = {
            'size': size,
            'train_days': len(train_data),
            'test_days': len(test_data),
            'rf': rf_metrics,
            'xgb': xgb_metrics,
            'winner': winner,
            'gap': float(gap)
        }

    return results

def main():
    print("=" * 80)
    print("ğŸ”¬ æ•¸æ“šé‡å½±éŸ¿æ¸¬è©¦: æ›´å¤šæ•¸æ“šæ˜¯å¦è®“ XGBoost æ›´æº–ç¢ºï¼Ÿ")
    print("=" * 80)
    print(f"â° é–‹å§‹æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")

    # æª¢æŸ¥æ•¸æ“šç¯„åœ
    data_info = check_data_range()
    if data_info is None:
        return

    # åŠ è¼‰å®Œæ•´æ•¸æ“š
    print("\nğŸ“¥ åŠ è¼‰å®Œæ•´æ•¸æ“š...")
    df = load_full_data_from_db()
    if df is None:
        return

    df['Date'] = pd.to_datetime(df['Date'])
    print(f"   âœ… æˆåŠŸåŠ è¼‰ {len(df)} ç­†æ•¸æ“š")

    # æ’é™¤ COVID
    covid_start = pd.Timestamp('2020-02-01')
    covid_end = pd.Timestamp('2022-06-30')
    covid_mask = (df['Date'] >= covid_start) & (df['Date'] <= covid_end)
    df_no_covid = df[~covid_mask].copy()

    print(f"\nğŸ“Š æ•¸æ“šçµ±è¨ˆ:")
    print(f"   åŸå§‹æ•¸æ“š: {len(df)} å¤©")
    print(f"   COVID æœŸé–“: {covid_mask.sum()} å¤©")
    print(f"   æ’é™¤ COVID å¾Œ: {len(df_no_covid)} å¤©")

    # å‰µå»ºç‰¹å¾µ
    print("\nğŸ”§ å‰µå»ºç‰¹å¾µ...")
    df_no_covid = create_comprehensive_features(df_no_covid)
    df_no_covid = df_no_covid.dropna(subset=['Attendance'])

    feature_cols = [
        "Attendance_Lag1", "Attendance_Lag7", "Attendance_Same_Weekday_Avg",
        "Day_of_Week", "DayOfWeek_Target_Mean", "Attendance_Rolling7",
        "Attendance_EWMA7", "Attendance_Lag14", "Attendance_Lag30",
        "Daily_Change", "Weekly_Change", "Is_Weekend",
        "Holiday_Factor", "Attendance_Std7", "Month"
    ]
    feature_cols = [c for c in feature_cols if c in df_no_covid.columns]

    # æ¸¬è©¦ä¸åŒæ•¸æ“šé‡
    results = test_with_different_data_sizes(df_no_covid, feature_cols)

    # ç¸½çµåˆ†æ
    print("\n" + "=" * 80)
    print("ğŸ“Š æ•¸æ“šé‡å½±éŸ¿ç¸½çµ")
    print("=" * 80)

    print(f"\n{'æ•¸æ“šé‡':<15} {'è¨“ç·´å¤©æ•¸':<12} {'RF MAE':<10} {'XGB MAE':<10} {'å‹è€…':<8} {'å·®è·':<10}")
    print("-" * 80)

    for size_name, result in results.items():
        rf_mae = result['rf']['mae']
        xgb_mae = result['xgb']['mae']
        winner = result['winner']
        gap = result['gap']

        winner_str = f"{winner} âœ…"
        print(f"{size_name:<15} {result['train_days']:<12} {rf_mae:<10.2f} {xgb_mae:<10.2f} {winner_str:<8} {gap:<10.2f}")

    # åˆ†æè¶¨å‹¢
    print("\n" + "=" * 80)
    print("ğŸ“ˆ è¶¨å‹¢åˆ†æ")
    print("=" * 80)

    # è¨ˆç®— XGBoost æ”¹å–„è¶¨å‹¢
    sizes = list(results.keys())
    if len(sizes) >= 2:
        first_xgb = results[sizes[0]]['xgb']['mae']
        last_xgb = results[sizes[-1]]['xgb']['mae']
        xgb_improvement = ((first_xgb - last_xgb) / first_xgb) * 100

        first_rf = results[sizes[0]]['rf']['mae']
        last_rf = results[sizes[-1]]['rf']['mae']
        rf_improvement = ((first_rf - last_rf) / first_rf) * 100

        print(f"\n   XGBoost æ”¹å–„ ({sizes[0]} â†’ {sizes[-1]}):")
        print(f"      MAE: {first_xgb:.2f} â†’ {last_xgb:.2f}")
        print(f"      æ”¹å–„: {xgb_improvement:+.1f}%")

        print(f"\n   Random Forest æ”¹å–„ ({sizes[0]} â†’ {sizes[-1]}):")
        print(f"      MAE: {first_rf:.2f} â†’ {last_rf:.2f}")
        print(f"      æ”¹å–„: {rf_improvement:+.1f}%")

        # åˆ¤æ–·èª°å—ç›Šæ›´å¤š
        if abs(xgb_improvement) > abs(rf_improvement):
            print(f"\n   âœ… XGBoost å¾æ›´å¤šæ•¸æ“šä¸­å—ç›Šæ›´å¤š ({abs(xgb_improvement):.1f}% vs {abs(rf_improvement):.1f}%)")
        else:
            print(f"\n   âœ… Random Forest å¾æ›´å¤šæ•¸æ“šä¸­å—ç›Šæ›´å¤š ({abs(rf_improvement):.1f}% vs {abs(xgb_improvement):.1f}%)")

    # çµè«–
    print("\n" + "=" * 80)
    print("ğŸ¯ çµè«–")
    print("=" * 80)

    last_result = results[sizes[-1]]

    if last_result['winner'] == 'XGB':
        print(f"\n   âœ… åœ¨æœ€å¤§æ•¸æ“šé‡ä¸‹ï¼ŒXGBoost å‹å‡º")
        print(f"   XGB MAE: {last_result['xgb']['mae']:.2f}")
        print(f"   RF MAE:  {last_result['rf']['mae']:.2f}")
        print(f"   é ˜å…ˆ: {last_result['gap']:.2f}")
    else:
        print(f"\n   âœ… å³ä½¿åœ¨æœ€å¤§æ•¸æ“šé‡ä¸‹ï¼ŒRandom Forest ä»ç„¶å‹å‡º")
        print(f"   RF MAE:  {last_result['rf']['mae']:.2f}")
        print(f"   XGB MAE: {last_result['xgb']['mae']:.2f}")
        print(f"   é ˜å…ˆ: {last_result['gap']:.2f}")

    # ä¿å­˜çµæœ
    output = {
        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'total_days': len(df),
        'covid_excluded_days': int(covid_mask.sum()),
        'usable_days': len(df_no_covid),
        'results': {k: {
            'size': v['size'],
            'train_days': v['train_days'],
            'test_days': v['test_days'],
            'rf_mae': float(v['rf']['mae']),
            'xgb_mae': float(v['xgb']['mae']),
            'winner': v['winner'],
            'gap': v['gap']
        } for k, v in results.items()}
    }

    os.makedirs('models', exist_ok=True)
    with open('models/data_size_impact_results.json', 'w') as f:
        json.dump(output, f, indent=2)

    print(f"\nâœ… çµæœå·²ä¿å­˜åˆ° models/data_size_impact_results.json")

if __name__ == '__main__':
    main()
