"""
ç¶œåˆæ¸¬è©¦ï¼šEnsembleã€AI/Weather Factorsã€å®Œæ•´æ•¸æ“šï¼ˆåŒ…æ‹¬ COVIDï¼‰
å¾ Railway Database åŠ è¼‰æ‰€æœ‰æ•¸æ“š
"""
import sys
import io

if sys.platform == 'win32':
    try:
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
        sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')
    except:
        pass

import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import json
import os
from datetime import datetime
import psycopg2
from psycopg2.extras import RealDictCursor

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
from feature_engineering import create_comprehensive_features
from ensemble_predict import load_ai_factors_from_db

def get_db_connection():
    """é€£æ¥åˆ° Railway Production Database"""
    password = os.environ.get('PGPASSWORD') or os.environ.get('DATABASE_PASSWORD') or 'nIdJPREHqkBdMgUifrazOsVlWbxsmDGq'
    return psycopg2.connect(
        host=os.environ.get('PGHOST', 'tramway.proxy.rlwy.net'),
        port=int(os.environ.get('PGPORT', '45703')),
        user=os.environ.get('PGUSER', 'postgres'),
        password=password,
        database=os.environ.get('PGDATABASE', 'railway'),
        sslmode='require'
    )

def load_all_data_from_db():
    """å¾æ•¸æ“šåº«åŠ è¼‰å®Œæ•´æ‰€æœ‰æ•¸æ“šï¼ˆåŒ…æ‹¬ COVIDï¼‰"""
    print("ğŸ“¥ é€£æ¥ Railway Database åŠ è¼‰æ‰€æœ‰æ•¸æ“š...")
    
    try:
        conn = get_db_connection()
        cur = conn.cursor(cursor_factory=RealDictCursor)
        
        # ç²å–æ‰€æœ‰æ•¸æ“š
        cur.execute("""
            SELECT date as "Date", patient_count as "Attendance"
            FROM actual_data
            ORDER BY date
        """)
        
        rows = cur.fetchall()
        df = pd.DataFrame(rows)
        
        cur.close()
        conn.close()
        
        df['Date'] = pd.to_datetime(df['Date'])
        print(f"   âœ… æˆåŠŸåŠ è¼‰ {len(df)} ç­†æ•¸æ“š")
        print(f"   ğŸ“… æ—¥æœŸç¯„åœ: {df['Date'].min()} â†’ {df['Date'].max()}")
        
        return df
        
    except Exception as e:
        print(f"   âŒ æ•¸æ“šåº«é€£æ¥å¤±æ•—: {e}")
        return None

def calculate_metrics(y_true, y_pred):
    return {
        'mae': mean_absolute_error(y_true, y_pred),
        'rmse': np.sqrt(mean_squared_error(y_true, y_pred)),
        'mape': np.mean(np.abs((y_true - y_pred) / y_true)) * 100,
        'r2': r2_score(y_true, y_pred)
    }

def train_ensemble_models(train_data, test_data, feature_cols):
    """è¨“ç·´ Ensemble æ¨¡å‹"""
    X_train = train_data[feature_cols].fillna(0)
    y_train = train_data['Attendance'].values
    X_test = test_data[feature_cols].fillna(0)
    
    models = {}
    predictions = {}
    
    # XGBoost
    print("   ğŸ”¥ è¨“ç·´ XGBoost...")
    xgb_model = xgb.XGBRegressor(n_estimators=500, max_depth=8, learning_rate=0.05, random_state=42)
    xgb_model.fit(X_train, y_train, verbose=False)
    models['xgboost'] = xgb_model
    predictions['xgboost'] = xgb_model.predict(X_test)
    
    # Random Forest
    print("   ğŸŒ² è¨“ç·´ Random Forest...")
    rf = RandomForestRegressor(n_estimators=200, max_depth=12, min_samples_split=10, random_state=42, n_jobs=-1)
    rf.fit(X_train, y_train)
    models['randomforest'] = rf
    predictions['randomforest'] = rf.predict(X_test)
    
    # Gradient Boosting
    print("   ğŸ“ˆ è¨“ç·´ Gradient Boosting...")
    gb = GradientBoostingRegressor(n_estimators=200, max_depth=6, learning_rate=0.05, random_state=42)
    gb.fit(X_train, y_train)
    models['gradientboost'] = gb
    predictions['gradientboost'] = gb.predict(X_test)
    
    # LightGBM (optional)
    try:
        print("   âš¡ è¨“ç·´ LightGBM...")
        from lightgbm import LGBMRegressor
        lgb = LGBMRegressor(n_estimators=300, max_depth=8, learning_rate=0.05, random_state=42, verbose=-1)
        lgb.fit(X_train, y_train)
        models['lightgbm'] = lgb
        predictions['lightgbm'] = lgb.predict(X_test)
    except:
        print("   âš ï¸ LightGBM æœªå®‰è£ï¼Œè·³é")
    
    # Ensemble (ç°¡å–®å¹³å‡)
    print("   ğŸ¯ è¨ˆç®— Ensemble é æ¸¬...")
    ensemble_pred = np.mean([predictions[k] for k in predictions.keys()], axis=0)
    predictions['ensemble'] = ensemble_pred
    
    return models, predictions

def test_scenario(name, train_data, test_data, feature_cols, y_test):
    """æ¸¬è©¦ä¸€å€‹å ´æ™¯"""
    print(f"\n   ğŸ“Š æ¸¬è©¦: {name}")
    models, predictions = train_ensemble_models(train_data, test_data, feature_cols)
    
    results = {}
    for model_name, pred in predictions.items():
        results[model_name] = calculate_metrics(y_test, pred)
    
    return results, predictions

def main():
    print("=" * 80)
    print("ğŸ”¬ ç¶œåˆæ¸¬è©¦ï¼šEnsembleã€AI/Weather Factorsã€å®Œæ•´æ•¸æ“š")
    print("   å¾ Railway Database åŠ è¼‰æ‰€æœ‰æ•¸æ“šï¼ˆåŒ…æ‹¬ COVIDï¼‰")
    print("=" * 80)
    print(f"â° é–‹å§‹æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    
    # å¾æ•¸æ“šåº«åŠ è¼‰æ‰€æœ‰æ•¸æ“š
    df = load_all_data_from_db()
    if df is None:
        print("âŒ ç„¡æ³•åŠ è¼‰æ•¸æ“š")
        return
    
    total_days = len(df)
    
    # COVID æœŸé–“å®šç¾©
    covid_start = pd.Timestamp('2020-02-01')
    covid_end = pd.Timestamp('2022-06-30')
    covid_mask = (df['Date'] >= covid_start) & (df['Date'] <= covid_end)
    covid_days = covid_mask.sum()
    
    print(f"\nğŸ“Š æ•¸æ“šçµ±è¨ˆ:")
    print(f"   ç¸½æ•¸æ“šé‡: {total_days} å¤©")
    print(f"   COVID æœŸé–“: {covid_days} å¤© (2020-02-01 è‡³ 2022-06-30)")
    print(f"   é COVID: {total_days - covid_days} å¤©")
    
    # åŠ è¼‰ AI factors
    print("\nğŸ“¥ åŠ è¼‰ AI Factors...")
    ai_factors = load_ai_factors_from_db()
    print(f"   âœ… AI Factors æ•¸æ“š: {len(ai_factors)} å€‹æ—¥æœŸ")
    
    # åŸºç¤ç‰¹å¾µåˆ—è¡¨
    base_feature_cols = [
        "Attendance_Lag1", "Attendance_Lag7", "Attendance_Same_Weekday_Avg",
        "Day_of_Week", "DayOfWeek_Target_Mean", "Attendance_Rolling7",
        "Attendance_EWMA7", "Attendance_Lag14", "Attendance_Lag30",
        "Daily_Change", "Weekly_Change", "Is_Weekend",
        "Holiday_Factor", "Attendance_Std7", "Month"
    ]
    
    all_results = {}
    
    # ============================================
    # æ¸¬è©¦ 1: å®Œæ•´æ•¸æ“šï¼ˆåŒ…æ‹¬ COVIDï¼‰vs æ’é™¤ COVID
    # ============================================
    print("\n" + "=" * 80)
    print("ğŸ“Š æ¸¬è©¦ 1: å®Œæ•´æ•¸æ“šï¼ˆåŒ…æ‹¬ COVIDï¼‰vs æ’é™¤ COVID")
    print("=" * 80)
    
    # 1.1 å®Œæ•´æ•¸æ“šï¼ˆåŒ…æ‹¬ COVIDï¼‰
    print("\nğŸ”§ è™•ç†å®Œæ•´æ•¸æ“šï¼ˆåŒ…æ‹¬ COVIDï¼‰...")
    df_full = df.copy()
    df_full = create_comprehensive_features(df_full, ai_factors_dict=None)
    df_full = df_full.dropna(subset=['Attendance'])
    
    split_idx_full = int(len(df_full) * 0.8)
    train_full = df_full[:split_idx_full].copy()
    test_full = df_full[split_idx_full:].copy()
    
    feature_cols_full = [c for c in base_feature_cols if c in train_full.columns]
    X_test_full = test_full[feature_cols_full].fillna(0)
    y_test_full = test_full['Attendance'].values
    
    print(f"   è¨“ç·´é›†: {len(train_full)} å¤©")
    print(f"   æ¸¬è©¦é›†: {len(test_full)} å¤©")
    
    results_full, _ = test_scenario("å®Œæ•´æ•¸æ“šï¼ˆåŒ…æ‹¬ COVIDï¼‰", train_full, test_full, feature_cols_full, y_test_full)
    all_results['full_data'] = results_full
    
    # 1.2 æ’é™¤ COVID
    print("\nğŸ”§ è™•ç†æ’é™¤ COVID æ•¸æ“š...")
    df_no_covid = df[~covid_mask].copy()
    df_no_covid = create_comprehensive_features(df_no_covid, ai_factors_dict=None)
    df_no_covid = df_no_covid.dropna(subset=['Attendance'])
    
    split_idx_no_covid = int(len(df_no_covid) * 0.8)
    train_no_covid = df_no_covid[:split_idx_no_covid].copy()
    test_no_covid = df_no_covid[split_idx_no_covid:].copy()
    
    feature_cols_no_covid = [c for c in base_feature_cols if c in train_no_covid.columns]
    X_test_no_covid = test_no_covid[feature_cols_no_covid].fillna(0)
    y_test_no_covid = test_no_covid['Attendance'].values
    
    print(f"   è¨“ç·´é›†: {len(train_no_covid)} å¤©")
    print(f"   æ¸¬è©¦é›†: {len(test_no_covid)} å¤©")
    
    results_no_covid, _ = test_scenario("æ’é™¤ COVID", train_no_covid, test_no_covid, feature_cols_no_covid, y_test_no_covid)
    all_results['no_covid'] = results_no_covid
    
    # ============================================
    # æ¸¬è©¦ 2: AI Factors å½±éŸ¿
    # ============================================
    print("\n" + "=" * 80)
    print("ğŸ“Š æ¸¬è©¦ 2: AI Factors å½±éŸ¿")
    print("=" * 80)
    
    # 2.1 ç„¡ AI factors
    print("\nğŸ”§ è™•ç†ç„¡ AI factors æ•¸æ“š...")
    train_no_ai = create_comprehensive_features(train_no_covid.copy(), ai_factors_dict=None)
    test_no_ai = create_comprehensive_features(test_no_covid.copy(), ai_factors_dict=None)
    
    feature_cols_no_ai = [c for c in base_feature_cols if c in train_no_ai.columns]
    y_test_no_ai = test_no_ai['Attendance'].values
    
    results_no_ai, _ = test_scenario("ç„¡ AI Factors", train_no_ai, test_no_ai, feature_cols_no_ai, y_test_no_ai)
    all_results['no_ai'] = results_no_ai
    
    # 2.2 æœ‰ AI factors
    print("\nğŸ”§ è™•ç†æœ‰ AI factors æ•¸æ“š...")
    train_with_ai = create_comprehensive_features(train_no_covid.copy(), ai_factors_dict=ai_factors if ai_factors else None)
    test_with_ai = create_comprehensive_features(test_no_covid.copy(), ai_factors_dict=ai_factors if ai_factors else None)
    
    # æ·»åŠ  AI ç‰¹å¾µ
    ai_feature_cols = [c for c in train_with_ai.columns if c.startswith('AI_')]
    feature_cols_with_ai = [c for c in base_feature_cols if c in train_with_ai.columns] + ai_feature_cols
    feature_cols_with_ai = [c for c in feature_cols_with_ai if c in train_with_ai.columns]
    
    y_test_with_ai = test_with_ai['Attendance'].values
    
    print(f"   åŸºç¤ç‰¹å¾µ: {len([c for c in base_feature_cols if c in train_with_ai.columns])} å€‹")
    print(f"   AI ç‰¹å¾µ: {len(ai_feature_cols)} å€‹")
    print(f"   ç¸½ç‰¹å¾µ: {len(feature_cols_with_ai)} å€‹")
    
    results_with_ai, _ = test_scenario("æœ‰ AI Factors", train_with_ai, test_with_ai, feature_cols_with_ai, y_test_with_ai)
    all_results['with_ai'] = results_with_ai
    
    # ============================================
    # æ¸¬è©¦ 3: Ensemble vs å–®ä¸€ XGBoost
    # ============================================
    print("\n" + "=" * 80)
    print("ğŸ“Š æ¸¬è©¦ 3: Ensemble vs å–®ä¸€ XGBoost")
    print("=" * 80)
    
    # ä½¿ç”¨æ’é™¤ COVID + ç„¡ AI factors çš„æ•¸æ“šé€²è¡Œæ¯”è¼ƒ
    print("\n   ä½¿ç”¨æ’é™¤ COVID + ç„¡ AI factors çš„æ•¸æ“šé€²è¡Œæ¯”è¼ƒ")
    
    baseline_mae = results_no_ai['xgboost']['mae']
    ensemble_mae = results_no_ai['ensemble']['mae']
    improvement = ((baseline_mae - ensemble_mae) / baseline_mae) * 100
    
    print(f"\n   XGBoost (å–®ä¸€): MAE = {baseline_mae:.2f}")
    print(f"   Ensemble:       MAE = {ensemble_mae:.2f}")
    print(f"   æ”¹å–„: {improvement:+.2f}%")
    
    if improvement > 0:
        print(f"   âœ… Ensemble æ›´å¥½ï¼")
    else:
        print(f"   âŒ XGBoost æ›´å¥½ï¼")
    
    # ============================================
    # ç¸½çµå ±å‘Š
    # ============================================
    print("\n" + "=" * 80)
    print("ğŸ† ç¸½çµå ±å‘Š")
    print("=" * 80)
    
    print("\nğŸ“Š æ¸¬è©¦ 1: å®Œæ•´æ•¸æ“š vs æ’é™¤ COVID")
    print(f"   å®Œæ•´æ•¸æ“š XGBoost MAE: {results_full['xgboost']['mae']:.2f}")
    print(f"   æ’é™¤ COVID XGBoost MAE: {results_no_covid['xgboost']['mae']:.2f}")
    improvement_covid = ((results_full['xgboost']['mae'] - results_no_covid['xgboost']['mae']) / results_full['xgboost']['mae']) * 100
    print(f"   æ’é™¤ COVID æ”¹å–„: {improvement_covid:+.2f}%")
    
    print("\nğŸ“Š æ¸¬è©¦ 2: AI Factors å½±éŸ¿")
    print(f"   ç„¡ AI Factors XGBoost MAE: {results_no_ai['xgboost']['mae']:.2f}")
    print(f"   æœ‰ AI Factors XGBoost MAE: {results_with_ai['xgboost']['mae']:.2f}")
    improvement_ai = ((results_no_ai['xgboost']['mae'] - results_with_ai['xgboost']['mae']) / results_no_ai['xgboost']['mae']) * 100
    print(f"   AI Factors æ”¹å–„: {improvement_ai:+.2f}%")
    
    print("\nğŸ“Š æ¸¬è©¦ 3: Ensemble vs å–®ä¸€ XGBoost")
    print(f"   XGBoost (å–®ä¸€) MAE: {baseline_mae:.2f}")
    print(f"   Ensemble MAE: {ensemble_mae:.2f}")
    print(f"   Ensemble æ”¹å–„: {improvement:+.2f}%")
    
    # ä¿å­˜çµæœ
    output = {
        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'total_days': total_days,
        'covid_days': int(covid_days),
        'ai_factors_count': len(ai_factors),
        'results': {
            'full_data': {k: {m: float(v) for m, v in metrics.items()} for k, metrics in results_full.items()},
            'no_covid': {k: {m: float(v) for m, v in metrics.items()} for k, metrics in results_no_covid.items()},
            'no_ai': {k: {m: float(v) for m, v in metrics.items()} for k, metrics in results_no_ai.items()},
            'with_ai': {k: {m: float(v) for m, v in metrics.items()} for k, metrics in results_with_ai.items()}
        },
        'summary': {
            'covid_exclusion_improvement_pct': float(improvement_covid),
            'ai_factors_improvement_pct': float(improvement_ai),
            'ensemble_improvement_pct': float(improvement)
        }
    }
    
    os.makedirs('models', exist_ok=True)
    with open('models/comprehensive_test_results.json', 'w', encoding='utf-8') as f:
        json.dump(output, f, indent=2, ensure_ascii=False)
    
    print(f"\nâœ… çµæœå·²ä¿å­˜åˆ° models/comprehensive_test_results.json")
    print(f"\nâ° çµæŸæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

if __name__ == '__main__':
    main()