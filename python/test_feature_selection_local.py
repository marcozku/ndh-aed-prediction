# -*- coding: utf-8 -*-
"""
ç‰¹å¾µé¸æ“‡æ¸¬è©¦ - ä½¿ç”¨æœ¬åœ° CSV æ•¸æ“š
"""
import sys
import io

if sys.platform == 'win32':
    try:
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
        sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')
    except:
        pass

import pandas as pd
import numpy as np
from datetime import datetime
import json
import os
import warnings
warnings.filterwarnings('ignore')

# æ©Ÿå™¨å­¸ç¿’
from sklearn.ensemble import RandomForestRegressor
import xgboost as xgb
from sklearn.metrics import mean_absolute_error

# COVID æœŸé–“
COVID_PERIODS = [
    ('2020-01-23', '2020-04-08'),
    ('2020-07-16', '2020-09-30'),
    ('2020-11-23', '2021-01-05'),
    ('2022-02-05', '2022-04-30'),
    ('2022-11-10', '2022-12-27'),
]


def load_local_data():
    """å¾æœ¬åœ° CSV åŠ è¼‰æ•¸æ“š"""
    # å˜—è©¦å¤šå€‹å¯èƒ½çš„æ–‡ä»¶è·¯å¾‘
    possible_files = [
        '../ndh_attendance_extracted.csv',
        '../../ndh_attendance_extracted.csv',
        'ndh_attendance_extracted.csv'
    ]

    for file_path in possible_files:
        if os.path.exists(file_path):
            print(f"ğŸ“‚ ä½¿ç”¨æœ¬åœ°æ–‡ä»¶: {file_path}")
            df = pd.read_csv(file_path)
            df['date'] = pd.to_datetime(df['date'])
            return df

    # å¦‚æœéƒ½æ‰¾ä¸åˆ°ï¼Œå˜—è©¦çµ•å°è·¯å¾‘
    abs_path = 'C:/Github/ndh-aed-prediction/ndh_attendance_extracted.csv'
    if os.path.exists(abs_path):
        print(f"ğŸ“‚ ä½¿ç”¨æœ¬åœ°æ–‡ä»¶: {abs_path}")
        df = pd.read_csv(abs_path)
        df['date'] = pd.to_datetime(df['date'])
        return df

    print("âŒ æ‰¾ä¸åˆ°æœ¬åœ°æ•¸æ“šæ–‡ä»¶")
    print("è«‹ç¢ºä¿ä»¥ä¸‹æ–‡ä»¶å­˜åœ¨:")
    for f in possible_files + [abs_path]:
        print(f"   - {f}")
    return None


def exclude_covid_periods(df):
    """æ’é™¤ COVID æœŸé–“"""
    for start, end in COVID_PERIODS:
        start_date = pd.to_datetime(start)
        end_date = pd.to_datetime(end)
        mask = (df['date'] >= start_date) & (df['date'] <= end_date)
        before = len(df)
        df = df[~mask]
        if before > len(df):
            print(f"   æ’é™¤ {start} åˆ° {end}: ç§»é™¤ {before - len(df)} ç­†")

    return df


def prepare_features(df):
    """æº–å‚™ç‰¹å¾µ"""
    print("\nğŸ“Š æº–å‚™ç‰¹å¾µ...")

    df = df.rename(columns={'date': 'Date'})

    # ç¢ºä¿åˆ—åæ­£ç¢º
    if 'attendance' in df.columns:
        df = df.rename(columns={'attendance': 'patient_count'})
    elif 'Attendance' in df.columns:
        df = df.rename(columns={'Attendance': 'patient_count'})

    # æ™‚é–“ç‰¹å¾µ
    df['Day_of_Week'] = df['Date'].dt.dayofweek
    df['Month'] = df['Date'].dt.month
    df['Day_of_Month'] = df['Date'].dt.day
    df['Is_Weekend'] = (df['Day_of_Week'] >= 5).astype(int)

    # é€±æœŸç·¨ç¢¼
    df['DayOfWeek_sin'] = np.sin(2 * np.pi * df['Day_of_Week'] / 7)
    df['DayOfWeek_cos'] = np.cos(2 * np.pi * df['Day_of_Week'] / 7)

    # å­£ç¯€æ€§
    df['Is_Winter_Flu_Season'] = df['Month'].isin([1, 2]).astype(int)
    df['Holiday_Factor'] = 1.0

    # æ­·å²å°±è¨º
    df = df.sort_values('Date').reset_index(drop=True)

    df['Attendance_Lag1'] = df['patient_count'].shift(1)
    df['Attendance_Lag7'] = df['patient_count'].shift(7)
    df['Attendance_Lag30'] = df['patient_count'].shift(30)

    df['Attendance_EWMA7'] = df['patient_count'].ewm(span=7, adjust=False).mean()
    df['Attendance_EWMA14'] = df['patient_count'].ewm(span=14, adjust=False).mean()

    df['Daily_Change'] = df['patient_count'].diff()
    df['Weekly_Change'] = df['patient_count'].diff(7)

    # å¡«è£œ
    df['Attendance_Lag1'] = df['Attendance_Lag1'].fillna(df['patient_count'].mean())
    df['Attendance_Lag7'] = df['Attendance_Lag7'].fillna(df['patient_count'].mean())
    df['Attendance_Lag30'] = df['Attendance_Lag30'].fillna(df['patient_count'].mean())
    df['Attendance_EWMA7'] = df['Attendance_EWMA7'].fillna(method='bfill')
    df['Attendance_EWMA14'] = df['Attendance_EWMA14'].fillna(method='bfill')
    df['Daily_Change'] = df['Daily_Change'].fillna(0)
    df['Weekly_Change'] = df['Weekly_Change'].fillna(0)

    # ç§»é™¤ NaN
    df = df.dropna()

    print(f"   âœ… ç‰¹å¾µæº–å‚™å®Œæˆ: {len(df)} ç­†")
    return df


def test_feature_counts(X_train, y_train, X_test, y_test, feature_names):
    """æ¸¬è©¦ä¸åŒç‰¹å¾µæ•¸é‡"""
    print("\n" + "=" * 80)
    print("ğŸ” ç‰¹å¾µé¸æ“‡æ¸¬è©¦")
    print("=" * 80)

    # è¨“ç·´æ¨¡å‹ç²å–é‡è¦æ€§
    print("\n1ï¸âƒ£ è¨“ç·´ XGBoost ç²å–ç‰¹å¾µé‡è¦æ€§...")
    model = xgb.XGBRegressor(
        n_estimators=300,
        max_depth=6,
        learning_rate=0.05,
        random_state=42,
        n_jobs=-1
    )
    model.fit(X_train, y_train, verbose=False)

    # ç‰¹å¾µé‡è¦æ€§
    importances = model.feature_importances_
    indices = np.argsort(importances)[::-1]

    print("\n   Top 15 ç‰¹å¾µ:")
    print(f"   {'æ’å':<4} {'ç‰¹å¾µ':<35} {'é‡è¦æ€§':<10}")
    print("   " + "-" * 60)

    for i, idx in enumerate(indices[:15], 1):
        feature = feature_names[idx]
        importance = importances[idx]
        print(f"   {i:<4} {feature:<35} {importance:.4f}")

    # æ¸¬è©¦ä¸åŒç‰¹å¾µæ•¸é‡
    print("\n2ï¸âƒ£ æ¸¬è©¦ä¸åŒç‰¹å¾µæ•¸é‡...")
    print(f"   {'ç‰¹å¾µæ•¸':<10} {'MAE':<10} {'æ”¹å–„ %':<10} {'ç‹€æ…‹':<5}")
    print("   " + "-" * 45)

    baseline_mae = 15.73
    results = []

    # æ¸¬è©¦ä¸åŒæ•¸é‡
    for n_features in range(5, len(feature_names) + 1, 5):
        # é¸æ“‡ top n_features
        selected_indices = indices[:n_features]
        X_train_selected = X_train.iloc[:, selected_indices]
        X_test_selected = X_test.iloc[:, selected_indices]

        # è¨“ç·´
        model_selected = xgb.XGBRegressor(
            n_estimators=300,
            max_depth=6,
            learning_rate=0.05,
            random_state=42,
            n_jobs=-1
        )
        model_selected.fit(X_train_selected, y_train, verbose=False)

        # è©•ä¼°
        y_pred = model_selected.predict(X_test_selected)
        mae = mean_absolute_error(y_test, y_pred)
        improvement = ((baseline_mae - mae) / baseline_mae * 100)

        results.append({
            'n_features': n_features,
            'mae': mae,
            'improvement': improvement
        })

        status = "âœ…" if mae < baseline_mae else "âŒ"
        print(f"   {n_features:<10} {mae:<10.2f} {improvement:>+6.1f}%   {status}")

    # æ‰¾å‡ºæœ€ä½³
    best = min(results, key=lambda x: x['mae'])

    print("\n" + "=" * 80)
    print("ğŸ† æ¸¬è©¦çµæœ")
    print("=" * 80)
    print(f"\nåŸºæº– (èˆŠæ¨¡å‹): MAE = {baseline_mae}")
    print(f"æœ€ä½³ç‰¹å¾µæ•¸é‡: {best['n_features']} å€‹")
    print(f"æœ€ä½³ MAE: {best['mae']:.2f}")
    print(f"æ”¹å–„: {best['improvement']:+.1f}%")

    # åˆ†æ
    if best['n_features'] < len(feature_names) * 0.7:
        print(f"\nâœ… é‡è¦ç™¼ç¾:")
        print(f"   ç‰¹å¾µæ•¸é‡å¯ä»¥å¾ {len(feature_names)} æ¸›å°‘åˆ° {best['n_features']}")
        print(f"   æ¸›å°‘ {len(feature_names) - best['n_features']} å€‹ç‰¹å¾µ")
        print(f"   åŒæ™‚æ”¹å–„æº–ç¢ºåº¦ï¼")
    else:
        print(f"\nâš ï¸ çµè«–:")
        print(f"   å¤§éƒ¨åˆ†ç‰¹å¾µéƒ½æœ‰ç”¨")
        print(f"   å»ºè­°ä¿ç•™ {best['n_features']} å€‹ç‰¹å¾µ")

    return results, best, indices, importances


def main():
    """ä¸»æ¸¬è©¦æµç¨‹"""
    print("=" * 80)
    print("ğŸ¯ ç‰¹å¾µé¸æ“‡æ¸¬è©¦ (æœ¬åœ°æ•¸æ“š)")
    print("=" * 80)
    print(f"æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")

    # 1. åŠ è¼‰æ•¸æ“š
    df = load_local_data()
    if df is None:
        return

    print(f"   âœ… åŠ è¼‰ {len(df)} ç­†è¨˜éŒ„")
    print(f"   ğŸ“… ç¯„åœ: {df['date'].min()} â†’ {df['date'].max()}")

    # 2. æ’é™¤ COVID
    print("\nğŸ¦  æ’é™¤ COVID æœŸé–“...")
    df = exclude_covid_periods(df)
    print(f"   ğŸ“Š éæ¿¾å¾Œ: {len(df)} ç­†è¨˜éŒ„")

    # 3. æº–å‚™ç‰¹å¾µ
    df = prepare_features(df)

    # 4. ç‰¹å¾µåˆ—è¡¨
    feature_names = [
        'Day_of_Week', 'Month', 'Day_of_Month', 'Is_Weekend',
        'Holiday_Factor', 'Is_Winter_Flu_Season',
        'DayOfWeek_sin', 'DayOfWeek_cos',
        'Attendance_Lag1', 'Attendance_Lag7', 'Attendance_Lag30',
        'Attendance_EWMA7', 'Attendance_EWMA14',
        'Daily_Change', 'Weekly_Change'
    ]

    feature_names = [f for f in feature_names if f in df.columns]
    print(f"\nğŸ“‹ ç‰¹å¾µæ•¸é‡: {len(feature_names)}")

    # 5. åˆ†å‰²æ•¸æ“š
    print("\nâœ‚ï¸ åˆ†å‰²æ•¸æ“š...")
    train_size = int(len(df) * 0.8)

    train_df = df.iloc[:train_size]
    test_df = df.iloc[train_size:]

    X_train = train_df[feature_names]
    y_train = train_df['patient_count']
    X_test = test_df[feature_names]
    y_test = test_df['patient_count']

    print(f"   è¨“ç·´é›†: {len(X_train)} ç­†")
    print(f"   æ¸¬è©¦é›†: {len(X_test)} ç­†")
    print(f"   æ¸¬è©¦ç¯„åœ: {test_df['Date'].min()} â†’ {test_df['Date'].max()}")

    # 6. æ¸¬è©¦
    results, best, indices, importances = test_feature_counts(
        X_train, y_train, X_test, y_test, feature_names
    )

    # 7. ä¿å­˜çµæœ
    output = {
        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'baseline_mae': 15.73,
        'total_features': len(feature_names),
        'best_n_features': best['n_features'],
        'best_mae': best['mae'],
        'improvement_pct': best['improvement'],
        'feature_importance': {
            feature_names[i]: float(importances[i]) for i in range(len(feature_names))
        },
        'test_results': results
    }

    os.makedirs('models', exist_ok=True)
    with open('models/feature_selection_local_results.json', 'w', encoding='utf-8') as f:
        json.dump(output, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ’¾ çµæœå·²ä¿å­˜åˆ° models/feature_selection_local_results.json")

    # æ¨è–¦
    print("\n" + "=" * 80)
    print("ğŸ’¡ æ¨è–¦ä½¿ç”¨çš„ç‰¹å¾µ")
    print("=" * 80)
    print(f"\nä½¿ç”¨é€™ {best['n_features']} å€‹æœ€é‡è¦ç‰¹å¾µä¾†è¨“ç·´æœ€çµ‚æ¨¡å‹:")
    for i in range(best['n_features']):
        idx = indices[i]
        print(f"   {i+1}. {feature_names[idx]}")

    print("\n" + "=" * 80)
    print("âœ… æ¸¬è©¦å®Œæˆ")
    print("=" * 80)


if __name__ == '__main__':
    main()
