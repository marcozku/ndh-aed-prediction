"""
P0 å„ªå…ˆä»»å‹™æ¸¬è©¦è…³æœ¬
æ¸¬è©¦é æœŸæ”¹å–„æœ€å¤§çš„å„ªåŒ–é …ç›®

ç›®æ¨™: MAE 15.77 â†’ 12.5 (ç´„ 20% æ”¹å–„)

P0 é …ç›®:
1. é«˜ç´šæ»¾å‹•çµ±è¨ˆç‰¹å¾µ (+1.5 MAE æ”¹å–„é æœŸ)
2. Stacking Ensemble (+1.0 MAE æ”¹å–„é æœŸ)
3. åˆ†å±¤å»ºæ¨¡ (å·¥ä½œæ—¥/é€±æœ«) (+0.8 MAE æ”¹å–„é æœŸ)
"""
import sys
import io

if sys.platform == 'win32':
    try:
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
        sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')
    except:
        pass

import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import json
import os
from datetime import datetime
import psycopg2
from psycopg2.extras import RealDictCursor

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
from feature_engineering import create_comprehensive_features, load_weather_history, add_weather_features
from feature_engineering_v2 import create_enhanced_features, get_enhanced_feature_columns
from stacking_ensemble import compare_all_ensembles, StackingEnsemble


def get_db_connection():
    """é€£æ¥åˆ° Railway Database"""
    password = os.environ.get('PGPASSWORD') or os.environ.get('DATABASE_PASSWORD') or 'nIdJPREHqkBdMgUifrazOsVlWbxsmDGq'
    return psycopg2.connect(
        host=os.environ.get('PGHOST', 'tramway.proxy.rlwy.net'),
        port=int(os.environ.get('PGPORT', '45703')),
        user=os.environ.get('PGUSER', 'postgres'),
        password=password,
        database=os.environ.get('PGDATABASE', 'railway'),
        sslmode='require'
    )


def load_all_data():
    """å¾æ•¸æ“šåº«åŠ è¼‰æ‰€æœ‰æ­·å²æ•¸æ“š"""
    print("=" * 80)
    print("ğŸ“¥ åŠ è¼‰æ­·å²æ•¸æ“š")
    print("=" * 80)

    try:
        conn = get_db_connection()
        cur = conn.cursor(cursor_factory=RealDictCursor)

        cur.execute("""
            SELECT date as "Date", patient_count as "Attendance"
            FROM actual_data
            ORDER BY date ASC
        """)

        rows = cur.fetchall()
        df = pd.DataFrame(rows)

        cur.close()
        conn.close()

        df['Date'] = pd.to_datetime(df['Date'])
        print(f"   âœ… æˆåŠŸåŠ è¼‰ {len(df)} ç­†æ•¸æ“š")
        print(f"   ğŸ“… æ—¥æœŸç¯„åœ: {df['Date'].min()} â†’ {df['Date'].max()}")

        return df

    except Exception as e:
        print(f"   âŒ æ•¸æ“šåº«é€£æ¥å¤±æ•—: {e}")
        return None


def calculate_metrics(y_true, y_pred):
    """è¨ˆç®—è©•ä¼°æŒ‡æ¨™"""
    return {
        'mae': mean_absolute_error(y_true, y_pred),
        'rmse': np.sqrt(mean_squared_error(y_true, y_pred)),
        'r2': r2_score(y_true, y_pred)
    }


def prepare_test_data(df):
    """æº–å‚™æ¸¬è©¦æ•¸æ“šï¼ˆæ’é™¤ COVIDï¼‰"""
    # æ’é™¤ COVID æœŸé–“
    covid_start = pd.Timestamp('2020-02-01')
    covid_end = pd.Timestamp('2022-06-30')
    df = df[~((df['Date'] >= covid_start) & (df['Date'] <= covid_end))].copy()

    # æ·»åŠ å¤©æ°£æ•¸æ“š
    weather_df = load_weather_history()
    if weather_df is not None:
        df = add_weather_features(df, weather_df)

    # ç¢ºä¿ Date æ˜¯ datetime
    df['Date'] = pd.to_datetime(df['Date'])

    # å‰µå»ºç‰¹å¾µ
    df = create_comprehensive_features(df, ai_factors_dict=None)
    df = df.dropna(subset=['Attendance'])

    # åˆ†å‰²æ•¸æ“š
    split_idx = int(len(df) * 0.8)
    train = df[:split_idx].copy()
    test = df[split_idx:].copy()

    return train, test


def test_enhanced_features():
    """
    æ¸¬è©¦ 1: å¢å¼·ç‰¹å¾µå·¥ç¨‹
    é æœŸ: MAE 15.77 â†’ 14.5
    """
    print("\n" + "=" * 80)
    print("ğŸ§ª æ¸¬è©¦ 1: å¢å¼·ç‰¹å¾µå·¥ç¨‹")
    print("=" * 80)

    df = load_all_data()
    if df is None:
        return None

    # æ’é™¤ COVID
    covid_start = pd.Timestamp('2020-02-01')
    covid_end = pd.Timestamp('2022-06-30')
    df = df[~((df['Date'] >= covid_start) & (df['Date'] <= covid_end))].copy()

    # æ·»åŠ å¤©æ°£
    weather_df = load_weather_history()
    if weather_df is not None:
        df = add_weather_features(df, weather_df)
    df['Date'] = pd.to_datetime(df['Date'])

    # ä½¿ç”¨å¢å¼·ç‰¹å¾µ
    df = create_enhanced_features(df, include_aqhi=True)
    df = df.dropna(subset=['Attendance'])

    # ç²å–å¢å¼·ç‰¹å¾µ
    enhanced_features = get_enhanced_feature_columns()
    enhanced_features = [c for c in enhanced_features if c in df.columns]

    print(f"\n   ä½¿ç”¨ {len(enhanced_features)} å€‹å¢å¼·ç‰¹å¾µ")

    # åˆ†å‰²
    split_idx = int(len(df) * 0.8)
    train = df[:split_idx].copy()
    test = df[split_idx:].copy()

    X_train = train[enhanced_features].fillna(0)
    y_train = train['Attendance'].values
    X_test = test[enhanced_features].fillna(0)
    y_test = test['Attendance'].values

    # è¨“ç·´ XGBoost
    print("\n   è¨“ç·´ XGBoost (å¢å¼·ç‰¹å¾µ)...")
    model = xgb.XGBRegressor(
        n_estimators=500,
        max_depth=8,
        learning_rate=0.05,
        subsample=0.85,
        colsample_bytree=0.85,
        objective='reg:squarederror',
        tree_method='hist',
        random_state=42,
        n_jobs=-1
    )
    model.fit(X_train.values, y_train, verbose=False)

    # é æ¸¬
    y_pred = model.predict(X_test.values)
    metrics = calculate_metrics(y_test, y_pred)

    print(f"\n   ğŸ“Š çµæœ:")
    print(f"      MAE:  {metrics['mae']:.2f}")
    print(f"      RMSE: {metrics['rmse']:.2f}")
    print(f"      RÂ²:   {metrics['r2']:.4f}")

    return {
        'name': 'Enhanced Features',
        'mae': metrics['mae'],
        'rmse': metrics['rmse'],
        'r2': metrics['r2'],
        'feature_count': len(enhanced_features)
    }


def test_stacking_ensemble():
    """
    æ¸¬è©¦ 2: Stacking Ensemble
    é æœŸ: MAE 15.77 â†’ 14.8
    """
    print("\n" + "=" * 80)
    print("ğŸ§ª æ¸¬è©¦ 2: Stacking Ensemble")
    print("=" * 80)

    df = load_all_data()
    if df is None:
        return None

    # æ’é™¤ COVID + å¤©æ°£
    covid_start = pd.Timestamp('2020-02-01')
    covid_end = pd.Timestamp('2022-06-30')
    df = df[~((df['Date'] >= covid_start) & (df['Date'] <= covid_end))].copy()

    weather_df = load_weather_history()
    if weather_df is not None:
        df = add_weather_features(df, weather_df)
    df['Date'] = pd.to_datetime(df['Date'])

    # ä½¿ç”¨åŸºç¤ç‰¹å¾µï¼ˆé¿å…éæ“¬åˆï¼‰
    df = create_comprehensive_features(df, ai_factors_dict=None)
    df = df.dropna(subset=['Attendance'])

    base_features = [
        "Attendance_EWMA7", "Attendance_EWMA14", "Daily_Change", "Monthly_Change",
        "Attendance_Lag1", "Weekly_Change", "Attendance_Rolling7", "Attendance_Position7",
        "Attendance_Lag30", "Attendance_Lag7", "Day_of_Week", "Lag1_Diff",
        "DayOfWeek_sin", "Attendance_Rolling14", "Attendance_Position14",
        "Attendance_Position30", "Attendance_Rolling3", "Attendance_Min7",
        "Attendance_Median14", "DayOfWeek_Target_Mean", "Attendance_Median3",
        "Attendance_EWMA30", "Is_Winter_Flu_Season", "Is_Weekend", "Holiday_Factor"
    ]
    base_features = [c for c in base_features if c in df.columns]

    # åˆ†å‰²
    split_idx = int(len(df) * 0.8)
    train = df[:split_idx].copy()
    test = df[split_idx:].copy()

    # æ¯”è¼ƒæ‰€æœ‰ Ensemble æ–¹æ³•
    results, best = compare_all_ensembles(train, test, base_features)

    return {
        'name': best[0],
        'mae': best[1]['mae'],
        'results': results
    }


def test_stratified_modeling():
    """
    æ¸¬è©¦ 3: åˆ†å±¤å»ºæ¨¡ (å·¥ä½œæ—¥ vs é€±æœ«)
    é æœŸ: MAE 15.77 â†’ 15.0
    """
    print("\n" + "=" * 80)
    print("ğŸ§ª æ¸¬è©¦ 3: åˆ†å±¤å»ºæ¨¡ (å·¥ä½œæ—¥ vs é€±æœ«)")
    print("=" * 80)

    df = load_all_data()
    if df is None:
        return None

    # æ’é™¤ COVID + å¤©æ°£
    covid_start = pd.Timestamp('2020-02-01')
    covid_end = pd.Timestamp('2022-06-30')
    df = df[~((df['Date'] >= covid_start) & (df['Date'] <= covid_end))].copy()

    weather_df = load_weather_history()
    if weather_df is not None:
        df = add_weather_features(df, weather_df)
    df['Date'] = pd.to_datetime(df['Date'])

    df = create_comprehensive_features(df, ai_factors_dict=None)
    df = df.dropna(subset=['Attendance'])

    base_features = [
        "Attendance_EWMA7", "Attendance_EWMA14", "Daily_Change", "Monthly_Change",
        "Attendance_Lag1", "Weekly_Change", "Attendance_Rolling7", "Attendance_Position7",
        "Attendance_Lag30", "Attendance_Lag7", "Day_of_Week", "Lag1_Diff",
        "DayOfWeek_sin", "Attendance_Rolling14", "Attendance_Position14",
        "Attendance_Position30", "Attendance_Rolling3", "Attendance_Min7",
        "Attendance_Median14", "DayOfWeek_Target_Mean", "Attendance_Median3",
        "Attendance_EWMA30", "Is_Winter_Flu_Season", "Is_Weekend", "Holiday_Factor"
    ]
    base_features = [c for c in base_features if c in df.columns]

    # åˆ†å‰²
    split_idx = int(len(df) * 0.8)
    train = df[:split_idx].copy()
    test = df[split_idx:].copy()

    # åˆ†å±¤æ¨¡å‹
    train_weekday = train[train['Is_Weekend'] == 0].copy()
    train_weekend = train[train['Is_Weekend'] == 1].copy()

    test_weekday = test[test['Is_Weekend'] == 0].copy()
    test_weekend = test[test['Is_Weekend'] == 1].copy()

    print(f"\n   å·¥ä½œæ—¥: è¨“ç·´ {len(train_weekday)}, æ¸¬è©¦ {len(test_weekday)}")
    print(f"   é€±æœ«:   è¨“ç·´ {len(train_weekend)}, æ¸¬è©¦ {len(test_weekend)}")

    # è¨“ç·´å·¥ä½œæ—¥æ¨¡å‹
    X_train_wd = train_weekday[base_features].fillna(0)
    y_train_wd = train_weekday['Attendance'].values
    X_test_wd = test_weekday[base_features].fillna(0)
    y_test_wd = test_weekday['Attendance'].values

    model_wd = xgb.XGBRegressor(
        n_estimators=500, max_depth=8, learning_rate=0.05,
        objective='reg:squarederror', random_state=42, n_jobs=-1
    )
    model_wd.fit(X_train_wd, y_train_wd, verbose=False)
    pred_wd = model_wd.predict(X_test_wd)

    # è¨“ç·´é€±æœ«æ¨¡å‹
    X_train_we = train_weekend[base_features].fillna(0)
    y_train_we = train_weekend['Attendance'].values
    X_test_we = test_weekend[base_features].fillna(0)
    y_test_we = test_weekend['Attendance'].values

    model_we = xgb.XGBRegressor(
        n_estimators=500, max_depth=8, learning_rate=0.05,
        objective='reg:squarederror', random_state=42, n_jobs=-1
    )
    model_we.fit(X_train_we, y_train_we, verbose=False)
    pred_we = model_we.predict(X_test_we)

    # åˆä½µé æ¸¬
    y_true_combined = np.concatenate([y_test_wd, y_test_we])
    y_pred_combined = np.concatenate([pred_wd, pred_we])

    metrics = calculate_metrics(y_true_combined, y_pred_combined)

    print(f"\n   ğŸ“Š åˆ†å±¤æ¨¡å‹çµæœ:")
    print(f"      å·¥ä½œæ—¥ MAE: {mean_absolute_error(y_test_wd, pred_wd):.2f}")
    print(f"      é€±æœ« MAE:   {mean_absolute_error(y_test_we, pred_we):.2f}")
    print(f"      ç¸½é«” MAE:   {metrics['mae']:.2f}")
    print(f"      RÂ²:         {metrics['r2']:.4f}")

    return {
        'name': 'Stratified Modeling',
        'mae': metrics['mae'],
        'rmse': metrics['rmse'],
        'r2': metrics['r2']
    }


def test_combined_p0():
    """
    æ¸¬è©¦ 4: çµåˆæ‰€æœ‰ P0 å„ªåŒ–
    é æœŸ: MAE 15.77 â†’ 12.5
    """
    print("\n" + "=" * 80)
    print("ğŸ§ª æ¸¬è©¦ 4: çµåˆæ‰€æœ‰ P0 å„ªåŒ–")
    print("=" * 80)

    df = load_all_data()
    if df is None:
        return None

    # æ’é™¤ COVID + å¤©æ°£
    covid_start = pd.Timestamp('2020-02-01')
    covid_end = pd.Timestamp('2022-06-30')
    df = df[~((df['Date'] >= covid_start) & (df['Date'] <= covid_end))].copy()

    weather_df = load_weather_history()
    if weather_df is not None:
        df = add_weather_features(df, weather_df)
    df['Date'] = pd.to_datetime(df['Date'])

    # å¢å¼·ç‰¹å¾µ
    df = create_enhanced_features(df, include_aqhi=True)
    df = df.dropna(subset=['Attendance'])

    enhanced_features = get_enhanced_feature_columns()
    enhanced_features = [c for c in enhanced_features if c in df.columns]

    print(f"\n   ä½¿ç”¨ {len(enhanced_features)} å€‹å¢å¼·ç‰¹å¾µ")

    # åˆ†å‰²
    split_idx = int(len(df) * 0.8)
    train = df[:split_idx].copy()
    test = df[split_idx:].copy()

    # Stacking Ensemble
    print("\n   è¨“ç·´ Stacking Ensemble (å¢å¼·ç‰¹å¾µ)...")

    stacking = StackingEnsemble(use_meta='ridge')

    val_size = len(train) // 5
    train_val = train[-val_size:].copy()
    train_main = train[:-val_size].copy()

    X_train = train_main[enhanced_features].fillna(0)
    y_train = train_main['Attendance'].values
    X_val = train_val[enhanced_features].fillna(0)
    y_val = train_val['Attendance'].values
    X_test = test[enhanced_features].fillna(0)
    y_test = test['Attendance'].values

    stacking.fit(X_train, y_train, X_val, y_val)

    y_pred = stacking.predict(X_test)
    metrics = calculate_metrics(y_test, y_pred)

    print(f"\n   ğŸ“Š æœ€çµ‚çµæœ (P0 å…¨éƒ¨å„ªåŒ–):")
    print(f"      MAE:  {metrics['mae']:.2f}")
    print(f"      RMSE: {metrics['rmse']:.2f}")
    print(f"      RÂ²:   {metrics['r2']:.4f}")

    # èˆ‡åŸºæº–æ¯”è¼ƒ
    baseline_mae = 15.77
    improvement = ((baseline_mae - metrics['mae']) / baseline_mae) * 100

    print(f"\n   vs åŸºæº– (MAE {baseline_mae}):")
    print(f"      æ”¹å–„: {improvement:+.1f}%")

    return {
        'name': 'P0 Combined (Enhanced + Stacking)',
        'mae': metrics['mae'],
        'rmse': metrics['rmse'],
        'r2': metrics['r2'],
        'improvement_pct': improvement
    }


def main():
    """é‹è¡Œæ‰€æœ‰ P0 æ¸¬è©¦"""
    print("=" * 80)
    print("ğŸš€ P0 å„ªå…ˆä»»å‹™æ¸¬è©¦")
    print("ç›®æ¨™: MAE 15.77 â†’ 12.5")
    print("=" * 80)
    print(f"é–‹å§‹æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")

    results = []
    baseline_mae = 15.77

    # æ¸¬è©¦ 1: å¢å¼·ç‰¹å¾µ
    try:
        result1 = test_enhanced_features()
        if result1:
            results.append(result1)
    except Exception as e:
        print(f"   âŒ æ¸¬è©¦ 1 å¤±æ•—: {e}")

    # æ¸¬è©¦ 2: Stacking
    try:
        result2 = test_stacking_ensemble()
        if result2:
            results.append(result2)
    except Exception as e:
        print(f"   âŒ æ¸¬è©¦ 2 å¤±æ•—: {e}")

    # æ¸¬è©¦ 3: åˆ†å±¤å»ºæ¨¡
    try:
        result3 = test_stratified_modeling()
        if result3:
            results.append(result3)
    except Exception as e:
        print(f"   âŒ æ¸¬è©¦ 3 å¤±æ•—: {e}")

    # æ¸¬è©¦ 4: çµåˆæ‰€æœ‰
    try:
        result4 = test_combined_p0()
        if result4:
            results.append(result4)
    except Exception as e:
        print(f"   âŒ æ¸¬è©¦ 4 å¤±æ•—: {e}")

    # ç¸½çµ
    print("\n" + "=" * 80)
    print("ğŸ† P0 æ¸¬è©¦ç¸½çµ")
    print("=" * 80)

    print(f"\n{'æ–¹æ³•':<35} {'MAE':>10} {'æ”¹å–„':>10}")
    print("-" * 60)
    print(f"{'åŸºæº– (ç•¶å‰æœ€ä½³)':<35} {baseline_mae:>10.2f} {'---':>10}")

    for r in results:
        improvement = ((baseline_mae - r['mae']) / baseline_mae) * 100
        print(f"{r['name']:<35} {r['mae']:>10.2f} {improvement:>+9.1f}%")

    # æ‰¾å‡ºæœ€ä½³
    best = min(results, key=lambda x: x['mae'])
    best_improvement = ((baseline_mae - best['mae']) / baseline_mae) * 100

    print("\n" + "=" * 80)
    print(f"ğŸ¥‡ æœ€ä½³æ–¹æ³•: {best['name']}")
    print(f"   MAE: {best['mae']:.2f} (æ”¹å–„ {best_improvement:+.1f}%)")
    print("=" * 80)

    # ä¿å­˜çµæœ
    output = {
        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'baseline_mae': baseline_mae,
        'results': results,
        'best': best
    }

    os.makedirs('models', exist_ok=True)
    with open('models/p0_test_results.json', 'w', encoding='utf-8') as f:
        json.dump(output, f, indent=2, ensure_ascii=False, default=lambda x: float(x) if isinstance(x, (np.integer, np.floating)) else x)

    print(f"\nâœ… çµæœå·²ä¿å­˜åˆ° models/p0_test_results.json")
    print(f"\nçµæŸæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")


if __name__ == '__main__':
    main()
