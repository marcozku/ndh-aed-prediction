# -*- coding: utf-8 -*-
"""
ç‰¹å¾µé¸æ“‡æ¸¬è©¦ - ä½¿ç”¨å®Œæ•´å°å‡ºæ•¸æ“š
"""
import sys
import io

if sys.platform == 'win32':
    try:
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
        sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')
    except:
        pass

import pandas as pd
import numpy as np
from datetime import datetime
import json
import os
import warnings
warnings.filterwarnings('ignore')

# æ©Ÿå™¨å­¸ç¿’
from sklearn.ensemble import RandomForestRegressor
import xgboost as xgb
from sklearn.metrics import mean_absolute_error

# COVID æœŸé–“
COVID_PERIODS = [
    ('2020-01-23', '2020-04-08'),
    ('2020-07-16', '2020-09-30'),
    ('2020-11-23', '2021-01-05'),
    ('2022-02-05', '2022-04-30'),
    ('2022-11-10', '2022-12-27'),
]


def load_exported_data():
    """åŠ è¼‰å°å‡ºçš„å®Œæ•´æ•¸æ“š"""
    # å˜—è©¦å¤šå€‹è·¯å¾‘
    possible_paths = [
        '../ndh_attendance_export.csv',
        '../../ndh_attendance_export.csv',
        'C:/Github/ndh-aed-prediction/ndh_attendance_export.csv'
    ]

    df = None
    for file_path in possible_paths:
        if os.path.exists(file_path):
            print(f"ğŸ“‚ æ‰¾åˆ°æ–‡ä»¶: {file_path}")
            df = pd.read_csv(file_path)
            break

    if df is None:
        print(f"âŒ æ‰¾ä¸åˆ° ndh_attendance_export.csv")
        print("   è«‹ç¢ºä¿æ–‡ä»¶åœ¨é …ç›®æ ¹ç›®éŒ„")
        return None

    df['date'] = pd.to_datetime(df['date']).dt.date

    print(f"   âœ… åŠ è¼‰ {len(df)} ç­†è¨˜éŒ„")
    print(f"   ğŸ“… ç¯„åœ: {df['date'].min()} â†’ {df['date'].max()}")
    print(f"   ğŸ“ˆ å¹³å‡å°±è¨º: {df['patient_count'].mean():.1f} äºº")

    return df


def exclude_covid_periods(df):
    """æ’é™¤ COVID æœŸé–“"""
    print("\nğŸ¦  æ’é™¤ COVID æœŸé–“...")

    original_count = len(df)

    for start, end in COVID_PERIODS:
        start_date = pd.to_datetime(start).date()
        end_date = pd.to_datetime(end).date()
        mask = (df['date'] >= start_date) & (df['date'] <= end_date)
        removed = len(df[mask])
        df = df[~mask]
        if removed > 0:
            print(f"   ç§»é™¤ {start} åˆ° {end}: -{removed} ç­†")

    print(f"   ğŸ“Š éæ¿¾å¾Œ: {len(df)} ç­† (ç§»é™¤ {original_count - len(df)} ç­†)")

    return df


def prepare_features(df):
    """æº–å‚™ç‰¹å¾µ"""
    print("\nğŸ“Š æº–å‚™ç‰¹å¾µ...")

    df = df.copy()
    df['Date'] = pd.to_datetime(df['date'])

    # æ™‚é–“ç‰¹å¾µ
    df['Day_of_Week'] = df['Date'].dt.dayofweek
    df['Month'] = df['Date'].dt.month
    df['Day_of_Month'] = df['Date'].dt.day
    df['Is_Weekend'] = (df['Day_of_Week'] >= 5).astype(int)

    # é€±æœŸç·¨ç¢¼
    df['DayOfWeek_sin'] = np.sin(2 * np.pi * df['Day_of_Week'] / 7)
    df['DayOfWeek_cos'] = np.cos(2 * np.pi * df['Day_of_Week'] / 7)

    # å­£ç¯€æ€§
    df['Is_Winter_Flu_Season'] = df['Month'].isin([1, 2]).astype(int)
    df['Holiday_Factor'] = 1.0

    # æ­·å²å°±è¨º
    df = df.sort_values('Date').reset_index(drop=True)

    df['Attendance_Lag1'] = df['patient_count'].shift(1)
    df['Attendance_Lag7'] = df['patient_count'].shift(7)
    df['Attendance_Lag30'] = df['patient_count'].shift(30)

    df['Attendance_EWMA7'] = df['patient_count'].ewm(span=7, adjust=False).mean()
    df['Attendance_EWMA14'] = df['patient_count'].ewm(span=14, adjust=False).mean()

    df['Daily_Change'] = df['patient_count'].diff()
    df['Weekly_Change'] = df['patient_count'].diff(7)

    # å¡«è£œ
    df['Attendance_Lag1'] = df['Attendance_Lag1'].fillna(df['patient_count'].mean())
    df['Attendance_Lag7'] = df['Attendance_Lag7'].fillna(df['patient_count'].mean())
    df['Attendance_Lag30'] = df['Attendance_Lag30'].fillna(df['patient_count'].mean())
    df['Attendance_EWMA7'] = df['Attendance_EWMA7'].fillna(method='bfill')
    df['Attendance_EWMA14'] = df['Attendance_EWMA14'].fillna(method='bfill')
    df['Daily_Change'] = df['Daily_Change'].fillna(0)
    df['Weekly_Change'] = df['Weekly_Change'].fillna(0)

    # ç§»é™¤ NaN
    before = len(df)
    df = df.dropna()
    after = len(df)

    print(f"   âœ… ç‰¹å¾µæº–å‚™å®Œæˆ: {after} ç­† (ç§»é™¤ {before - after} ç­†å« NaN)")
    return df


def test_feature_selection(X_train, y_train, X_test, y_test, feature_names):
    """å®Œæ•´ç‰¹å¾µé¸æ“‡æ¸¬è©¦"""
    print("\n" + "=" * 80)
    print("ğŸ” ç‰¹å¾µé¸æ“‡æ¸¬è©¦ (å®Œæ•´æ•¸æ“š)")
    print("=" * 80)

    # è¨“ç·´æ¨¡å‹ç²å–é‡è¦æ€§
    print("\n1ï¸âƒ£ è¨“ç·´ XGBoost ç²å–ç‰¹å¾µé‡è¦æ€§...")
    model = xgb.XGBRegressor(
        n_estimators=500,
        max_depth=6,
        learning_rate=0.05,
        min_child_weight=3,
        subsample=0.8,
        colsample_bytree=0.8,
        random_state=42,
        n_jobs=-1
    )
    model.fit(X_train, y_train, verbose=False)

    # ç‰¹å¾µé‡è¦æ€§
    importances = model.feature_importances_
    indices = np.argsort(importances)[::-1]

    print("\n   ç‰¹å¾µé‡è¦æ€§æ’å:")
    print(f"   {'æ’å':<4} {'ç‰¹å¾µ':<30} {'é‡è¦æ€§':<10}")
    print("   " + "-" * 50)

    for i, idx in enumerate(indices, 1):
        feature = feature_names[idx]
        importance = importances[idx]
        print(f"   {i:<4} {feature:<30} {importance:.4f}")

    # æ¸¬è©¦ä¸åŒç‰¹å¾µæ•¸é‡
    print("\n2ï¸âƒ£ æ¸¬è©¦ä¸åŒç‰¹å¾µæ•¸é‡...")
    print(f"   {'ç‰¹å¾µæ•¸':<10} {'MAE':<10} {'æ”¹å–„ %':<10} {'ç‹€æ…‹':<5}")
    print("   " + "-" * 45)

    baseline_mae = 15.73
    results = []

    # æ¸¬è©¦æ‰€æœ‰å¯èƒ½çš„æ•¸é‡
    for n_features in range(3, len(feature_names) + 1):
        selected_indices = indices[:n_features]
        X_train_sel = X_train.iloc[:, selected_indices]
        X_test_sel = X_test.iloc[:, selected_indices]

        model_sel = xgb.XGBRegressor(
            n_estimators=300,
            max_depth=6,
            learning_rate=0.05,
            random_state=42,
            n_jobs=-1
        )
        model_sel.fit(X_train_sel, y_train, verbose=False)

        y_pred = model_sel.predict(X_test_sel)
        mae = mean_absolute_error(y_test, y_pred)
        improvement = ((baseline_mae - mae) / baseline_mae * 100)

        results.append({
            'n_features': n_features,
            'mae': mae,
            'improvement': improvement
        })

        status = "âœ…" if mae < baseline_mae else "âŒ"
        print(f"   {n_features:<10} {mae:<10.2f} {improvement:>+6.1f}%   {status}")

    # æ‰¾å‡ºæœ€ä½³
    best = min(results, key=lambda x: x['mae'])
    worst = max(results, key=lambda x: x['mae'])

    print("\n" + "=" * 80)
    print("ğŸ† æ¸¬è©¦çµæœ")
    print("=" * 80)
    print(f"\nåŸºæº– (èˆŠæ¨¡å‹): MAE = {baseline_mae}")
    print(f"æœ€ä½³ç‰¹å¾µæ•¸: {best['n_features']} å€‹ â†’ MAE = {best['mae']:.2f} ({best['improvement']:+.1f}%)")
    print(f"æœ€å·®ç‰¹å¾µæ•¸: {worst['n_features']} å€‹ â†’ MAE = {worst['mae']:.2f}")

    # åˆ†æ
    improvement_best_vs_all = ((results[-1]['mae'] - best['mae']) / results[-1]['mae'] * 100)

    if best['n_features'] < len(feature_names):
        print(f"\nâœ… é‡è¦ç™¼ç¾:")
        print(f"   ä½¿ç”¨å…¨éƒ¨ {len(feature_names)} å€‹ç‰¹å¾µ: MAE = {results[-1]['mae']:.2f}")
        print(f"   æœ€ä½³ {best['n_features']} å€‹ç‰¹å¾µ: MAE = {best['mae']:.2f}")
        print(f"   æ¸›å°‘ç‰¹å¾µæ”¹å–„: {improvement_best_vs_all:+.1f}%")
    else:
        print(f"\nâš ï¸ çµè«–: æ‰€æœ‰ç‰¹å¾µéƒ½æœ‰ç”¨")

    return results, best, indices, importances


def main():
    """ä¸»æ¸¬è©¦æµç¨‹"""
    print("=" * 80)
    print("ğŸ¯ ç‰¹å¾µé¸æ“‡æ¸¬è©¦ (å®Œæ•´ Railway æ•¸æ“š)")
    print("=" * 80)
    print(f"æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")

    # 1. åŠ è¼‰æ•¸æ“š
    df = load_exported_data()
    if df is None:
        return

    # 2. æ’é™¤ COVID
    df = exclude_covid_periods(df)

    # 3. æº–å‚™ç‰¹å¾µ
    df = prepare_features(df)

    # 4. ç‰¹å¾µåˆ—è¡¨
    feature_names = [
        'Day_of_Week', 'Month', 'Day_of_Month', 'Is_Weekend',
        'Holiday_Factor', 'Is_Winter_Flu_Season',
        'DayOfWeek_sin', 'DayOfWeek_cos',
        'Attendance_Lag1', 'Attendance_Lag7', 'Attendance_Lag30',
        'Attendance_EWMA7', 'Attendance_EWMA14',
        'Daily_Change', 'Weekly_Change'
    ]

    # 5. åˆ†å‰²æ•¸æ“š
    print("\nâœ‚ï¸ åˆ†å‰²æ•¸æ“š...")
    train_size = int(len(df) * 0.8)

    train_df = df.iloc[:train_size]
    test_df = df.iloc[train_size:]

    X_train = train_df[feature_names]
    y_train = train_df['patient_count']
    X_test = test_df[feature_names]
    y_test = test_df['patient_count']

    print(f"   è¨“ç·´é›†: {len(X_train)} ç­†")
    print(f"   æ¸¬è©¦é›†: {len(X_test)} ç­†")
    print(f"   æ¸¬è©¦ç¯„åœ: {test_df['Date'].min()} â†’ {test_df['Date'].max()}")

    # 6. æ¸¬è©¦
    results, best, indices, importances = test_feature_selection(
        X_train, y_train, X_test, y_test, feature_names
    )

    # 7. ä¿å­˜çµæœ
    output = {
        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'data_info': {
            'total_records': len(df),
            'date_range': f"{df['Date'].min()} â†’ {df['Date'].max()}",
            'train_size': len(X_train),
            'test_size': len(X_test)
        },
        'baseline_mae': 15.73,
        'total_features': len(feature_names),
        'best_n_features': best['n_features'],
        'best_mae': best['mae'],
        'improvement_pct': best['improvement'],
        'feature_importance': {
            feature_names[i]: float(importances[i]) for i in range(len(feature_names))
        },
        'all_results': results
    }

    os.makedirs('models', exist_ok=True)
    with open('models/feature_selection_full_results.json', 'w', encoding='utf-8') as f:
        json.dump(output, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ’¾ çµæœå·²ä¿å­˜åˆ° models/feature_selection_full_results.json")

    # æ¨è–¦
    print("\n" + "=" * 80)
    print("ğŸ’¡ æ¨è–¦")
    print("=" * 80)
    print(f"\næœ€ä½³ {best['n_features']} å€‹ç‰¹å¾µ:")
    for i in range(best['n_features']):
        idx = indices[i]
        print(f"   {i+1}. {feature_names[idx]} (é‡è¦æ€§: {importances[idx]:.4f})")

    print("\n" + "=" * 80)
    print("âœ… æ¸¬è©¦å®Œæˆ")
    print("=" * 80)


if __name__ == '__main__':
    main()
