# -*- coding: utf-8 -*-
"""
ç°¡åŒ–ç‰ˆç‰¹å¾µé¸æ“‡æ¸¬è©¦ - è¨ºæ–·ç‰ˆæœ¬
"""
import sys
import io

if sys.platform == 'win32':
    try:
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
        sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')
    except:
        pass

import pandas as pd
import numpy as np
from datetime import datetime
import psycopg2
import psycopg2.extras
from sklearn.ensemble import RandomForestRegressor
import xgboost as xgb
import json
import os
import warnings
warnings.filterwarnings('ignore')

# æ•¸æ“šåº«é€£æ¥
DB_CONFIG = {
    'host': 'razzle.db.elephantsql.com',
    'database': 'ndh_aed',
    'user': 'ndh_aed',
    'password': 'B3IG7EYud_UMqfUNvEbi5XxO9xh5l8Pp',
    'port': 5432
}

# COVID æœŸé–“
COVID_PERIODS = [
    ('2020-01-23', '2020-04-08'),
    ('2020-07-16', '2020-09-30'),
    ('2020-11-23', '2021-01-05'),
    ('2022-02-05', '2022-04-30'),
    ('2022-11-10', '2022-12-27'),
]


def load_data():
    """åŠ è¼‰æ•¸æ“š"""
    try:
        print("ğŸ“¡ åŠ è¼‰æ•¸æ“š...")
        conn = psycopg2.connect(**DB_CONFIG)
        cursor = conn.cursor(cursor_factory=psycopg2.extras.RealDictCursor)

        query = "SELECT date, patient_count FROM actual_data ORDER BY date ASC"
        cursor.execute(query)
        rows = cursor.fetchall()

        cursor.close()
        conn.close()

        df = pd.DataFrame(rows)
        df['date'] = pd.to_datetime(df['date'])

        # æ’é™¤ COVID
        for start, end in COVID_PERIODS:
            start_date = pd.to_datetime(start)
            end_date = pd.to_datetime(end)
            mask = (df['date'] >= start_date) & (df['date'] <= end_date)
            df = df[~mask]

        print(f"   âœ… {len(df)} ç­†è¨˜éŒ„")
        return df

    except Exception as e:
        print(f"   âŒ {e}")
        return None


def load_weather_data():
    """åŠ è¼‰å¤©æ°£æ•¸æ“š"""
    weather_file = 'models/weather_full_history.csv'
    if not os.path.exists(weather_file):
        return None

    weather_df = pd.read_csv(weather_file)
    weather_df['Date'] = pd.to_datetime(weather_df['Date'])
    return weather_df


def prepare_features_simple(df):
    """æº–å‚™åŸºç¤ç‰¹å¾µ"""
    print("\nğŸ“Š æº–å‚™ç‰¹å¾µ...")

    df = df.rename(columns={'date': 'Date'})

    # æ™‚é–“ç‰¹å¾µ
    df['Day_of_Week'] = df['Date'].dt.dayofweek
    df['Month'] = df['Date'].dt.month
    df['Day_of_Month'] = df['Date'].dt.day
    df['Is_Weekend'] = (df['Day_of_Week'] >= 5).astype(int)

    # é€±æœŸç·¨ç¢¼
    df['DayOfWeek_sin'] = np.sin(2 * np.pi * df['Day_of_Week'] / 7)
    df['DayOfWeek_cos'] = np.cos(2 * np.pi * df['Day_of_Week'] / 7)

    # æµæ„Ÿå­£ç¯€
    df['Is_Winter_Flu_Season'] = df['Month'].isin([1, 2]).astype(int)
    df['Holiday_Factor'] = 1.0

    # æ­·å²å°±è¨º
    df = df.sort_values('Date').reset_index(drop=True)

    df['Attendance_Lag1'] = df['patient_count'].shift(1)
    df['Attendance_Lag7'] = df['patient_count'].shift(7)
    df['Attendance_Lag30'] = df['patient_count'].shift(30)

    df['Attendance_EWMA7'] = df['patient_count'].ewm(span=7, adjust=False).mean()
    df['Attendance_EWMA14'] = df['patient_count'].ewm(span=14, adjust=False).mean()

    df['Daily_Change'] = df['patient_count'].diff()
    df['Weekly_Change'] = df['patient_count'].diff(7)

    # å¡«è£œ
    df['Attendance_Lag1'] = df['Attendance_Lag1'].fillna(df['patient_count'].mean())
    df['Attendance_Lag7'] = df['Attendance_Lag7'].fillna(df['patient_count'].mean())
    df['Attendance_Lag30'] = df['Attendance_Lag30'].fillna(df['patient_count'].mean())
    df['Attendance_EWMA7'] = df['Attendance_EWMA7'].fillna(method='bfill')
    df['Attendance_EWMA14'] = df['Attendance_EWMA14'].fillna(method='bfill')
    df['Daily_Change'] = df['Daily_Change'].fillna(0)
    df['Weekly_Change'] = df['Weekly_Change'].fillna(0)

    # ç§»é™¤ NaN
    df = df.dropna()

    print(f"   âœ… ç‰¹å¾µæº–å‚™å®Œæˆ: {len(df)} ç­†")
    return df


def test_feature_importance(X_train, y_train, X_test, y_test, feature_names):
    """æ¸¬è©¦ç‰¹å¾µé‡è¦æ€§"""
    print("\n" + "=" * 80)
    print("ğŸ” ç‰¹å¾µé‡è¦æ€§åˆ†æ")
    print("=" * 80)

    # è¨“ç·´æ¨¡å‹
    print("\nè¨“ç·´ XGBoost...")
    model = xgb.XGBRegressor(
        n_estimators=300,
        max_depth=6,
        learning_rate=0.05,
        random_state=42,
        n_jobs=-1
    )

    model.fit(X_train, y_train, verbose=False)

    # ç‰¹å¾µé‡è¦æ€§
    importances = model.feature_importances_
    indices = np.argsort(importances)[::-1]

    print("\n   Top 20 ç‰¹å¾µ:")
    print(f"   {'æ’å':<4} {'ç‰¹å¾µ':<35} {'é‡è¦æ€§':<10}")
    print("   " + "-" * 60)

    for i, idx in enumerate(indices[:20], 1):
        feature = feature_names[idx]
        importance = importances[idx]
        print(f"   {i:<4} {feature:<35} {importance:.4f}")

    # è©•ä¼°
    from sklearn.metrics import mean_absolute_error
    y_pred = model.predict(X_test)
    mae = mean_absolute_error(y_test, y_pred)

    print(f"\n   æ‰€æœ‰ç‰¹å¾µ ({len(feature_names)} å€‹): MAE = {mae:.2f}")

    # æ¸¬è©¦ä¸åŒç‰¹å¾µæ•¸é‡
    print("\n" + "=" * 80)
    print("ğŸ” æ¸¬è©¦ä¸åŒç‰¹å¾µæ•¸é‡")
    print("=" * 80)

    results = []
    feature_counts = [5, 10, 15, 20, 25, 30, 40, 50]

    for n_features in feature_counts:
        if n_features > len(feature_names):
            continue

        # é¸æ“‡ top n_features
        selected_indices = indices[:n_features]
        X_train_selected = X_train.iloc[:, selected_indices]
        X_test_selected = X_test.iloc[:, selected_indices]

        # è¨“ç·´
        model_selected = xgb.XGBRegressor(
            n_estimators=300,
            max_depth=6,
            learning_rate=0.05,
            random_state=42,
            n_jobs=-1
        )
        model_selected.fit(X_train_selected, y_train, verbose=False)

        # è©•ä¼°
        y_pred_selected = model_selected.predict(X_test_selected)
        mae_selected = mean_absolute_error(y_test, y_pred_selected)

        results.append({
            'n_features': n_features,
            'mae': mae_selected
        })

        print(f"   {n_features:3d} ç‰¹å¾µ: MAE = {mae_selected:.2f}")

    # æ‰¾å‡ºæœ€ä½³
    best_result = min(results, key=lambda x: x['mae'])

    print("\n" + "=" * 80)
    print(f"ğŸ† æœ€ä½³ç‰¹å¾µæ•¸é‡: {best_result['n_features']} å€‹")
    print(f"   MAE: {best_result['mae']:.2f}")
    print(f"   æ”¹å–„: {((15.73 - best_result['mae']) / 15.73 * 100):.1f}%")
    print("=" * 80)

    return results, best_result, indices, importances


def main():
    """ä¸»æ¸¬è©¦æµç¨‹"""
    print("=" * 80)
    print("ğŸ¯ ç‰¹å¾µé¸æ“‡æ¸¬è©¦ï¼ˆç°¡åŒ–ç‰ˆï¼‰")
    print("=" * 80)
    print(f"æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")

    # 1. åŠ è¼‰æ•¸æ“š
    df = load_data()
    if df is None:
        print("   âŒ ç„¡æ³•åŠ è¼‰æ•¸æ“š")
        return

    # 2. æº–å‚™ç‰¹å¾µ
    df = prepare_features_simple(df)

    # 3. ç‰¹å¾µåˆ—è¡¨
    feature_names = [
        'Day_of_Week', 'Month', 'Day_of_Month', 'Is_Weekend',
        'Holiday_Factor', 'Is_Winter_Flu_Season',
        'DayOfWeek_sin', 'DayOfWeek_cos',
        'Attendance_Lag1', 'Attendance_Lag7', 'Attendance_Lag30',
        'Attendance_EWMA7', 'Attendance_EWMA14',
        'Daily_Change', 'Weekly_Change'
    ]

    # éæ¿¾å­˜åœ¨çš„ç‰¹å¾µ
    feature_names = [f for f in feature_names if f in df.columns]

    print(f"\nğŸ“‹ ç‰¹å¾µæ•¸é‡: {len(feature_names)}")

    # 4. åˆ†å‰²æ•¸æ“š
    print("\nâœ‚ï¸ åˆ†å‰²æ•¸æ“š...")
    train_size = int(len(df) * 0.8)

    train_df = df.iloc[:train_size]
    test_df = df.iloc[train_size:]

    X_train = train_df[feature_names]
    y_train = train_df['patient_count']
    X_test = test_df[feature_names]
    y_test = test_df['patient_count']

    print(f"   è¨“ç·´é›†: {len(X_train)} ç­†")
    print(f"   æ¸¬è©¦é›†: {len(X_test)} ç­†")

    # 5. æ¸¬è©¦
    results, best_result, indices, importances = test_feature_importance(
        X_train, y_train, X_test, y_test, feature_names
    )

    # 6. ä¿å­˜çµæœ
    output = {
        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'baseline_mae': 15.73,
        'total_features': len(feature_names),
        'best_n_features': best_result['n_features'],
        'best_mae': best_result['mae'],
        'improvement_pct': ((15.73 - best_result['mae']) / 15.73 * 100),
        'feature_importance': {
            feature_names[i]: float(importances[i]) for i in range(len(feature_names))
        }
    }

    os.makedirs('models', exist_ok=True)
    with open('models/feature_selection_simple_results.json', 'w', encoding='utf-8') as f:
        json.dump(output, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ’¾ çµæœå·²ä¿å­˜")

    print("\n" + "=" * 80)
    print("âœ… æ¸¬è©¦å®Œæˆ")
    print("=" * 80)


if __name__ == '__main__':
    main()
