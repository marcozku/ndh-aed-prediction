"""
æ¸¬è©¦å¤©æ°£æ»¯å¾Œæ•ˆæ‡‰ï¼ˆWeather Lag Effectsï¼‰
çªç„¶é™æº«å¯èƒ½ 3-5 å¤©å¾Œæ‰å½±éŸ¿å°±è¨ºç‡
"""
import sys
import io

if sys.platform == 'win32':
    try:
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
        sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')
    except:
        pass

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import json
import os
from datetime import datetime

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
from feature_engineering import create_comprehensive_features

def load_data():
    csv_paths = [
        '../ndh_attendance_extracted.csv',
        'ndh_attendance_extracted.csv',
        'c:/Github/ndh-aed-prediction/ndh_attendance_extracted.csv',
    ]
    for csv_path in csv_paths:
        if os.path.exists(csv_path):
            df = pd.read_csv(csv_path)
            if 'date' in df.columns:
                df['Date'] = df['date']
            if 'patient_count' in df.columns:
                df['Attendance'] = df['patient_count']
            if 'attendance' in df.columns:
                df['Attendance'] = df['attendance']
            return df[['Date', 'Attendance']].copy()
    return None

def load_weather_data():
    weather_paths = [
        'weather_history.csv',
        'python/weather_history.csv',
        'c:/Github/ndh-aed-prediction/python/weather_history.csv',
    ]
    for path in weather_paths:
        if os.path.exists(path):
            df = pd.read_csv(path)
            df['Date'] = pd.to_datetime(df['Date'])
            return df
    return None

def create_weather_lag_features(df):
    """
    å‰µå»ºå¤©æ°£æ»¯å¾Œç‰¹å¾µ
    å‡è¨­ï¼šä»Šå¤©é™æº« â†’ 3-5å¤©å¾Œæ‰å½±éŸ¿å°±è¨º
    """
    df = df.copy()
    df = df.sort_values('Date').reset_index(drop=True)

    # æº«åº¦è®ŠåŒ–
    df['temp_change_1d'] = df['mean_temp'].diff(1)
    df['sudden_temp_drop'] = (df['temp_change_1d'] < -5).astype(int)
    df['extreme_temp_drop'] = (df['temp_change_1d'] < -8).astype(int)

    # æ»¯å¾Œç‰¹å¾µï¼ˆ3-7å¤©å‰çš„å¤©æ°£è®ŠåŒ–ï¼‰
    for lag in [1, 2, 3, 4, 5, 7]:
        df[f'temp_change_lag{lag}d'] = df['temp_change_1d'].shift(lag)
        df[f'sudden_drop_lag{lag}d'] = df['sudden_temp_drop'].shift(lag)
        df[f'extreme_drop_lag{lag}d'] = df['extreme_temp_drop'].shift(lag)
        df[f'mean_temp_lag{lag}d'] = df['mean_temp'].shift(lag)
        df[f'is_cold_lag{lag}d'] = df['is_cold'].shift(lag)

    # ç´¯ç©æ•ˆæ‡‰ï¼ˆéå»3å¤©/5å¤©/7å¤©æœ‰å¹¾å¤©çªç„¶é™æº«ï¼‰
    df['sudden_drops_past3d'] = df['sudden_temp_drop'].rolling(window=3, min_periods=1).sum()
    df['sudden_drops_past5d'] = df['sudden_temp_drop'].rolling(window=5, min_periods=1).sum()
    df['sudden_drops_past7d'] = df['sudden_temp_drop'].rolling(window=7, min_periods=1).sum()

    # æ¥µç«¯é™æº«å¾Œçš„å¤©æ•¸
    df['days_since_extreme_drop'] = 0
    days_counter = 999
    for i in range(len(df)):
        if df.at[i, 'extreme_temp_drop'] == 1:
            days_counter = 0
        else:
            days_counter += 1
        df.at[i, 'days_since_extreme_drop'] = min(days_counter, 14)

    return df

def calculate_metrics(y_true, y_pred):
    mae = mean_absolute_error(y_true, y_pred)
    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100
    r2 = r2_score(y_true, y_pred)
    return {'mae': mae, 'rmse': rmse, 'mape': mape, 'r2': r2}

def main():
    print("=" * 70)
    print("â±ï¸ æ¸¬è©¦å¤©æ°£æ»¯å¾Œæ•ˆæ‡‰ï¼ˆ3-7å¤©å¾Œæ‰å½±éŸ¿å°±è¨ºï¼‰")
    print("=" * 70)
    print(f"â° é–‹å§‹æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")

    df = load_data()
    if df is None:
        print("âŒ ç„¡æ³•åŠ è¼‰æ•¸æ“š")
        return

    df['Date'] = pd.to_datetime(df['Date'])

    # COVID æ’é™¤
    covid_start = pd.Timestamp('2020-02-01')
    covid_end = pd.Timestamp('2022-06-30')
    covid_mask = (df['Date'] >= covid_start) & (df['Date'] <= covid_end)
    df = df[~covid_mask].copy()

    print("ğŸ”§ å‰µå»ºåŸºç¤ç‰¹å¾µ...")
    df = create_comprehensive_features(df)
    df = df.dropna(subset=['Attendance'])

    print("ğŸŒ¤ï¸ åŠ è¼‰å¤©æ°£æ•¸æ“š...")
    weather_df = load_weather_data()
    if weather_df is None:
        print("âŒ ç„¡æ³•åŠ è¼‰å¤©æ°£æ•¸æ“š")
        return

    print("ğŸ”§ å‰µå»ºå¤©æ°£æ»¯å¾Œç‰¹å¾µ...")
    weather_df = create_weather_lag_features(weather_df)

    df = df.merge(weather_df, on='Date', how='left')
    print(f"   âœ… åˆä½µå¾Œ: {len(df)} ç­†")

    # å¡«å……ç¼ºå¤±å€¼
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    for col in numeric_cols:
        if col not in ['Date', 'Attendance']:
            df[col] = df[col].fillna(0)

    # æ™‚é–“åºåˆ—åˆ†å‰²
    split_idx = int(len(df) * 0.8)
    train_data = df[:split_idx].copy()
    test_data = df[split_idx:].copy()

    print(f"\nğŸ“Š æ•¸æ“šåˆ†å‰²:")
    print(f"   è¨“ç·´é›†: {len(train_data)} ç­†")
    print(f"   æ¸¬è©¦é›†: {len(test_data)} ç­†")

    base_features = [
        "Attendance_Lag1", "Attendance_Lag7", "Attendance_Same_Weekday_Avg",
        "Day_of_Week", "DayOfWeek_Target_Mean", "Attendance_Rolling7",
        "Attendance_EWMA7", "Attendance_Lag14", "Attendance_Lag30",
        "Daily_Change", "Weekly_Change", "Is_Weekend",
        "Holiday_Factor", "Attendance_Std7", "Month"
    ]
    base_features = [c for c in base_features if c in df.columns]

    # æ»¯å¾Œå¤©æ°£ç‰¹å¾µ
    lag_weather_features = [col for col in df.columns if 'lag' in col.lower() and col not in base_features]
    lag_weather_features += ['sudden_drops_past3d', 'sudden_drops_past5d', 'sudden_drops_past7d', 'days_since_extreme_drop']
    lag_weather_features = [c for c in lag_weather_features if c in df.columns]

    y_train = train_data['Attendance'].values
    y_test = test_data['Attendance'].values

    results = {}

    # æ¸¬è©¦ 1: åŸºæº–
    print("\n" + "=" * 70)
    print("ğŸ“Š æ¸¬è©¦ 1: Random Forest (ç„¡å¤©æ°£) - åŸºæº–")
    print("=" * 70)

    X_train = train_data[base_features].fillna(0)
    X_test = test_data[base_features].fillna(0)

    rf_base = RandomForestRegressor(n_estimators=200, max_depth=12, min_samples_split=10, random_state=42, n_jobs=-1)
    rf_base.fit(X_train, y_train)
    pred_base = rf_base.predict(X_test)

    metrics_base = calculate_metrics(y_test, pred_base)
    results['rf_base'] = metrics_base

    print(f"   MAE:  {metrics_base['mae']:.2f}")
    print(f"   MAPE: {metrics_base['mape']:.2f}%")
    print(f"   RÂ²:   {metrics_base['r2']:.4f}")

    # æ¸¬è©¦ 2: åŠ å…¥æ»¯å¾Œå¤©æ°£ç‰¹å¾µ
    print("\n" + "=" * 70)
    print("ğŸ“Š æ¸¬è©¦ 2: Random Forest + å¤©æ°£æ»¯å¾Œç‰¹å¾µ")
    print("=" * 70)
    print(f"   æ»¯å¾Œç‰¹å¾µæ•¸é‡: {len(lag_weather_features)}")

    all_features = base_features + lag_weather_features
    X_train_lag = train_data[all_features].fillna(0)
    X_test_lag = test_data[all_features].fillna(0)

    rf_lag = RandomForestRegressor(n_estimators=200, max_depth=12, min_samples_split=10, random_state=42, n_jobs=-1)
    rf_lag.fit(X_train_lag, y_train)
    pred_lag = rf_lag.predict(X_test_lag)

    metrics_lag = calculate_metrics(y_test, pred_lag)
    results['rf_lag'] = metrics_lag

    improvement = metrics_lag['mae'] - metrics_base['mae']
    improvement_pct = (improvement / metrics_base['mae']) * 100

    print(f"   MAE:  {metrics_lag['mae']:.2f} ({improvement:+.2f}, {improvement_pct:+.1f}%)")
    print(f"   MAPE: {metrics_lag['mape']:.2f}%")
    print(f"   RÂ²:   {metrics_lag['r2']:.4f}")

    # ç‰¹å¾µé‡è¦æ€§
    print("\n   ğŸ” æ»¯å¾Œå¤©æ°£ç‰¹å¾µé‡è¦æ€§ (Top 15):")
    feature_importance = pd.DataFrame({
        'feature': all_features,
        'importance': rf_lag.feature_importances_
    }).sort_values('importance', ascending=False)

    lag_importance = feature_importance[feature_importance['feature'].isin(lag_weather_features)].head(15)
    for _, row in lag_importance.iterrows():
        print(f"      {row['feature']:35} {row['importance']:.4f}")

    # ç¸½çµ
    print("\n" + "=" * 70)
    print("ğŸ† çµè«–")
    print("=" * 70)

    if metrics_lag['mae'] < metrics_base['mae']:
        print(f"   âœ… å¤©æ°£æ»¯å¾Œæ•ˆæ‡‰æœ‰å¹«åŠ©ï¼")
        print(f"   MAE æ”¹å–„: {abs(improvement_pct):.1f}%")
        print(f"   â†’ çªç„¶é™æº«ç¢ºå¯¦æœƒåœ¨ 3-7 å¤©å¾Œå½±éŸ¿å°±è¨ºç‡")
    else:
        print(f"   âŒ å¤©æ°£æ»¯å¾Œæ•ˆæ‡‰æ²’æœ‰æ˜é¡¯å¹«åŠ©")
        print(f"   â†’ å¤©æ°£å°åŒ—å€é†«é™¢æ€¥ç—‡å°±è¨ºå½±éŸ¿å¾ˆå°")

    # ä¿å­˜çµæœ
    output = {
        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'results': results,
        'lag_features_used': lag_weather_features,
        'conclusion': {
            'lag_helps': metrics_lag['mae'] < metrics_base['mae'],
            'improvement': improvement,
            'improvement_pct': improvement_pct
        }
    }

    os.makedirs('models', exist_ok=True)
    with open('models/weather_lag_test_results.json', 'w') as f:
        json.dump(output, f, indent=2)

    print(f"\nâœ… çµæœå·²ä¿å­˜åˆ° models/weather_lag_test_results.json")

if __name__ == '__main__':
    main()
