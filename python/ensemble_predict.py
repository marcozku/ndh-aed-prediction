"""
XGBoost é æ¸¬è…³æœ¬
v4.0.20: æ”¯æŒæ»¾å‹•é æ¸¬ (rolling forecast) - ä¿®å¾©é€±æœŸæ€§å¾ªç’°å•é¡Œ
å„ªå…ˆä½¿ç”¨ opt10 æ¨¡å‹ (MAE: 2.85)
"""
import pandas as pd
import numpy as np
import json
import os
import sys
from datetime import datetime, timedelta

# æœ€ä½³ 10 å€‹ç‰¹å¾µ (opt10)
OPT10_FEATURES = [
    'Attendance_EWMA7', 'Daily_Change', 'Attendance_EWMA14',
    'Weekly_Change', 'Day_of_Week', 'Attendance_Lag7',
    'Attendance_Lag1', 'Is_Weekend', 'DayOfWeek_sin', 'DayOfWeek_cos'
]

def prepare_opt10_features(df, target_date_str):
    """ç‚º opt10 æ¨¡å‹æº–å‚™ç‰¹å¾µï¼ˆå–®æ—¥é æ¸¬ï¼‰"""
    df = df.copy()
    df['Date'] = pd.to_datetime(df['Date'])
    df = df.sort_values('Date').reset_index(drop=True)

    # æ™‚é–“ç‰¹å¾µ
    target_dt = pd.to_datetime(target_date_str)

    # ç‚ºç›®æ¨™æ—¥æœŸå‰µå»ºä¸€è¡Œ
    last_row = {}
    last_row['Date'] = target_dt
    last_row['Day_of_Week'] = target_dt.dayofweek
    last_row['Is_Weekend'] = 1 if target_dt.dayofweek >= 5 else 0

    # é€±æœŸç·¨ç¢¼
    last_row['DayOfWeek_sin'] = np.sin(2 * np.pi * target_dt.dayofweek / 7)
    last_row['DayOfWeek_cos'] = np.cos(2 * np.pi * target_dt.dayofweek / 7)

    # æ­·å²å°±è¨ºæ•¸æ“š
    if len(df) >= 1:
        last_row['Attendance_Lag1'] = df.iloc[-1]['Attendance']
    else:
        last_row['Attendance_Lag1'] = df['Attendance'].mean() if len(df) > 0 else 250

    if len(df) >= 7:
        last_row['Attendance_Lag7'] = df.iloc[-7]['Attendance']
    else:
        last_row['Attendance_Lag7'] = df['Attendance'].mean() if len(df) > 0 else 250

    # EWMA
    if len(df) >= 1:
        series = df['Attendance']
        last_row['Attendance_EWMA7'] = series.ewm(span=7, adjust=False).mean().iloc[-1]
        last_row['Attendance_EWMA14'] = series.ewm(span=14, adjust=False).mean().iloc[-1]
    else:
        last_row['Attendance_EWMA7'] = 250
        last_row['Attendance_EWMA14'] = 250

    # è®ŠåŒ–
    if len(df) >= 2:
        last_row['Daily_Change'] = df.iloc[-1]['Attendance'] - df.iloc[-2]['Attendance']
    else:
        last_row['Daily_Change'] = 0

    if len(df) >= 8:
        last_row['Weekly_Change'] = df.iloc[-1]['Attendance'] - df.iloc[-8]['Attendance']
    else:
        last_row['Weekly_Change'] = 0

    # ç¢ºä¿åˆ—é †åºèˆ‡ OPT10_FEATURES å®Œå…¨ä¸€è‡´ï¼ˆXGBoost éœ€è¦åŒ¹é…çš„ç‰¹å¾µåç¨±ï¼‰
    return pd.DataFrame([last_row], columns=OPT10_FEATURES)


def prepare_rolling_features(df, target_date_str, previous_predictions=None):
    """
    ç‚ºæ»¾å‹•é æ¸¬æº–å‚™ç‰¹å¾µ (v4.0.20)

    åƒæ•¸:
        df: æ­·å²æ•¸æ“š DataFrame
        target_date_str: ç›®æ¨™æ—¥æœŸ
        previous_predictions: ä¹‹å‰çš„é æ¸¬å€¼åˆ—è¡¨ [{date, prediction}, ...]

    è¿”å›:
        ç‰¹å¾µ DataFrame
    """
    df = df.copy()
    df['Date'] = pd.to_datetime(df['Date'])
    df = df.sort_values('Date').reset_index(drop=True)

    target_dt = pd.to_datetime(target_date_str)

    # å¦‚æœæœ‰ä¹‹å‰çš„é æ¸¬ï¼Œå°‡å®ƒå€‘æ·»åŠ åˆ°æ­·å²æ•¸æ“šä¸­
    if previous_predictions and len(previous_predictions) > 0:
        pred_rows = []
        for pred in previous_predictions:
            pred_rows.append({
                'Date': pd.to_datetime(pred['date']),
                'Attendance': pred['prediction']
            })
        pred_df = pd.DataFrame(pred_rows)
        df = pd.concat([df, pred_df], ignore_index=True)
        df = df.sort_values('Date').reset_index(drop=True)

    # æ™‚é–“ç‰¹å¾µ
    last_row = {}
    last_row['Date'] = target_dt
    last_row['Day_of_Week'] = target_dt.dayofweek
    last_row['Is_Weekend'] = 1 if target_dt.dayofweek >= 5 else 0
    last_row['DayOfWeek_sin'] = np.sin(2 * np.pi * target_dt.dayofweek / 7)
    last_row['DayOfWeek_cos'] = np.cos(2 * np.pi * target_dt.dayofweek / 7)

    # Lag ç‰¹å¾µï¼ˆä½¿ç”¨åˆä½µå¾Œçš„æ•¸æ“šï¼‰
    if len(df) >= 1:
        last_row['Attendance_Lag1'] = df.iloc[-1]['Attendance']
    else:
        last_row['Attendance_Lag1'] = 250

    if len(df) >= 7:
        last_row['Attendance_Lag7'] = df.iloc[-7]['Attendance']
    else:
        last_row['Attendance_Lag7'] = df['Attendance'].mean() if len(df) > 0 else 250

    # EWMAï¼ˆä½¿ç”¨åˆä½µå¾Œçš„æ•¸æ“šï¼‰
    if len(df) >= 1:
        series = df['Attendance']
        last_row['Attendance_EWMA7'] = series.ewm(span=7, adjust=False).mean().iloc[-1]
        last_row['Attendance_EWMA14'] = series.ewm(span=14, adjust=False).mean().iloc[-1]
    else:
        last_row['Attendance_EWMA7'] = 250
        last_row['Attendance_EWMA14'] = 250

    # è®ŠåŒ–ç‰¹å¾µ
    if len(df) >= 2:
        last_row['Daily_Change'] = df.iloc[-1]['Attendance'] - df.iloc[-2]['Attendance']
    else:
        last_row['Daily_Change'] = 0

    if len(df) >= 8:
        last_row['Weekly_Change'] = df.iloc[-1]['Attendance'] - df.iloc[-8]['Attendance']
    else:
        last_row['Weekly_Change'] = 0

    return pd.DataFrame([last_row], columns=OPT10_FEATURES)


def load_xgboost_model():
    """åŠ è¼‰ XGBoost æ¨¡å‹ï¼ˆå„ªå…ˆä½¿ç”¨ opt10 æ¨¡å‹ï¼‰v3.2.01"""
    try:
        import xgboost as xgb
        script_dir = os.path.dirname(os.path.abspath(__file__))
        models_dir = os.path.join(script_dir, 'models')

        # v3.2.01: å„ªå…ˆæª¢æŸ¥ opt10 æ¨¡å‹
        opt10_model_path = os.path.join(models_dir, 'xgboost_opt10_model.json')
        opt10_features_path = os.path.join(models_dir, 'xgboost_opt10_features.json')

        if os.path.exists(opt10_model_path) and os.path.exists(opt10_features_path):
            print(f"âœ… ä½¿ç”¨ opt10 æ¨¡å‹ (æœ€ä½³ 10 ç‰¹å¾µ)", file=sys.stderr)
            booster = xgb.Booster()
            booster.load_model(opt10_model_path)
            model = XGBoostWrapper(booster, model_type='opt10')

            with open(opt10_features_path, 'r') as f:
                feature_cols = json.load(f)

            return model, feature_cols, 'opt10'

        # å›é€€åˆ°æ¨™æº– XGBoost æ¨¡å‹
        model_path = os.path.join(models_dir, 'xgboost_model.json')
        if not os.path.exists(model_path):
            return None, None, None

        print(f"âš ï¸ ä½¿ç”¨èˆŠæ¨¡å‹ (å»ºè­°è¨“ç·´ opt10 æ¨¡å‹)", file=sys.stderr)
        booster = xgb.Booster()
        booster.load_model(model_path)
        model = XGBoostWrapper(booster, model_type='standard')

        features_path = os.path.join(models_dir, 'xgboost_features.json')
        with open(features_path, 'r') as f:
            feature_cols = json.load(f)

        return model, feature_cols, 'standard'
    except Exception as e:
        print(f"ç„¡æ³•åŠ è¼‰ XGBoost æ¨¡å‹: {e}", file=sys.stderr)
        return None, None, None


class XGBoostWrapper:
    """åŒ…è£ XGBoost Booster æä¾›é¡ä¼¼ sklearn çš„æ¥å£"""
    def __init__(self, booster, model_type='standard'):
        self.booster = booster
        self.model_type = model_type

    def predict(self, X):
        import xgboost as xgb
        if isinstance(X, pd.DataFrame):
            # æ˜ç¢ºæŒ‡å®š feature_names ä»¥é¿å…ç‰¹å¾µåç¨±ä¸åŒ¹é…å•é¡Œ
            feature_names = X.columns.tolist()
            dmatrix = xgb.DMatrix(X, feature_names=feature_names)
        else:
            dmatrix = xgb.DMatrix(X)
        return self.booster.predict(dmatrix)


def predict_with_xgboost(model, feature_cols, features_df):
    """ä½¿ç”¨ XGBoost é æ¸¬"""
    if model is None:
        return None
    X = features_df[feature_cols]
    prediction = model.predict(X)[0]
    return float(prediction)


def load_ai_factors_from_db():
    """å¾æ•¸æ“šåº«åŠ è¼‰ AI å› å­æ•¸æ“š"""
    try:
        from sqlalchemy import create_engine
        from dotenv import load_dotenv
        load_dotenv()

        database_url = os.getenv('DATABASE_URL')
        if database_url:
            if not database_url.startswith('postgresql://') and not database_url.startswith('postgres://'):
                database_url = database_url.replace('postgres://', 'postgresql://', 1)
            engine = create_engine(database_url)
        else:
            host = os.getenv('PGHOST', 'localhost')
            database = os.getenv('PGDATABASE', 'postgres')
            user = os.getenv('PGUSER', 'postgres')
            password = os.getenv('PGPASSWORD', '')
            port = os.getenv('PGPORT', '5432')
            connection_string = f"postgresql://{user}:{password}@{host}:{port}/{database}"
            engine = create_engine(connection_string)

        query = "SELECT factors_cache FROM ai_factors_cache WHERE id = 1"
        result = pd.read_sql_query(query, engine)
        engine.dispose()

        if len(result) > 0 and result.iloc[0]['factors_cache'] is not None:
            factors_cache = result.iloc[0]['factors_cache']
            if isinstance(factors_cache, str):
                factors_cache = json.loads(factors_cache)
            return factors_cache
        return {}
    except Exception as e:
        return {}


def ensemble_predict(target_date, historical_data):
    """
    XGBoost é æ¸¬ä¸»å‡½æ•¸ v3.2.01

    åƒæ•¸:
        target_date: ç›®æ¨™æ—¥æœŸ (YYYY-MM-DD)
        historical_data: DataFrameï¼ŒåŒ…å«æ­·å²æ•¸æ“šï¼ˆDate, Attendanceï¼‰

    è¿”å›:
        dict: {
            'prediction': XGBoost é æ¸¬å€¼,
            'model_type': 'opt10' æˆ– 'standard',
            'ci80': {'low': ..., 'high': ...},
            'ci95': {'low': ..., 'high': ...},
            'individual': {
                'xgboost': ...
            }
        }
    """
    # åŠ è¼‰æ¨¡å‹ï¼ˆå„ªå…ˆ opt10ï¼‰
    xgb_model, xgb_features, model_type = load_xgboost_model()

    if xgb_model is None:
        return None

    # æº–å‚™ç‰¹å¾µæ•¸æ“š
    if model_type == 'opt10':
        # ä½¿ç”¨ç°¡åŒ–çš„ 10 ç‰¹å¾µ
        features_df = prepare_opt10_features(historical_data, target_date)
    else:
        # ä½¿ç”¨å®Œæ•´ç‰¹å¾µï¼ˆèˆŠæ¨¡å‹ï¼‰
        from feature_engineering import create_comprehensive_features
        ai_factors = load_ai_factors_from_db()

        if historical_data is not None and len(historical_data) > 0:
            all_data = historical_data.copy()
            target_dt = pd.to_datetime(target_date)
            all_data = create_comprehensive_features(all_data, ai_factors_dict=ai_factors if ai_factors else None)

            if len(all_data) > 0:
                last_row = all_data.iloc[-1].copy()
                last_row['Date'] = target_dt
                last_row['Year'] = target_dt.year
                last_row['Month'] = target_dt.month
                last_row['Day_of_Week'] = target_dt.dayofweek
                last_row['Day_of_Month'] = target_dt.day
                last_row['Week_of_Year'] = target_dt.isocalendar().week
                last_row['Quarter'] = target_dt.quarter
                last_row['DayOfYear'] = target_dt.dayofyear
                last_row['Days_Since_Start'] = (target_dt - all_data['Date'].min()).days
                last_row['Month_sin'] = np.sin(2 * np.pi * target_dt.month / 12)
                last_row['Month_cos'] = np.cos(2 * np.pi * target_dt.month / 12)
                last_row['DayOfWeek_sin'] = np.sin(2 * np.pi * target_dt.dayofweek / 7)
                last_row['DayOfWeek_cos'] = np.cos(2 * np.pi * target_dt.dayofweek / 7)
                last_row['Is_COVID_Period'] = 0
                last_row['Is_Winter_Flu_Season'] = 1 if target_dt.month in [12, 1, 2, 3] else 0
                last_row['Is_Monday'] = 1 if target_dt.dayofweek == 0 else 0
                last_row['Is_Weekend'] = 1 if target_dt.dayofweek >= 5 else 0

                # AI å› å­
                if ai_factors and str(target_date) in ai_factors:
                    ai_data = ai_factors[str(target_date)]
                    if isinstance(ai_data, dict):
                        impact = max(0.7, min(1.3, ai_data.get('impactFactor', 1.0)))
                        last_row['AI_Impact_Factor'] = impact
                        last_row['AI_Impact_Magnitude'] = abs(impact - 1.0)
                        last_row['AI_Impact_Direction'] = 1 if impact > 1.02 else (-1 if impact < 0.98 else 0)
                        conf = ai_data.get('confidence', 'ä¸­').lower()
                        last_row['AI_Confidence_Score'] = 1.0 if 'é«˜' in conf or 'high' in conf else (0.3 if 'ä½' in conf or 'low' in conf else 0.6)
                        last_row['AI_Factor_Count'] = 1
                        last_row['Has_AI_Factor'] = 1
                    else:
                        set_default_ai(last_row)
                else:
                    set_default_ai(last_row)

                features_df = pd.DataFrame([last_row])
            else:
                features_df = None
        else:
            features_df = None

    if features_df is None:
        return None

    # XGBoost é æ¸¬
    xgb_pred = predict_with_xgboost(xgb_model, xgb_features, features_df)

    if xgb_pred is None:
        return None

    # è¨ˆç®—ç½®ä¿¡å€é–“
    std_preds = xgb_pred * 0.05
    ci80_low = xgb_pred - 1.28 * std_preds
    ci80_high = xgb_pred + 1.28 * std_preds
    ci95_low = xgb_pred - 1.96 * std_preds
    ci95_high = xgb_pred + 1.96 * std_preds

    return {
        'prediction': float(xgb_pred),
        'model_type': model_type,
        'ci80': {
            'low': float(ci80_low),
            'high': float(ci80_high)
        },
        'ci95': {
            'low': float(ci95_low),
            'high': float(ci95_high)
        },
        'individual': {
            'xgboost': xgb_pred
        }
    }


def set_default_ai(row):
    """è¨­ç½® AI å› å­é»˜èªå€¼"""
    row['AI_Impact_Factor'] = 1.0
    row['AI_Impact_Magnitude'] = 0.0
    row['AI_Impact_Direction'] = 0
    row['AI_Confidence_Score'] = 0.0
    row['AI_Factor_Count'] = 0
    row['AI_Type_Weather'] = 0
    row['AI_Type_Health'] = 0
    row['AI_Type_Policy'] = 0
    row['AI_Type_Event'] = 0
    row['AI_Type_Seasonal'] = 0
    row['Has_AI_Factor'] = 0
    row['AI_Impact_Rolling7'] = 1.0
    row['AI_Impact_Trend'] = 0.0


def rolling_forecast(start_date, days, historical_data):
    """
    æ»¾å‹•é æ¸¬ (v4.0.20) - ä¿®å¾©é€±æœŸæ€§å¾ªç’°å•é¡Œ

    æ¯å¤©çš„é æ¸¬ä½¿ç”¨å‰ä¸€å¤©çš„é æ¸¬å€¼ä¾†æ›´æ–° Lag å’Œ EWMA ç‰¹å¾µï¼Œ
    é¿å…æ‰€æœ‰æœªä¾†æ—¥æœŸä½¿ç”¨ç›¸åŒçš„ç‰¹å¾µå€¼ã€‚

    åƒæ•¸:
        start_date: é–‹å§‹æ—¥æœŸ (YYYY-MM-DD)
        days: é æ¸¬å¤©æ•¸
        historical_data: DataFrameï¼ŒåŒ…å«æ­·å²æ•¸æ“šï¼ˆDate, Attendanceï¼‰

    è¿”å›:
        list: [{date, prediction, ci80, ci95}, ...]
    """
    # åŠ è¼‰æ¨¡å‹
    xgb_model, xgb_features, model_type = load_xgboost_model()

    if xgb_model is None:
        return None

    # æº–å‚™æ­·å²æ•¸æ“š
    df = historical_data.copy()
    df['Date'] = pd.to_datetime(df['Date'])
    df = df.sort_values('Date').reset_index(drop=True)

    predictions = []
    previous_predictions = []

    start_dt = pd.to_datetime(start_date)

    for i in range(days):
        target_dt = start_dt + timedelta(days=i)
        target_date_str = target_dt.strftime('%Y-%m-%d')

        # ä½¿ç”¨æ»¾å‹•ç‰¹å¾µï¼ˆåŒ…å«ä¹‹å‰çš„é æ¸¬å€¼ï¼‰
        if model_type == 'opt10':
            features_df = prepare_rolling_features(df, target_date_str, previous_predictions)
        else:
            # èˆŠæ¨¡å‹ä½¿ç”¨åŸå§‹æ–¹æ³•
            features_df = prepare_opt10_features(df, target_date_str)

        if features_df is None:
            continue

        # XGBoost é æ¸¬
        try:
            xgb_pred = predict_with_xgboost(xgb_model, xgb_features, features_df)
        except Exception as e:
            print(f"âš ï¸ Day {i} é æ¸¬å¤±æ•—: {e}", file=sys.stderr)
            continue

        if xgb_pred is None:
            continue

        # è¨ˆç®—ç½®ä¿¡å€é–“ï¼ˆé æœŸé æ¸¬ä¸ç¢ºå®šæ€§å¢åŠ ï¼‰
        uncertainty_multiplier = 1.0 + i * 0.02  # æ¯å¤©å¢åŠ  2%
        std_preds = xgb_pred * 0.05 * uncertainty_multiplier

        result = {
            'date': target_date_str,
            'prediction': float(xgb_pred),
            'day_ahead': i,
            'ci80': {
                'low': float(xgb_pred - 1.28 * std_preds),
                'high': float(xgb_pred + 1.28 * std_preds)
            },
            'ci95': {
                'low': float(xgb_pred - 1.96 * std_preds),
                'high': float(xgb_pred + 1.96 * std_preds)
            }
        }

        predictions.append(result)

        # å°‡é€™å¤©çš„é æ¸¬æ·»åŠ åˆ°æ­·å²ä¸­ï¼Œä¾›ä¸‹ä¸€å¤©ä½¿ç”¨
        previous_predictions.append({
            'date': target_date_str,
            'prediction': xgb_pred
        })

        # æ¯ 7 å¤©è¼¸å‡ºä¸€æ¬¡é€²åº¦
        if (i + 1) % 7 == 0:
            print(f"ğŸ“Š å·²å®Œæˆ {i + 1}/{days} å¤©æ»¾å‹•é æ¸¬", file=sys.stderr)

    return predictions

def main():
    """å‘½ä»¤è¡Œæ¥å£ v4.0.20"""
    if len(sys.argv) < 2:
        print("ç”¨æ³•:", file=sys.stderr)
        print("  å–®æ—¥é æ¸¬: python ensemble_predict.py <target_date> [historical_data_path]", file=sys.stderr)
        print("  æ»¾å‹•é æ¸¬: python ensemble_predict.py --rolling <start_date> <days> [historical_data_path]", file=sys.stderr)
        sys.exit(1)

    # æª¢æŸ¥æ˜¯å¦ç‚ºæ»¾å‹•é æ¸¬æ¨¡å¼
    if sys.argv[1] == '--rolling':
        if len(sys.argv) < 4:
            print("æ»¾å‹•é æ¸¬ç”¨æ³•: python ensemble_predict.py --rolling <start_date> <days> [historical_data_path]", file=sys.stderr)
            sys.exit(1)

        start_date = sys.argv[2]
        days = int(sys.argv[3])

        # åŠ è¼‰æ­·å²æ•¸æ“š
        historical_data = None
        if len(sys.argv) >= 5:
            csv_path = sys.argv[4]
            if os.path.exists(csv_path):
                historical_data = pd.read_csv(csv_path)
                if 'Date' not in historical_data.columns and 'date' in historical_data.columns:
                    historical_data['Date'] = historical_data['date']
                if 'Attendance' not in historical_data.columns and 'patient_count' in historical_data.columns:
                    historical_data['Attendance'] = historical_data['patient_count']

        if historical_data is None:
            print("éŒ¯èª¤: æ»¾å‹•é æ¸¬éœ€è¦æ­·å²æ•¸æ“š", file=sys.stderr)
            sys.exit(1)

        print(f"ğŸ”„ é–‹å§‹ {days} å¤©æ»¾å‹•é æ¸¬ (å¾ {start_date})", file=sys.stderr)
        results = rolling_forecast(start_date, days, historical_data)

        if results:
            print(json.dumps({'predictions': results, 'model_type': 'opt10_rolling'}, indent=2))
        else:
            print("éŒ¯èª¤: æ»¾å‹•é æ¸¬å¤±æ•—", file=sys.stderr)
            sys.exit(1)
    else:
        # å–®æ—¥é æ¸¬æ¨¡å¼
        target_date = sys.argv[1]

        # å˜—è©¦å¾æ•¸æ“šåº«æˆ– CSV åŠ è¼‰æ­·å²æ•¸æ“š
        historical_data = None
        if len(sys.argv) >= 3:
            csv_path = sys.argv[2]
            if os.path.exists(csv_path):
                historical_data = pd.read_csv(csv_path)
                if 'Date' not in historical_data.columns:
                    if 'date' in historical_data.columns:
                        historical_data['Date'] = historical_data['date']
                if 'Attendance' not in historical_data.columns:
                    if 'patient_count' in historical_data.columns:
                        historical_data['Attendance'] = historical_data['patient_count']

        result = ensemble_predict(target_date, historical_data)

        if result:
            print(json.dumps(result, indent=2))
        else:
            print("éŒ¯èª¤: ç„¡æ³•ç”Ÿæˆé æ¸¬", file=sys.stderr)
            sys.exit(1)

if __name__ == '__main__':
    main()

