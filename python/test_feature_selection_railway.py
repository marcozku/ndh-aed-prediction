# -*- coding: utf-8 -*-
"""
ç‰¹å¾µé¸æ“‡æ¸¬è©¦ - Railway æ•¸æ“šåº«
"""
import sys
import io

if sys.platform == 'win32':
    try:
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
        sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')
    except:
        pass

import pandas as pd
import numpy as np
from datetime import datetime
import psycopg2
import psycopg2.extras
import json
import os
import warnings
warnings.filterwarnings('ignore')

# æ©Ÿå™¨å­¸ç¿’
from sklearn.ensemble import RandomForestRegressor
import xgboost as xgb
from sklearn.metrics import mean_absolute_error

# Railway æ•¸æ“šåº«é…ç½®
DB_CONFIG = {
    'host': 'postgres.railway.internal',
    'port': 5432,
    'user': 'postgres',
    'password': 'nIdJPREHqkBdMgUifrazOsVlWbxsmDGq',
    'database': 'railway'
}

# COVID æœŸé–“
COVID_PERIODS = [
    ('2020-01-23', '2020-04-08'),
    ('2020-07-16', '2020-09-30'),
    ('2020-11-23', '2021-01-05'),
    ('2022-02-05', '2022-04-30'),
    ('2022-11-10', '2022-12-27'),
]


def load_data_from_railway():
    """å¾ Railway åŠ è¼‰æ•¸æ“š"""
    try:
        print("ğŸ“¡ é€£æ¥ Railway æ•¸æ“šåº«...")

        # é€£æ¥ï¼ˆRailway å…§éƒ¨ç¶²çµ¡ä¸éœ€è¦ SSLï¼‰
        conn = psycopg2.connect(
            host=DB_CONFIG['host'],
            port=DB_CONFIG['port'],
            user=DB_CONFIG['user'],
            password=DB_CONFIG['password'],
            database=DB_CONFIG['database'],
            connect_timeout=10
        )
        cursor = conn.cursor(cursor_factory=psycopg2.extras.RealDictCursor)

        query = "SELECT date, patient_count FROM actual_data ORDER BY date ASC"
        cursor.execute(query)
        rows = cursor.fetchall()

        cursor.close()
        conn.close()

        df = pd.DataFrame(rows)
        df['date'] = pd.to_datetime(df['date'])

        # æ’é™¤ COVID æœŸé–“
        for start, end in COVID_PERIODS:
            start_date = pd.to_datetime(start)
            end_date = pd.to_datetime(end)
            mask = (df['date'] >= start_date) & (df['date'] <= end_date)
            df = df[~mask]

        print(f"   âœ… åŠ è¼‰ {len(df)} ç­†è¨˜éŒ„")
        print(f"   ğŸ“… ç¯„åœ: {df['date'].min()} â†’ {df['date'].max()}")

        return df

    except Exception as e:
        print(f"   âŒ éŒ¯èª¤: {e}")
        return None


def prepare_features(df):
    """æº–å‚™åŸºç¤ç‰¹å¾µ"""
    print("\nğŸ“Š æº–å‚™ç‰¹å¾µ...")

    df = df.rename(columns={'date': 'Date'})

    # æ™‚é–“ç‰¹å¾µ
    df['Day_of_Week'] = df['Date'].dt.dayofweek
    df['Month'] = df['Date'].dt.month
    df['Day_of_Month'] = df['Date'].dt.day
    df['Is_Weekend'] = (df['Day_of_Week'] >= 5).astype(int)

    # é€±æœŸç·¨ç¢¼
    df['DayOfWeek_sin'] = np.sin(2 * np.pi * df['Day_of_Week'] / 7)
    df['DayOfWeek_cos'] = np.cos(2 * np.pi * df['Day_of_Week'] / 7)

    # å­£ç¯€æ€§
    df['Is_Winter_Flu_Season'] = df['Month'].isin([1, 2]).astype(int)
    df['Holiday_Factor'] = 1.0

    # æ­·å²å°±è¨º
    df = df.sort_values('Date').reset_index(drop=True)

    df['Attendance_Lag1'] = df['patient_count'].shift(1)
    df['Attendance_Lag7'] = df['patient_count'].shift(7)
    df['Attendance_Lag30'] = df['patient_count'].shift(30)

    df['Attendance_EWMA7'] = df['patient_count'].ewm(span=7, adjust=False).mean()
    df['Attendance_EWMA14'] = df['patient_count'].ewm(span=14, adjust=False).mean()

    df['Daily_Change'] = df['patient_count'].diff()
    df['Weekly_Change'] = df['patient_count'].diff(7)

    # å¡«è£œ
    df['Attendance_Lag1'] = df['Attendance_Lag1'].fillna(df['patient_count'].mean())
    df['Attendance_Lag7'] = df['Attendance_Lag7'].fillna(df['patient_count'].mean())
    df['Attendance_Lag30'] = df['Attendance_Lag30'].fillna(df['patient_count'].mean())
    df['Attendance_EWMA7'] = df['Attendance_EWMA7'].fillna(method='bfill')
    df['Attendance_EWMA14'] = df['Attendance_EWMA14'].fillna(method='bfill')
    df['Daily_Change'] = df['Daily_Change'].fillna(0)
    df['Weekly_Change'] = df['Weekly_Change'].fillna(0)

    # ç§»é™¤ NaN
    df = df.dropna()

    print(f"   âœ… ç‰¹å¾µæº–å‚™å®Œæˆ: {len(df)} ç­†")
    return df


def test_feature_counts(X_train, y_train, X_test, y_test, feature_names):
    """æ¸¬è©¦ä¸åŒç‰¹å¾µæ•¸é‡"""
    print("\n" + "=" * 80)
    print("ğŸ” ç‰¹å¾µé¸æ“‡æ¸¬è©¦")
    print("=" * 80)

    # è¨“ç·´æ¨¡å‹ç²å–é‡è¦æ€§
    print("\n1ï¸âƒ£ è¨“ç·´ XGBoost ç²å–ç‰¹å¾µé‡è¦æ€§...")
    model = xgb.XGBRegressor(
        n_estimators=300,
        max_depth=6,
        learning_rate=0.05,
        random_state=42,
        n_jobs=-1
    )
    model.fit(X_train, y_train, verbose=False)

    # ç‰¹å¾µé‡è¦æ€§
    importances = model.feature_importances_
    indices = np.argsort(importances)[::-1]

    print("\n   Top 15 ç‰¹å¾µ:")
    print(f"   {'æ’å':<4} {'ç‰¹å¾µ':<35} {'é‡è¦æ€§':<10}")
    print("   " + "-" * 60)

    for i, idx in enumerate(indices[:15], 1):
        feature = feature_names[idx]
        importance = importances[idx]
        print(f"   {i:<4} {feature:<35} {importance:.4f}")

    # æ¸¬è©¦ä¸åŒç‰¹å¾µæ•¸é‡
    print("\n2ï¸âƒ£ æ¸¬è©¦ä¸åŒç‰¹å¾µæ•¸é‡...")
    print(f"   {'ç‰¹å¾µæ•¸':<10} {'MAE':<10} {'æ”¹å–„ %':<10} {'ç‹€æ…‹':<5}")
    print("   " + "-" * 45)

    baseline_mae = 15.73
    results = []
    feature_counts = [5, 10, 15] + list(range(20, min(len(feature_names) + 1, 81), 10))

    for n_features in feature_counts:
        if n_features > len(feature_names):
            n_features = len(feature_names)

        # é¸æ“‡ top n_features
        selected_indices = indices[:n_features]
        X_train_selected = X_train.iloc[:, selected_indices]
        X_test_selected = X_test.iloc[:, selected_indices]

        # è¨“ç·´
        model_selected = xgb.XGBRegressor(
            n_estimators=300,
            max_depth=6,
            learning_rate=0.05,
            random_state=42,
            n_jobs=-1
        )
        model_selected.fit(X_train_selected, y_train, verbose=False)

        # è©•ä¼°
        y_pred = model_selected.predict(X_test_selected)
        mae = mean_absolute_error(y_test, y_pred)
        improvement = ((baseline_mae - mae) / baseline_mae * 100)

        results.append({
            'n_features': n_features,
            'mae': mae,
            'improvement': improvement
        })

        status = "âœ…" if mae < baseline_mae else "âŒ"
        print(f"   {n_features:<10} {mae:<10.2f} {improvement:>+6.1f}%   {status}")

    # æ‰¾å‡ºæœ€ä½³
    best = min(results, key=lambda x: x['mae'])

    print("\n" + "=" * 80)
    print("ğŸ† æ¸¬è©¦çµæœ")
    print("=" * 80)
    print(f"\nåŸºæº– (èˆŠæ¨¡å‹): MAE = {baseline_mae}")
    print(f"æœ€ä½³ç‰¹å¾µæ•¸é‡: {best['n_features']} å€‹")
    print(f"æœ€ä½³ MAE: {best['mae']:.2f}")
    print(f"æ”¹å–„: {best['improvement']:+.1f}%")

    # åˆ†æ
    if best['n_features'] < len(feature_names) * 0.5:
        print(f"\nâœ… é‡è¦ç™¼ç¾:")
        print(f"   ç‰¹å¾µæ•¸é‡å¯ä»¥å¾ {len(feature_names)} æ¸›å°‘åˆ° {best['n_features']}")
        print(f"   æ¸›å°‘ {len(feature_names) - best['n_features']} å€‹ç‰¹å¾µ ({(1 - best['n_features']/len(feature_names))*100:.1f}%)")
        print(f"   åŒæ™‚æ”¹å–„æº–ç¢ºåº¦ï¼")
    elif best['n_features'] < len(feature_names) * 0.8:
        print(f"\nâš ï¸ ç™¼ç¾:")
        print(f"   å»ºè­°ä½¿ç”¨ {best['n_features']} å€‹ç‰¹å¾µ")
        print(f"   ç§»é™¤ {len(feature_names) - best['n_features']} å€‹è¼ƒä¸é‡è¦çš„ç‰¹å¾µ")
    else:
        print(f"\nâœ… çµè«–:")
        print(f"   å¤§éƒ¨åˆ†ç‰¹å¾µéƒ½æœ‰ç”¨")
        print(f"   å»ºè­°ä¿ç•™ {best['n_features']} å€‹ç‰¹å¾µ")

    return results, best, indices, importances


def main():
    """ä¸»æ¸¬è©¦æµç¨‹"""
    print("=" * 80)
    print("ğŸ¯ ç‰¹å¾µé¸æ“‡æ¸¬è©¦ (Railway æ•¸æ“šåº«)")
    print("=" * 80)
    print(f"æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")

    # 1. åŠ è¼‰æ•¸æ“š
    df = load_data_from_railway()
    if df is None:
        return

    # 2. æº–å‚™ç‰¹å¾µ
    df = prepare_features(df)

    # 3. ç‰¹å¾µåˆ—è¡¨
    feature_names = [
        'Day_of_Week', 'Month', 'Day_of_Month', 'Is_Weekend',
        'Holiday_Factor', 'Is_Winter_Flu_Season',
        'DayOfWeek_sin', 'DayOfWeek_cos',
        'Attendance_Lag1', 'Attendance_Lag7', 'Attendance_Lag30',
        'Attendance_EWMA7', 'Attendance_EWMA14',
        'Daily_Change', 'Weekly_Change'
    ]

    feature_names = [f for f in feature_names if f in df.columns]
    print(f"\nğŸ“‹ ç‰¹å¾µæ•¸é‡: {len(feature_names)}")

    # 4. åˆ†å‰²æ•¸æ“š
    print("\nâœ‚ï¸ åˆ†å‰²æ•¸æ“š...")
    train_size = int(len(df) * 0.8)

    train_df = df.iloc[:train_size]
    test_df = df.iloc[train_size:]

    X_train = train_df[feature_names]
    y_train = train_df['patient_count']
    X_test = test_df[feature_names]
    y_test = test_df['patient_count']

    print(f"   è¨“ç·´é›†: {len(X_train)} ç­†")
    print(f"   æ¸¬è©¦é›†: {len(X_test)} ç­†")
    print(f"   æ¸¬è©¦ç¯„åœ: {test_df['Date'].min()} â†’ {test_df['Date'].max()}")

    # 5. æ¸¬è©¦
    results, best, indices, importances = test_feature_counts(
        X_train, y_train, X_test, y_test, feature_names
    )

    # 6. ä¿å­˜çµæœ
    output = {
        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'baseline_mae': 15.73,
        'total_features': len(feature_names),
        'best_n_features': best['n_features'],
        'best_mae': best['mae'],
        'improvement_pct': best['improvement'],
        'feature_importance': {
            feature_names[i]: float(importances[i]) for i in range(len(feature_names))
        },
        'test_results': results
    }

    os.makedirs('models', exist_ok=True)
    with open('models/feature_selection_results.json', 'w', encoding='utf-8') as f:
        json.dump(output, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ’¾ çµæœå·²ä¿å­˜åˆ° models/feature_selection_results.json")

    # æ¨è–¦
    print("\n" + "=" * 80)
    print("ğŸ’¡ æ¨è–¦")
    print("=" * 80)
    print(f"\nä½¿ç”¨é€™ {best['n_features']} å€‹æœ€é‡è¦ç‰¹å¾µä¾†è¨“ç·´æœ€çµ‚æ¨¡å‹:")
    for i in range(best['n_features']):
        idx = indices[i]
        print(f"   {i+1}. {feature_names[idx]}")

    print("\n" + "=" * 80)
    print("âœ… æ¸¬è©¦å®Œæˆ")
    print("=" * 80)


if __name__ == '__main__':
    main()
