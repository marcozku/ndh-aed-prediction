# è‡ªå‹•å­¸ç¿’ç³»çµ±è¨­è¨ˆæ–‡æª”
## Continuous Learning System Design

> **ç‰ˆæœ¬**: 4.0.00
> **æ—¥æœŸ**: 2026-01-18
> **ä½œè€…**: Ma Tsz Kiu

---

## ç›®éŒ„

1. [ç³»çµ±æ¦‚è¿°](#ç³»çµ±æ¦‚è¿°)
2. [æ¶æ§‹è¨­è¨ˆ](#æ¶æ§‹è¨­è¨ˆ)
3. [æ•¸æ“šåº« Schema](#æ•¸æ“šåº«-schema)
4. [Phase 1: è‡ªå‹•è¨˜éŒ„ç³»çµ±](#phase-1-è‡ªå‹•è¨˜éŒ„ç³»çµ±)
5. [Phase 2: ç•°å¸¸æª¢æ¸¬èˆ‡ Flag æ©Ÿåˆ¶](#phase-2-ç•°å¸¸æª¢æ¸¬èˆ‡-flag-æ©Ÿåˆ¶)
6. [Phase 3: å­¸ç¿’è¿´æ­¸æ¨¡å‹](#phase-3-å­¸ç¿’è¿´æ­¸æ¨¡å‹)
7. [Phase 4: é æ¸¬æ•´åˆ](#phase-4-é æ¸¬æ•´åˆ)
8. [API è¨­è¨ˆ](#api-è¨­è¨ˆ)
9. [éƒ¨ç½²ç­–ç•¥](#éƒ¨ç½²ç­–ç•¥)
10. [ç›£æ§èˆ‡è­¦å ±](#ç›£æ§èˆ‡è­¦å ±)

---

## ç³»çµ±æ¦‚è¿°

### ç›®æ¨™

å»ºç«‹ä¸€å€‹ **æŒçºŒå­¸ç¿’ç³»çµ±**ï¼Œè‡ªå‹•å¾çœŸå¯¦æ•¸æ“šä¸­å­¸ç¿’ï¼š

1. **å¤©æ°£å› ç´ å½±éŸ¿** - è‡ªå‹•è¨ˆç®—ä¸åŒå¤©æ°£æ¢ä»¶å° attendance çš„å½±éŸ¿
2. **AI å› ç´ å½±éŸ¿** - é©—è­‰ AI ç”Ÿæˆçš„å› ç´ æ˜¯å¦æœ‰æ•ˆ
3. **å¤©æ°£é å ±æ•´åˆ** - ç”¨æœªä¾†å¤©æ°£é æ¸¬èª¿æ•´é æ¸¬å€¼

### ç•¶å‰ç‹€æ…‹

| çµ„ä»¶ | ç‹€æ…‹ | æè¿° |
|------|------|------|
| XGBoost æ¨¡å‹ | âœ… é‹è¡Œä¸­ | MAE: 2.85, ä½¿ç”¨æœ€ä½³ 10 ç‰¹å¾µ |
| å¤©æ°£å½±éŸ¿åˆ†æ | âœ… éœæ…‹ | `weather_impact_analysis.json` (å¯’æ½® -6.8%) |
| AI å› å­é©—è­‰ | âœ… é›™è»Œé“ | `dual_track_predictions.sql` å·²éƒ¨ç½² |
| å¤©æ°£é å ±æ•´åˆ | ğŸš§ å¾…å¯¦ç¾ | `weather_forecast_integration.py` å­˜åœ¨ä½†æœªæ•´åˆ |
| æŒçºŒå­¸ç¿’ | âŒ æœªå¯¦ç¾ | **æœ¬è¨­è¨ˆçš„ç›®æ¨™** |

### å­¸ç¿’å¾ªç’°

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     è‡ªå‹•å­¸ç¿’å¾ªç’° (æ¯æ—¥åŸ·è¡Œ)                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚  1. ç²å–æ–°   â”‚ -> â”‚  2. è¨ˆç®—    â”‚ -> â”‚  3. æª¢æ¸¬    â”‚          â”‚
â”‚  â”‚     å¯¦éš›æ•¸æ“š â”‚    â”‚     Gap    â”‚    â”‚   ç•°å¸¸      â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚         â”‚                   â”‚                   â”‚                â”‚
â”‚         â–¼                   â–¼                   â–¼                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚  4. åˆ†æ    â”‚ <- â”‚  5. æ¨™è¨˜    â”‚ <- â”‚  6. è¨˜éŒ„    â”‚          â”‚
â”‚  â”‚   å¤©æ°£/AI  â”‚    â”‚   é¡ä¼¼æ—¥   â”‚    â”‚   åˆ°DB     â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚         â”‚                                                   â”‚     â”‚
â”‚         â–¼                                                   â”‚     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                            â”‚     â”‚
â”‚  â”‚  7. æ›´æ–°    â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚  â”‚  å½±éŸ¿åƒæ•¸   â”‚                                                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                  â”‚
â”‚         â”‚                                                         â”‚
â”‚         â–¼                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                  â”‚
â”‚  â”‚  8. é‡æ–°è¨“ç·´ â”‚ â”€â”€â”€ (å¯é¸ï¼Œæ¯30å¤©)                              â”‚
â”‚  â”‚   XGBoost   â”‚                                                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                  â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## æ¶æ§‹è¨­è¨ˆ

### ç³»çµ±çµ„ä»¶åœ–

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          Railway Production                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Node.js     â”‚         â”‚  PostgreSQL  â”‚         â”‚  Python      â”‚ â”‚
â”‚  â”‚  Backend     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  Database    â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”‚  Learning    â”‚ â”‚
â”‚  â”‚              â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”‚              â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  Engine      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚         â”‚                         â”‚                         â”‚        â”‚
â”‚         â”‚ API                     â”‚                         â”‚        â”‚
â”‚         â–¼                         â–¼                         â–¼        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚  Frontend    â”‚         â”‚  Tables:     â”‚         â”‚  Scripts:    â”‚â”‚
â”‚  â”‚  Dashboard   â”‚         â”‚  - actual_   â”‚         â”‚  - weather_  â”‚â”‚
â”‚  â”‚              â”‚         â”‚    data      â”‚         â”‚    learner.pyâ”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚  - daily_    â”‚         â”‚  - ai_       â”‚â”‚
â”‚                           â”‚    predictionsâ”‚         â”‚    learner.pyâ”‚â”‚
â”‚                           â”‚  - learning_  â”‚         â”‚  - forecast_ â”‚â”‚
â”‚                           â”‚    records    â”‚         â”‚    predictor.pyâ”‚
â”‚                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â–²
                              â”‚ å¤–éƒ¨æ•¸æ“šæº
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚  HKO Weather â”‚         â”‚  HKO 9-Day   â”‚         â”‚  AI Service  â”‚â”‚
â”‚  â”‚  API         â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  Forecast    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  (OpenAI)    â”‚â”‚
â”‚  â”‚  (æ­·å²æ•¸æ“š)  â”‚         â”‚  (é å ±æ•¸æ“š)  â”‚         â”‚              â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ•¸æ“šæµåœ–

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         æ¯æ—¥è‡ªå‹•å­¸ç¿’æµç¨‹                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                        â”‚
â”‚  00:00 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚
â”‚    â”‚                                                                   â”‚
â”‚    â”œâ”€ Cron Job è§¸ç™¼                                                   â”‚
â”‚    â”‚                                                                   â”‚
â”‚    â–¼                                                                   â”‚
â”‚  00:05 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚
â”‚    â”‚                                                                   â”‚
â”‚    â”œâ”€ 1. ç²å–æ˜¨æ—¥å¯¦éš› attendance                                       â”‚
â”‚    â”‚   å¾ actual_data è¡¨                                               â”‚
â”‚    â”‚                                                                   â”‚
â”‚    â”œâ”€ 2. ç²å–æ˜¨æ—¥é æ¸¬å€¼                                               â”‚
â”‚    â”‚   å¾ daily_predictions è¡¨                                         â”‚
â”‚    â”‚                                                                   â”‚
â”‚    â”œâ”€ 3. è¨ˆç®—é æ¸¬èª¤å·®                                                 â”‚
â”‚    â”‚   gap = actual - predicted                                       â”‚
â”‚    â”‚                                                                   â”‚
â”‚    â–¼                                                                   â”‚
â”‚  00:10 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚
â”‚    â”‚                                                                   â”‚
â”‚    â”œâ”€ 4. ç²å–æ˜¨æ—¥å¤©æ°£æ•¸æ“š                                             â”‚
â”‚    â”‚   å¾ weather_history è¡¨ æˆ– HKO API                                â”‚
â”‚    â”‚                                                                   â”‚
â”‚    â”œâ”€ 5. ç²å–æ˜¨æ—¥ AI factor                                           â”‚
â”‚    â”‚   å¾ ai_factor_validation è¡¨                                      â”‚
â”‚    â”‚                                                                   â”‚
â”‚    â”œâ”€ 6. æª¢æ¸¬ç•°å¸¸æ¢ä»¶                                                 â”‚
â”‚    â”‚   if |gap| > threshold (e.g., 15)                                â”‚
â”‚    â”‚       flag as anomaly                                            â”‚
â”‚    â”‚                                                                   â”‚
â”‚    â–¼                                                                   â”‚
â”‚  00:15 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚
â”‚    â”‚                                                                   â”‚
â”‚    â”œâ”€ 7. æ›´æ–°å¤©æ°£å½±éŸ¿åƒæ•¸                                             â”‚
â”‚    â”‚   åŸºæ–¼ç•¶å¤©æ¢ä»¶ + gap                                             â”‚
â”‚    â”‚                                                                   â”‚
â”‚    â”œâ”€ 8. æ›´æ–° AI å› ç´ é©—è­‰                                             â”‚
â”‚    â”‚   è¨˜éŒ„ AI é æ¸¬æ˜¯å¦æ­£ç¢º                                           â”‚
â”‚    â”‚                                                                   â”‚
â”‚    â”œâ”€ 9. ä¿å­˜å­¸ç¿’è¨˜éŒ„                                                 â”‚
â”‚    â”‚   åˆ° learning_records è¡¨                                         â”‚
â”‚    â”‚                                                                   â”‚
â”‚    â–¼                                                                   â”‚
â”‚  00:20 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚
â”‚    â”‚                                                                   â”‚
â”‚    â”œâ”€ 10. æª¢æŸ¥æ˜¯å¦éœ€è¦é‡æ–°è¨“ç·´                                        â”‚
â”‚    â”‚    if (æ–°æ¨£æœ¬æ•¸ >= 30) AND (ä¸Šæ¬¡è¨“ç·´ > 30å¤©)                      â”‚
â”‚    â”‚        è§¸ç™¼ XGBoost é‡æ–°è¨“ç·´                                      â”‚
â”‚    â”‚                                                                   â”‚
â”‚    â”œâ”€ 11. æª¢æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°æ¬Šé‡                                        â”‚
â”‚    â”‚    if (é©—è­‰æ¨£æœ¬ >= 30)                                           â”‚
â”‚    â”‚        é‹è¡Œæ¬Šé‡å„ªåŒ–è…³æœ¬                                           â”‚
â”‚    â”‚                                                                   â”‚
â”‚    â–¼                                                                   â”‚
â”‚  00:25 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚
â”‚    â”‚                                                                   â”‚
â”‚    â””â”€ å®Œæˆï¼Œç­‰å¾…æ˜å¤©                                                   â”‚
â”‚                                                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## æ•¸æ“šåº« Schema

### æ–°å¢è¡¨æ ¼

```sql
-- ============================================================
-- Migration 004: Continuous Learning System
-- è‡ªå‹•å­¸ç¿’ç³»çµ±æ•¸æ“šåº«çµæ§‹
-- ============================================================

-- 1. å¤©æ°£æ­·å²æ•¸æ“šè¡¨ (ç”¨æ–¼å¿«é€ŸæŸ¥è©¢)
CREATE TABLE IF NOT EXISTS weather_history (
    date DATE PRIMARY KEY,
    temp_min NUMERIC(5,2),
    temp_max NUMERIC(5,2),
    temp_mean NUMERIC(5,2),
    humidity_pct NUMERIC(5,2),
    rainfall_mm NUMERIC(6,2),
    wind_kmh NUMERIC(5,2),
    pressure_hpa NUMERIC(7,2),
    visibility_km NUMERIC(5,2),
    cloud_pct NUMERIC(5,2),
    sunshine_hrs NUMERIC(4,2),
    dew_point NUMERIC(5,2),

    -- å¤©æ°£è­¦å‘Š
    typhoon_signal VARCHAR(10),      -- T1, T3, T8, T8NE, T8NW, T8SE, T8SW, T9, T10
    rainstorm_warning VARCHAR(20),   -- AMBER, RED, BLACK
    cold_warning BOOLEAN,
    hot_warning BOOLEAN,

    -- æ¥µç«¯æ¢ä»¶æ¨™è¨˜ (è¨ˆç®—æ¬„ä½)
    is_very_cold BOOLEAN,            -- temp_min <= 12
    is_very_hot BOOLEAN,             -- temp_max >= 33
    is_heavy_rain BOOLEAN,           -- rainfall_mm > 25
    is_strong_wind BOOLEAN,          -- wind_kmh > 30
    is_low_humidity BOOLEAN,         -- humidity_pct < 50
    is_high_pressure BOOLEAN,        -- pressure_hpa > 1020

    data_fetch_time TIMESTAMP DEFAULT NOW()
);

-- 2. å­¸ç¿’è¨˜éŒ„è¡¨ (æ ¸å¿ƒå­¸ç¿’æ•¸æ“š)
CREATE TABLE IF NOT EXISTS learning_records (
    id SERIAL PRIMARY KEY,
    date DATE NOT NULL UNIQUE,

    -- é æ¸¬ vs å¯¦éš›
    xgboost_base_pred NUMERIC(10,2),
    final_prediction NUMERIC(10,2),
    actual_attendance NUMERIC(10,2),
    prediction_error NUMERIC(10,2),
    error_pct NUMERIC(6,2),

    -- å¤©æ°£æ¢ä»¶
    temp_min NUMERIC(5,2),
    temp_max NUMERIC(5,2),
    rainfall_mm NUMERIC(6,2),
    wind_kmh NUMERIC(5,2),
    humidity_pct NUMERIC(5,2),
    pressure_hpa NUMERIC(7,2),

    -- æ¥µç«¯å¤©æ°£æ¨™è¨˜
    is_very_cold BOOLEAN,
    is_very_hot BOOLEAN,
    is_heavy_rain BOOLEAN,
    is_strong_wind BOOLEAN,
    typhoon_signal VARCHAR(10),

    -- AI å› ç´ 
    ai_factor NUMERIC(5,3),
    ai_event_type VARCHAR(100),
    ai_description TEXT,

    -- å­¸ç¿’çµæœ
    weather_impact_learned NUMERIC(6,3),     -- å­¸ç¿’åˆ°çš„å¤©æ°£å½±éŸ¿
    ai_impact_learned NUMERIC(6,3),          -- å­¸ç¿’åˆ°çš„ AI å½±éŸ¿
    is_anomaly BOOLEAN,                      -- æ˜¯å¦ç‚ºç•°å¸¸å€¼
    anomaly_reason TEXT,                     -- ç•°å¸¸åŸå› 

    -- å…ƒæ•¸æ“š
    created_at TIMESTAMP DEFAULT NOW(),
    processed BOOLEAN DEFAULT FALSE          -- æ˜¯å¦å·²è¢«å­¸ç¿’æ¨¡å‹è™•ç†
);

-- 3. å¤©æ°£å½±éŸ¿åƒæ•¸è¡¨ (å‹•æ…‹æ›´æ–°)
CREATE TABLE IF NOT EXISTS weather_impact_parameters (
    id SERIAL PRIMARY KEY,
    parameter_name VARCHAR(50) NOT NULL,
    parameter_value NUMERIC(8,4) NOT NULL,
    sample_count INTEGER NOT NULL,
    confidence_interval_lower NUMERIC(8,4),
    confidence_interval_upper NUMERIC(8,4),
    p_value NUMERIC(8,6),
    last_updated TIMESTAMP DEFAULT NOW(),
    is_active BOOLEAN DEFAULT TRUE,
    UNIQUE(parameter_name)
);

-- 4. å¤©æ°£æ¢ä»¶çµ„åˆå½±éŸ¿è¡¨
CREATE TABLE IF NOT EXISTS weather_combination_impacts (
    id SERIAL PRIMARY KEY,

    -- æ¢ä»¶çµ„åˆ (JSON æ ¼å¼)
    -- ä¾‹: {"is_very_cold": true, "is_heavy_rain": true}
    conditions_json JSONB NOT NULL,

    -- çµ±è¨ˆæ•¸æ“š
    sample_count INTEGER NOT NULL,
    mean_attendance NUMERIC(10,2),
    std_attendance NUMERIC(10,2),
    baseline_mean NUMERIC(10,2),
    impact_factor NUMERIC(6,3),           -- å¹³å‡ attendance / baseline
    impact_absolute NUMERIC(8,2),         -- mean - baseline

    -- çµ±è¨ˆé¡¯è‘—æ€§
    t_statistic NUMERIC(8,4),
    p_value NUMERIC(8,6),
    is_significant BOOLEAN DEFAULT FALSE,

    last_seen DATE,
    last_updated TIMESTAMP DEFAULT NOW(),

    -- å”¯ä¸€ç´„æŸ: ç›¸åŒæ¢ä»¶çµ„åˆ
    UNIQUE(conditions_json)
);

-- 5. AI äº‹ä»¶å­¸ç¿’è¡¨
CREATE TABLE IF NOT EXISTS ai_event_learning (
    id SERIAL PRIMARY KEY,

    -- äº‹ä»¶åˆ†é¡
    event_type VARCHAR(100) NOT NULL,
    event_pattern VARCHAR(200),           -- äº‹ä»¶æ¨¡å¼ (å¦‚ "marathon", "holiday")

    -- çµ±è¨ˆæ•¸æ“š
    total_occurrences INTEGER NOT NULL,
    avg_ai_factor NUMERIC(6,3),
    avg_actual_impact NUMERIC(8,2),      -- å¯¦éš›å¹³å‡å½±éŸ¿ (äººæ•¸)
    avg_actual_impact_pct NUMERIC(6,3),  -- å¯¦éš›å¹³å‡å½±éŸ¿ (%)

    -- é æ¸¬æº–ç¢ºæ€§
    correct_predictions INTEGER,          -- AI æ–¹å‘æ­£ç¢ºçš„æ¬¡æ•¸
    prediction_accuracy NUMERIC(5,3),     -- æ­£ç¢ºç‡

    -- ä¿¡åº¦
    confidence_level VARCHAR(20),         -- 'high', 'medium', 'low'
    min_sample_threshold INTEGER DEFAULT 10,

    last_occurrence DATE,
    last_updated TIMESTAMP DEFAULT NOW(),

    UNIQUE(event_type, event_pattern)
);

-- 6. å¤©æ°£é å ±ç·©å­˜è¡¨
CREATE TABLE IF NOT EXISTS weather_forecast_cache (
    id SERIAL PRIMARY KEY,
    forecast_date DATE NOT NULL,
    fetch_date TIMESTAMP DEFAULT NOW(),

    -- é å ±æ•¸æ“š (ä¾†è‡ª HKO 9-Day Forecast)
    temp_min_forecast NUMERIC(5,2),
    temp_max_forecast NUMERIC(5,2),
    rain_prob_forecast VARCHAR(20),       -- Low, Medium, High, Very High
    weather_desc TEXT,

    -- é æ¸¬çš„å¤©æ°£å½±éŸ¿
    predicted_impact_factor NUMERIC(6,3),
    predicted_impact_absolute NUMERIC(8,2),
    confidence_level VARCHAR(20),

    -- é©—è­‰ (ä¹‹å¾Œæ›´æ–°)
    actual_temp_min NUMERIC(5,2),
    actual_temp_max NUMERIC(5,2),
    forecast_error_temp NUMERIC(5,2),
    forecast_accuracy BOOLEAN,

    UNIQUE(forecast_date, fetch_date)
);

-- 7. ç•°å¸¸äº‹ä»¶æ—¥èªŒ
CREATE TABLE IF NOT EXISTS anomaly_events (
    id SERIAL PRIMARY KEY,
    date DATE NOT NULL,
    anomaly_type VARCHAR(50) NOT NULL,    -- 'weather', 'ai', 'unknown'

    -- ç•°å¸¸è©³æƒ…
    prediction_error NUMERIC(10,2),
    error_std_deviations NUMERIC(6,2),   -- èª¤å·®æ˜¯æ¨™æº–å·®çš„å¹¾å€

    -- ç•¶æ—¥æ¢ä»¶
    conditions_json JSONB,

    -- è™•ç†ç‹€æ…‹
    is_explained BOOLEAN DEFAULT FALSE,
    explanation TEXT,
    requires_review BOOLEAN DEFAULT TRUE,

    -- å¾ŒçºŒè¿½è¹¤
    similar_event_count INTEGER,          -- é¡ä¼¼äº‹ä»¶ç™¼ç”Ÿæ¬¡æ•¸
    next_similar_date DATE,

    created_at TIMESTAMP DEFAULT NOW(),
    resolved_at TIMESTAMP
);

-- ç´¢å¼•å„ªåŒ–
CREATE INDEX IF NOT EXISTS idx_learning_records_date ON learning_records(date DESC);
CREATE INDEX IF NOT EXISTS idx_learning_records_anomaly ON learning_records(is_anomaly, date DESC);
CREATE INDEX IF NOT EXISTS idx_weather_history_date ON weather_history(date DESC);
CREATE INDEX IF NOT EXISTS idx_weather_conditions ON weather_history(is_very_cold, is_very_hot, is_heavy_rain);
CREATE INDEX IF NOT EXISTS idx_weather_combo_conditions ON weather_combination_impacts USING GIN(conditions_json);
CREATE INDEX IF NOT EXISTS idx_ai_event_pattern ON ai_event_learning(event_type, event_pattern);
CREATE INDEX IF NOT EXISTS idx_forecast_date ON weather_forecast_cache(forecast_date DESC);
CREATE INDEX IF NOT EXISTS idx_anomaly_type ON anomaly_events(anomaly_type, is_explained);

-- è¦–åœ–: ç•¶å‰å¤©æ°£å½±éŸ¿åƒæ•¸æ‘˜è¦
CREATE OR REPLACE VIEW current_weather_impacts AS
SELECT
    parameter_name,
    parameter_value,
    sample_count,
    confidence_interval_lower,
    confidence_interval_upper,
    p_value,
    CASE
        WHEN p_value < 0.001 THEN '***'
        WHEN p_value < 0.01 THEN '**'
        WHEN p_value < 0.05 THEN '*'
        ELSE 'n.s.'
    END as significance,
    last_updated
FROM weather_impact_parameters
WHERE is_active = TRUE
ORDER BY ABS(parameter_value) DESC;

-- è¦–åœ–: AI äº‹ä»¶å­¸ç¿’æ‘˜è¦
CREATE OR REPLACE VIEW ai_learning_summary AS
SELECT
    event_type,
    event_pattern,
    total_occurrences,
    avg_ai_factor,
    avg_actual_impact_pct,
    prediction_accuracy,
    confidence_level,
    last_occurrence
FROM ai_event_learning
WHERE total_occurrences >= 5
ORDER BY total_occurrences DESC;

-- è¦–åœ–: ç•°å¸¸çµ±è¨ˆ
CREATE OR REPLACE VIEW anomaly_stats AS
SELECT
    COUNT(*) as total_anomalies,
    COUNT(CASE WHEN is_explained THEN 1 END) as explained_anomalies,
    COUNT(CASE WHEN requires_review THEN 1 END) as pending_review,
    AVG(prediction_error) as avg_error,
    MAX(date) as latest_anomaly
FROM anomaly_events
WHERE created_at >= CURRENT_DATE - INTERVAL '90 days';

COMMENT ON TABLE learning_records IS 'æ ¸å¿ƒå­¸ç¿’è¨˜éŒ„è¡¨ï¼Œè¨˜éŒ„æ¯å¤©çš„é æ¸¬ã€å¯¦éš›ã€æ¢ä»¶å’Œå­¸ç¿’çµæœ';
COMMENT ON TABLE weather_impact_parameters IS 'å‹•æ…‹æ›´æ–°çš„å¤©æ°£å½±éŸ¿åƒæ•¸';
COMMENT ON TABLE weather_combination_impacts IS 'å¤©æ°£æ¢ä»¶çµ„åˆå° attendance çš„å½±éŸ¿';
COMMENT ON TABLE ai_event_learning IS 'AI äº‹ä»¶æ¨¡å¼å­¸ç¿’çµæœ';
COMMENT ON TABLE weather_forecast_cache IS 'å¤©æ°£é å ±ç·©å­˜ï¼Œç”¨æ–¼é æ¸¬èª¿æ•´';
COMMENT ON TABLE anomaly_events IS 'ç•°å¸¸äº‹ä»¶è¨˜éŒ„å’Œè¿½è¹¤';
```

---

## Phase 1: è‡ªå‹•è¨˜éŒ„ç³»çµ±

### ç›®æ¨™

è‡ªå‹•è¨˜éŒ„æ¯å¤©çš„ï¼š
1. é æ¸¬å€¼ vs å¯¦éš›å€¼
2. å¤©æ°£æ¢ä»¶
3. AI å› ç´ 
4. é æ¸¬èª¤å·®

### å¯¦ç¾æ–‡ä»¶

#### `python/continuous_learner.py`

```python
#!/usr/bin/env python3
"""
Continuous Learning Engine
è‡ªå‹•å­¸ç¿’å¤©æ°£å’Œ AI å› ç´ å° attendance çš„å½±éŸ¿

Daily Cron Job:
1. ç²å–æ˜¨æ—¥å¯¦éš›æ•¸æ“š
2. ç²å–æ˜¨æ—¥é æ¸¬
3. è¨ˆç®—èª¤å·®
4. åˆ†æå¤©æ°£æ¢ä»¶
5. åˆ†æ AI å› ç´ 
6. æ›´æ–°å­¸ç¿’è¨˜éŒ„
"""

import os
import sys
import psycopg2
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from dotenv import load_dotenv
import json
import requests

# ============================================================
# Configuration
# ============================================================

HKO_WEATHER_API = "https://data.weather.gov.hk/weatherAPI/opendata/weather.php?dataType=fnd&lang=tc"
ANOMALY_THRESHOLD = 15.0  # èª¤å·® > 15 äººè¦–ç‚ºç•°å¸¸
HIGH_ANOMALY_THRESHOLD = 30.0  # èª¤å·® > 30 äººè¦–ç‚ºé«˜ç•°å¸¸

# ============================================================
# Database Connection
# ============================================================

def get_db_connection():
    """ç²å–æ•¸æ“šåº«é€£æ¥"""
    load_dotenv()
    database_url = os.getenv('DATABASE_URL')
    if database_url:
        conn = psycopg2.connect(database_url)
    else:
        conn = psycopg2.connect(
            host=os.getenv('PGHOST'),
            database=os.getenv('PGDATABASE'),
            user=os.getenv('PGUSER'),
            password=os.getenv('PGPASSWORD'),
        )
    return conn

# ============================================================
# Data Collection
# ============================================================

def fetch_yesterday_data(date):
    """ç²å–æŒ‡å®šæ—¥æœŸçš„æ‰€æœ‰ç›¸é—œæ•¸æ“š"""

    conn = get_db_connection()
    cur = conn.cursor()

    data = {
        'date': date,
        'actual': None,
        'prediction': None,
        'ai_factor': None,
        'weather': None
    }

    # 1. ç²å–å¯¦éš› attendance
    cur.execute("""
        SELECT patient_count
        FROM actual_data
        WHERE date = %s
    """, (date,))
    result = cur.fetchone()
    if result:
        data['actual'] = result[0]

    # 2. ç²å–é æ¸¬å€¼
    cur.execute("""
        SELECT
            xgboost_base,
            prediction_production,
            prediction_experimental,
            ai_factor,
            weather_factor
        FROM daily_predictions
        WHERE target_date = %s
        ORDER BY prediction_date DESC
        LIMIT 1
    """, (date,))
    result = cur.fetchone()
    if result:
        data['prediction'] = {
            'xgboost_base': float(result[0]) if result[0] else None,
            'production': float(result[1]) if result[1] else None,
            'experimental': float(result[2]) if result[2] else None,
            'ai_factor': float(result[3]) if result[3] else None,
            'weather_factor': float(result[4]) if result[4] else None,
        }

    # 3. ç²å– AI factor è©³æƒ…
    cur.execute("""
        SELECT
            event_type,
            event_description,
            ai_factor
        FROM ai_factor_validation
        WHERE prediction_date = %s
    """, (date,))
    result = cur.fetchone()
    if result:
        data['ai_factor'] = {
            'event_type': result[0],
            'description': result[1],
            'factor': float(result[2]) if result[2] else None
        }

    # 4. ç²å–å¤©æ°£æ•¸æ“š
    cur.execute("""
        SELECT
            temp_min, temp_max, temp_mean,
            humidity_pct, rainfall_mm, wind_kmh,
            pressure_hpa, visibility_km,
            is_very_cold, is_very_hot, is_heavy_rain,
            is_strong_wind, typhoon_signal
        FROM weather_history
        WHERE date = %s
    """, (date,))
    result = cur.fetchone()
    if result:
        data['weather'] = {
            'temp_min': float(result[0]) if result[0] else None,
            'temp_max': float(result[1]) if result[1] else None,
            'temp_mean': float(result[2]) if result[2] else None,
            'humidity_pct': float(result[3]) if result[3] else None,
            'rainfall_mm': float(result[4]) if result[4] else None,
            'wind_kmh': float(result[5]) if result[5] else None,
            'pressure_hpa': float(result[6]) if result[6] else None,
            'visibility_km': float(result[7]) if result[7] else None,
            'is_very_cold': result[8],
            'is_very_hot': result[9],
            'is_heavy_rain': result[10],
            'is_strong_wind': result[11],
            'typhoon_signal': result[12]
        }

    cur.close()
    conn.close()

    return data

# ============================================================
# Learning Engine
# ============================================================

def calculate_error_metrics(actual, predicted):
    """è¨ˆç®—èª¤å·®æŒ‡æ¨™"""
    error = actual - predicted
    error_pct = (error / actual * 100) if actual > 0 else 0
    return {
        'error': error,
        'error_pct': error_pct,
        'abs_error': abs(error)
    }

def detect_anomaly(error, std_threshold=2.5):
    """æª¢æ¸¬æ˜¯å¦ç‚ºç•°å¸¸å€¼"""
    return {
        'is_anomaly': abs(error) > ANOMALY_THRESHOLD,
        'is_high_anomaly': abs(error) > HIGH_ANOMALY_THRESHOLD,
        'severity': 'high' if abs(error) > HIGH_ANOMALY_THRESHOLD else 'medium' if abs(error) > ANOMALY_THRESHOLD else 'none'
    }

def analyze_weather_impact(data, error):
    """åˆ†æå¤©æ°£å°èª¤å·®çš„å½±éŸ¿"""
    if not data.get('weather'):
        return None

    weather = data['weather']

    # åŸºæ–¼ç•¶å‰å·²çŸ¥å½±éŸ¿åˆ†æ
    # é€™è£¡ç°¡åŒ–è™•ç†ï¼Œå¯¦éš›æ‡‰è©²ç”¨æ›´è¤‡é›œçš„æ¨¡å‹

    impact = {
        'temperature_effect': 0,
        'rain_effect': 0,
        'wind_effect': 0,
        'total_effect': 0
    }

    # æº«åº¦æ•ˆæ‡‰
    if weather.get('is_very_cold'):
        impact['temperature_effect'] = -6.8  # å¾æ­·å²åˆ†æ
    elif weather.get('is_very_hot'):
        impact['temperature_effect'] = 1.2

    # é›¨æ•ˆæ‡‰
    if weather.get('is_heavy_rain'):
        impact['rain_effect'] = -4.9

    # é¢¨æ•ˆæ‡‰
    if weather.get('is_strong_wind'):
        impact['wind_effect'] = -2.8

    # ç¸½æ•ˆæ‡‰
    impact['total_effect'] = impact['temperature_effect'] + impact['rain_effect'] + impact['wind_effect']

    return impact

def analyze_ai_impact(data, error):
    """åˆ†æ AI å› ç´ å°èª¤å·®çš„å½±éŸ¿"""
    if not data.get('ai_factor'):
        return None

    ai = data['ai_factor']

    # å¦‚æœ AI factor å­˜åœ¨ï¼Œæª¢æŸ¥å®ƒæ˜¯å¦æ”¹å–„äº†é æ¸¬
    prediction_without_ai = data['prediction']['production']  # production ä¸åŒ…å« AI
    prediction_with_ai = data['prediction'].get('experimental')

    impact = {
        'ai_factor': ai.get('factor'),
        'event_type': ai.get('event_type'),
        'improved': False,
        'improvement_amount': 0
    }

    if prediction_with_ai and data.get('actual'):
        error_without_ai = abs(data['actual'] - prediction_without_ai)
        error_with_ai = abs(data['actual'] - prediction_with_ai)
        impact['improved'] = error_with_ai < error_without_ai
        impact['improvement_amount'] = error_without_ai - error_with_ai

    return impact

# ============================================================
# Database Update
# ============================================================

def save_learning_record(conn, data, metrics, anomaly, weather_impact, ai_impact):
    """ä¿å­˜å­¸ç¿’è¨˜éŒ„åˆ°æ•¸æ“šåº«"""
    cur = conn.cursor()

    prediction = data.get('prediction', {})
    weather = data.get('weather', {})
    ai = data.get('ai_factor')

    cur.execute("""
        INSERT INTO learning_records (
            date,
            xgboost_base_pred,
            final_prediction,
            actual_attendance,
            prediction_error,
            error_pct,

            -- å¤©æ°£æ¢ä»¶
            temp_min,
            temp_max,
            rainfall_mm,
            wind_kmh,
            humidity_pct,
            pressure_hpa,
            is_very_cold,
            is_very_hot,
            is_heavy_rain,
            is_strong_wind,
            typhoon_signal,

            -- AI å› ç´ 
            ai_factor,
            ai_event_type,
            ai_description,

            -- å­¸ç¿’çµæœ
            weather_impact_learned,
            ai_impact_learned,
            is_anomaly
        ) VALUES (
            %s, %s, %s, %s, %s, %s,
            %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s,
            %s, %s, %s,
            %s, %s, %s
        )
        ON CONFLICT (date) DO UPDATE SET
            actual_attendance = EXCLUDED.actual_attendance,
            prediction_error = EXCLUDED.prediction_error,
            is_anomaly = EXCLUDED.is_anomaly,
            processed = FALSE
    """, (
        data['date'],
        prediction.get('xgboost_base'),
        prediction.get('production'),
        data.get('actual'),
        metrics.get('error'),
        metrics.get('error_pct'),

        weather.get('temp_min'),
        weather.get('temp_max'),
        weather.get('rainfall_mm'),
        weather.get('wind_kmh'),
        weather.get('humidity_pct'),
        weather.get('pressure_hpa'),
        weather.get('is_very_cold', False),
        weather.get('is_very_hot', False),
        weather.get('is_heavy_rain', False),
        weather.get('is_strong_wind', False),
        weather.get('typhoon_signal'),

        ai.get('factor') if ai else None,
        ai.get('event_type') if ai else None,
        ai.get('description') if ai else None,

        weather_impact.get('total_effect') if weather_impact else None,
        ai_impact.get('improvement_amount') if ai_impact else None,
        anomaly.get('is_anomaly', False)
    ))

    conn.commit()
    cur.close()

def update_anomaly_if_needed(conn, data, metrics, anomaly):
    """å¦‚æœæª¢æ¸¬åˆ°ç•°å¸¸ï¼Œè¨˜éŒ„åˆ°ç•°å¸¸è¡¨"""
    if not anomaly.get('is_anomaly'):
        return

    cur = conn.cursor()

    weather = data.get('weather', {})
    conditions = {
        'temp_min': weather.get('temp_min'),
        'temp_max': weather.get('temp_max'),
        'rainfall_mm': weather.get('rainfall_mm'),
        'is_very_cold': weather.get('is_very_cold', False),
        'is_heavy_rain': weather.get('is_heavy_rain', False)
    }

    cur.execute("""
        INSERT INTO anomaly_events (
            date,
            anomaly_type,
            prediction_error,
            conditions_json,
            requires_review
        ) VALUES (
            %s, %s, %s, %s, %s
        )
    """, (
        data['date'],
        'unknown',  # å¾ŒçºŒåˆ†æç¢ºå®šé¡å‹
        metrics.get('error'),
        json.dumps(conditions),
        anomaly.get('severity') == 'high'
    ))

    conn.commit()
    cur.close()

# ============================================================
# Main Learning Loop
# ============================================================

def process_date(date):
    """è™•ç†å–®æ—¥æ•¸æ“š"""
    print(f"Processing date: {date}")

    # 1. ç²å–æ•¸æ“š
    data = fetch_yesterday_data(date)

    if not data.get('actual') or not data.get('prediction'):
        print(f"  âš ï¸ Missing data for {date}")
        return False

    # 2. è¨ˆç®—èª¤å·®
    metrics = calculate_error_metrics(
        data['actual'],
        data['prediction']['production']
    )

    print(f"  Actual: {data['actual']}, Predicted: {data['prediction']['production']:.1f}")
    print(f"  Error: {metrics['error']:.1f} ({metrics['error_pct']:.1f}%)")

    # 3. æª¢æ¸¬ç•°å¸¸
    anomaly = detect_anomaly(metrics['error'])
    if anomaly['is_anomaly']:
        print(f"  âš ï¸ Anomaly detected! Severity: {anomaly['severity']}")

    # 4. åˆ†æå¤©æ°£å½±éŸ¿
    weather_impact = analyze_weather_impact(data, metrics['error'])
    if weather_impact:
        print(f"  Weather impact: {weather_impact['total_effect']:.1f}")

    # 5. åˆ†æ AI å½±éŸ¿
    ai_impact = analyze_ai_impact(data, metrics['error'])
    if ai_impact and ai_impact.get('improved'):
        print(f"  âœ… AI improved prediction by {ai_impact['improvement_amount']:.1f}")

    # 6. ä¿å­˜åˆ°æ•¸æ“šåº«
    conn = get_db_connection()
    try:
        save_learning_record(conn, data, metrics, anomaly, weather_impact, ai_impact)
        update_anomaly_if_needed(conn, data, metrics, anomaly)
        print(f"  âœ… Saved to database")
    finally:
        conn.close()

    return True

def main():
    """ä¸»å‡½æ•¸ - è™•ç†æ˜¨å¤©çš„æ•¸æ“š"""
    yesterday = (datetime.now() - timedelta(days=1)).date()

    print("=" * 60)
    print("Continuous Learning Engine")
    print("=" * 60)
    print(f"Processing: {yesterday}")
    print()

    success = process_date(yesterday)

    print()
    if success:
        print("âœ… Learning complete")
    else:
        print("âš ï¸ Learning incomplete - missing data")

if __name__ == '__main__':
    main()
```

---

## Phase 2: ç•°å¸¸æª¢æ¸¬èˆ‡ Flag æ©Ÿåˆ¶

### ç›®æ¨™

ç•¶é æ¸¬èª¤å·®è¶…éé–¾å€¼æ™‚ï¼š
1. è‡ªå‹• flag ç‚ºç•°å¸¸
2. åˆ†æç•°å¸¸åŸå› 
3. å°‹æ‰¾é¡ä¼¼æ­·å²äº‹ä»¶
4. ç”Ÿæˆå ±å‘Šçµ¦ç®¡ç†å“¡

### å¯¦ç¾æ–‡ä»¶

#### `python/anomaly_detector.py`

```python
#!/usr/bin/env python3
"""
ç•°å¸¸æª¢æ¸¬èˆ‡åˆ†ææ¨¡çµ„
Anomaly Detection and Analysis

åŠŸèƒ½:
1. æª¢æ¸¬é æ¸¬ç•°å¸¸
2. åˆ†é¡ç•°å¸¸åŸå›  (å¤©æ°£/AI/æœªçŸ¥)
3. å°‹æ‰¾é¡ä¼¼æ­·å²äº‹ä»¶
4. ç”Ÿæˆç•°å¸¸å ±å‘Š
"""

import psycopg2
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from dotenv import load_dotenv
import os
import json

# ============================================================
# Anomaly Detection
# ============================================================

def calculate_baseline_stats(conn, days=90):
    """è¨ˆç®—åŸºç·šçµ±è¨ˆ (éå» N å¤©çš„èª¤å·®åˆ†ä½ˆ)"""
    cur = conn.cursor()

    cur.execute("""
        SELECT
            AVG(prediction_error) as mean_error,
            STDDEV(prediction_error) as std_error,
            MIN(prediction_error) as min_error,
            MAX(prediction_error) as max_error,
            COUNT(*) as sample_count
        FROM learning_records
        WHERE date >= CURRENT_DATE - INTERVAL '%s days'
          AND actual_attendance IS NOT NULL
    """, (days,))

    result = cur.fetchone()
    cur.close()

    if not result or result[4] < 10:
        # é»˜èªå€¼
        return {
            'mean': 0,
            'std': 10,
            'min': -30,
            'max': 30,
            'count': 0
        }

    return {
        'mean': float(result[0]) if result[0] else 0,
        'std': float(result[1]) if result[1] else 10,
        'min': float(result[2]) if result[2] else -30,
        'max': float(result[3]) if result[3] else 30,
        'count': int(result[4])
    }

def classify_anomaly(conn, date, error, weather=None, ai_factor=None):
    """åˆ†é¡ç•°å¸¸åŸå› """

    classification = {
        'type': 'unknown',
        'confidence': 'low',
        'reason': [],
        'suggested_adjustment': 0
    }

    # 1. æª¢æŸ¥æ˜¯å¦ç‚ºå¤©æ°£ç•°å¸¸
    if weather:
        weather_causes = []

        if weather.get('is_very_cold'):
            weather_causes.append('very_cold')
            classification['suggested_adjustment'] -= 6.8

        if weather.get('is_heavy_rain'):
            weather_causes.append('heavy_rain')
            classification['suggested_adjustment'] -= 4.9

        if weather.get('typhoon_signal') and weather['typhoon_signal'] in ['T8', 'T9', 'T10']:
            weather_causes.append('typhoon')
            classification['suggested_adjustment'] -= 12.0

        if len(weather_causes) > 0:
            classification['type'] = 'weather'
            classification['confidence'] = 'high' if len(weather_causes) >= 2 else 'medium'
            classification['reason'] = weather_causes

    # 2. æª¢æŸ¥æ˜¯å¦ç‚º AI äº‹ä»¶ç•°å¸¸
    if ai_factor and abs(ai_factor.get('factor', 1.0) - 1.0) > 0.05:
        if classification['type'] == 'unknown':
            classification['type'] = 'ai'
            classification['reason'] = [ai_factor.get('event_type', 'unknown_ai_event')]
            classification['confidence'] = 'medium'

    return classification

def find_similar_events(conn, current_weather, current_ai, limit=10):
    """å°‹æ‰¾é¡ä¼¼çš„æ­·å²äº‹ä»¶"""
    cur = conn.cursor()

    # æ§‹å»ºæŸ¥è©¢æ¢ä»¶
    conditions = []
    params = []

    if current_weather:
        if current_weather.get('is_very_cold'):
            conditions.append("is_very_cold = TRUE")
        if current_weather.get('is_heavy_rain'):
            conditions.append("is_heavy_rain = TRUE")
        if current_weather.get('is_strong_wind'):
            conditions.append("is_strong_wind = TRUE")

    if current_ai:
        if current_ai.get('event_type'):
            conditions.append("ai_event_type = %s")
            params.append(current_ai['event_type'])

    where_clause = " AND ".join(conditions) if conditions else "TRUE"

    cur.execute(f"""
        SELECT
            date,
            actual_attendance,
            prediction_error,
            is_very_cold,
            is_heavy_rain,
            is_strong_wind,
            ai_event_type
        FROM learning_records
        WHERE {where_clause}
          AND actual_attendance IS NOT NULL
        ORDER BY date DESC
        LIMIT %s
    """, params + [limit])

    results = cur.fetchall()
    cur.close()

    return [
        {
            'date': str(r[0]),
            'actual': float(r[1]),
            'error': float(r[2]),
            'conditions': {
                'is_very_cold': r[3],
                'is_heavy_rain': r[4],
                'is_strong_wind': r[5],
                'ai_event': r[6]
            }
        }
        for r in results
    ]

def generate_anomaly_report(conn, date):
    """ç”Ÿæˆç•°å¸¸å ±å‘Š"""

    cur = conn.cursor()

    # ç²å–ç•°å¸¸è¨˜éŒ„
    cur.execute("""
        SELECT
            date,
            actual_attendance,
            final_prediction,
            prediction_error,
            temp_min,
            temp_max,
            rainfall_mm,
            is_very_cold,
            is_heavy_rain,
            ai_factor,
            ai_event_type
        FROM learning_records
        WHERE date = %s
    """, (date,))

    result = cur.fetchone()
    if not result:
        return None

    cur.close()

    # æ§‹å»ºå ±å‘Š
    report = {
        'date': str(result[0]),
        'actual': float(result[1]),
        'predicted': float(result[2]),
        'error': float(result[3]),
        'error_pct': (float(result[3]) / float(result[1]) * 100) if result[1] else 0,

        'conditions': {
            'temp_min': float(result[4]) if result[4] else None,
            'temp_max': float(result[5]) if result[5] else None,
            'rainfall_mm': float(result[6]) if result[6] else None,
            'is_very_cold': result[7],
            'is_heavy_rain': result[8]
        },

        'ai_factor': {
            'factor': float(result[9]) if result[9] else None,
            'event_type': result[10]
        }
    }

    return report

# ============================================================
# Main
# ============================================================

def main():
    """æª¢æ¸¬ä¸¦å ±å‘Šæœ€è¿‘çš„ç•°å¸¸"""
    conn = psycopg2.connect(os.getenv('DATABASE_URL'))
    load_dotenv()

    # è¨ˆç®—åŸºç·š
    baseline = calculate_baseline_stats(conn)

    print("=" * 60)
    print("Anomaly Detection Report")
    print("=" * 60)
    print(f"Baseline (last 90 days):")
    print(f"  Mean Error: {baseline['mean']:.2f}")
    print(f"  Std Dev: {baseline['std']:.2f}")
    print(f"  Sample Count: {baseline['count']}")
    print()

    # æª¢æ¸¬æœªè™•ç†çš„ç•°å¸¸
    cur = conn.cursor()
    cur.execute("""
        SELECT date, prediction_error
        FROM learning_records
        WHERE is_anomaly = TRUE
          AND processed = FALSE
        ORDER BY date DESC
    """)

    anomalies = cur.fetchall()
    cur.close()

    if not anomalies:
        print("âœ… No new anomalies to process")
        return

    print(f"Found {len(anomalies)} anomalies:")
    print()

    for date, error in anomalies:
        print(f"ğŸ“… {date}: Error = {error:.1f}")

        # ç”Ÿæˆå ±å‘Š
        report = generate_anomaly_report(conn, date)
        if report:
            print(f"   Actual: {report['actual']}, Predicted: {report['predicted']:.1f}")
            print(f"   Conditions: {report['conditions']}")

        print()

    conn.close()

if __name__ == '__main__':
    main()
```

---

## Phase 3: å­¸ç¿’è¿´æ­¸æ¨¡å‹

### ç›®æ¨™

åŸºæ–¼æ”¶é›†çš„æ•¸æ“šï¼Œå»ºç«‹å­¸ç¿’æ¨¡å‹ï¼š
1. å¤©æ°£æ¢ä»¶ â†’ é æœŸ attendance è®ŠåŒ–
2. AI äº‹ä»¶é¡å‹ â†’ é æœŸ attendance è®ŠåŒ–
3. æ¢ä»¶çµ„åˆ â†’ é æœŸ attendance è®ŠåŒ–

### å¯¦ç¾æ–‡ä»¶

#### `python/weather_impact_learner.py`

```python
#!/usr/bin/env python3
"""
å¤©æ°£å½±éŸ¿å­¸ç¿’æ¨¡å‹
Weather Impact Learning Model

åŸºæ–¼æ­·å²æ•¸æ“šå­¸ç¿’ä¸åŒå¤©æ°£æ¢ä»¶å° attendance çš„å½±éŸ¿
"""

import psycopg2
import pandas as pd
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from datetime import datetime, timedelta
import os
from dotenv import load_dotenv
import json

def fetch_learning_data(conn, days=365):
    """ç²å–å­¸ç¿’æ•¸æ“š"""
    query = f"""
        SELECT
            date,
            actual_attendance,
            xgboost_base_pred,
            prediction_error,

            -- å¤©æ°£ç‰¹å¾µ
            temp_min,
            temp_max,
            rainfall_mm,
            wind_kmh,
            humidity_pct,
            pressure_hpa,

            -- æ¥µç«¯æ¢ä»¶
            is_very_cold,
            is_very_hot,
            is_heavy_rain,
            is_strong_wind

        FROM learning_records
        WHERE actual_attendance IS NOT NULL
          AND xgboost_base_pred IS NOT NULL
          AND date >= CURRENT_DATE - INTERVAL '{days} days'
    """

    return pd.read_sql_query(query, conn)

def prepare_features(df):
    """æº–å‚™æ©Ÿå™¨å­¸ç¿’ç‰¹å¾µ"""

    # ç›®æ¨™è®Šé‡: å¯¦éš› attendance vs XGBoost é æ¸¬çš„å·®ç•°
    df['target_impact'] = df['actual_attendance'] - df['xgboost_base_pred']

    # ç‰¹å¾µå·¥ç¨‹
    features = []

    # 1. é€£çºŒç‰¹å¾µ
    continuous_features = [
        'temp_min', 'temp_max', 'rainfall_mm',
        'wind_kmh', 'humidity_pct', 'pressure_hpa'
    ]

    # 2. äºŒå…ƒç‰¹å¾µ
    binary_features = [
        'is_very_cold', 'is_very_hot',
        'is_heavy_rain', 'is_strong_wind'
    ]

    # 3. äº¤äº’ç‰¹å¾µ
    df['cold_rain'] = df['is_very_cold'] & df['is_heavy_rain']
    df['hot_rain'] = df['is_very_hot'] & df['is_heavy_rain']

    all_features = continuous_features + binary_features + ['cold_rain', 'hot_rain']

    # è™•ç†ç¼ºå¤±å€¼
    for col in all_features:
        if col not in df.columns:
            df[col] = 0
        df[col] = df[col].fillna(0)

    X = df[all_features]
    y = df['target_impact']

    return X, y, all_features

def train_impact_model(conn):
    """è¨“ç·´å¤©æ°£å½±éŸ¿æ¨¡å‹"""

    # 1. ç²å–æ•¸æ“š
    df = fetch_learning_data(conn)

    if len(df) < 50:
        print(f"âš ï¸ Not enough data: {len(df)} samples (need >= 50)")
        return None

    # 2. æº–å‚™ç‰¹å¾µ
    X, y, feature_names = prepare_features(df)

    # 3. è¨“ç·´æ¨¡å‹
    model = LinearRegression()
    model.fit(X, y)

    # 4. è©•ä¼°
    score = model.score(X, y)

    # 5. æå–å½±éŸ¿åƒæ•¸
    impacts = {}
    for i, feature in enumerate(feature_names):
        impacts[feature] = {
            'coefficient': float(model.coef_[i]),
            'abs_impact': abs(float(model.coef_[i]))
        }

    # 6. æ›´æ–°æ•¸æ“šåº«
    cur = conn.cursor()

    for feature, data in impacts.items():
        cur.execute("""
            INSERT INTO weather_impact_parameters (
                parameter_name,
                parameter_value,
                sample_count,
                is_active
            ) VALUES (%s, %s, %s, %s)
            ON CONFLICT (parameter_name) DO UPDATE SET
                parameter_value = EXCLUDED.parameter_value,
                sample_count = EXCLUDED.sample_count,
                last_updated = NOW()
        """, (feature, data['coefficient'], len(df), True))

    conn.commit()
    cur.close()

    print(f"âœ… Weather impact model trained (RÂ² = {score:.3f})")
    print(f"   Samples: {len(df)}")

    return model, impacts

def update_combination_impacts(conn):
    """æ›´æ–°å¤©æ°£æ¢ä»¶çµ„åˆå½±éŸ¿"""

    # è¨ˆç®—åŸºç·šå¹³å‡
    cur = conn.cursor()
    cur.execute("""
        SELECT AVG(actual_attendance), STDDEV(actual_attendance), COUNT(*)
        FROM learning_records
        WHERE actual_attendance IS NOT NULL
    """)
    baseline_mean, baseline_std, total_count = cur.fetchone()

    # åˆ†æå„ç¨®çµ„åˆ
    combinations = [
        # (æ¢ä»¶åç¨±, WHERE æ¢ä»¶)
        ('very_cold', 'is_very_cold = TRUE'),
        ('very_hot', 'is_very_hot = TRUE'),
        ('heavy_rain', 'is_heavy_rain = TRUE'),
        ('strong_wind', 'is_strong_wind = TRUE'),
        ('cold_and_rain', 'is_very_cold = TRUE AND is_heavy_rain = TRUE'),
        ('hot_and_rain', 'is_very_hot = TRUE AND is_heavy_rain = TRUE'),
        ('cold_and_wind', 'is_very_cold = TRUE AND is_strong_wind = TRUE'),
    ]

    for name, condition in combinations:
        cur.execute(f"""
            SELECT
                COUNT(*) as n,
                AVG(actual_attendance) as mean_att,
                STDDEV(actual_attendance) as std_att
            FROM learning_records
            WHERE {condition}
              AND actual_attendance IS NOT NULL
        """)

        result = cur.fetchone()
        n, mean_att, std_att = result

        if n < 5:  # æ¨£æœ¬å¤ªå°‘
            continue

        impact_factor = mean_att / baseline_mean
        impact_absolute = mean_att - baseline_mean

        # t-test
        t_stat = impact_absolute / (std_att / np.sqrt(n)) if std_att > 0 else 0

        cur.execute("""
            INSERT INTO weather_combination_impacts (
                conditions_json,
                sample_count,
                mean_attendance,
                std_attendance,
                baseline_mean,
                impact_factor,
                impact_absolute,
                t_statistic,
                last_seen
            ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)
            ON CONFLICT (conditions_json) DO UPDATE SET
                sample_count = EXCLUDED.sample_count,
                impact_factor = EXCLUDED.impact_factor,
                impact_absolute = EXCLUDED.impact_absolute,
                t_statistic = EXCLUDED.t_statistic,
                last_seen = EXCLUDED.last_seen,
                last_updated = NOW()
        """, (
            json.dumps({'condition': name}),
            n, mean_att, std_att, baseline_mean,
            impact_factor, impact_absolute, t_stat,
            datetime.now().date()
        ))

    conn.commit()
    cur.close()

    print(f"âœ… Updated {len(combinations)} weather combinations")

def main():
    """ä¸»å‡½æ•¸"""
    load_dotenv()
    conn = psycopg2.connect(os.getenv('DATABASE_URL'))

    print("=" * 60)
    print("Weather Impact Learning")
    print("=" * 60)
    print()

    # 1. è¨“ç·´å½±éŸ¿æ¨¡å‹
    train_impact_model(conn)

    # 2. æ›´æ–°çµ„åˆå½±éŸ¿
    update_combination_impacts(conn)

    conn.close()
    print()
    print("âœ… Learning complete")

if __name__ == '__main__':
    main()
```

---

## Phase 4: é æ¸¬æ•´åˆ

### ç›®æ¨™

å°‡å­¸ç¿’åˆ°çš„å¤©æ°£å’Œ AI å½±éŸ¿æ•´åˆåˆ°é æ¸¬æµç¨‹ä¸­ï¼š
1. ç²å–å¤©æ°£é å ±
2. æŸ¥è©¢å­¸ç¿’åˆ°çš„å½±éŸ¿åƒæ•¸
3. èª¿æ•´ XGBoost åŸºç¤é æ¸¬
4. ç”Ÿæˆæœ€çµ‚é æ¸¬

### å¯¦ç¾æ–‡ä»¶

#### `python/forecast_predictor.py`

```python
#!/usr/bin/env python3
"""
å¤©æ°£é å ±é æ¸¬æ•´åˆ
Weather Forecast Integrated Prediction

ä½¿ç”¨å¤©æ°£é å ±å’Œå­¸ç¿’åˆ°çš„å½±éŸ¿åƒæ•¸èª¿æ•´é æ¸¬
"""

import psycopg2
import requests
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import os
from dotenv import load_dotenv
import json

HKO_FORECAST_API = "https://data.weather.gov.hk/weatherAPI/opendata/weather.php?dataType=fnd&lang=tc"

def fetch_weather_forecast():
    """ç²å– HKO 9 å¤©å¤©æ°£é å ±"""
    try:
        response = requests.get(HKO_FORECAST_API, timeout=30)
        response.raise_for_status()
        data = response.json()

        forecasts = []
        for day in data.get('weatherForecast', []):
            forecasts.append({
                'date': datetime.strptime(day['forecastDate'], '%Y%m%d').date(),
                'temp_min': int(day.get('forecastMintemp', '20').replace('Â°C', '').strip()),
                'temp_max': int(day.get('forecastMaxtemp', '28').replace('Â°C', '').strip()),
                'humidity': day.get('forecastHumidity', ''),
                'rain_prob': day.get('PSR', 'Low'),
                'desc': day.get('ForecastDesc', '')
            })

        return forecasts
    except Exception as e:
        print(f"âŒ Failed to fetch forecast: {e}")
        return []

def get_learned_impacts(conn):
    """å¾æ•¸æ“šåº«ç²å–å­¸ç¿’åˆ°çš„å½±éŸ¿åƒæ•¸"""
    cur = conn.cursor()

    cur.execute("""
        SELECT parameter_name, parameter_value, sample_count
        FROM weather_impact_parameters
        WHERE is_active = TRUE
    """)

    impacts = {row[0]: {'value': float(row[1]), 'n': int(row[2])} for row in cur.fetchall()}
    cur.close()

    return impacts

def calculate_weather_adjustment(forecast, impacts):
    """åŸºæ–¼é å ±è¨ˆç®—èª¿æ•´å€¼"""

    adjustment = 0
    factors = []

    temp_min = forecast['temp_min']
    temp_max = forecast['temp_max']
    rain_prob = forecast['rain_prob']

    # 1. æº«åº¦èª¿æ•´
    if temp_min <= 12:
        cold_impact = impacts.get('is_very_cold', {}).get('value', -6.8)
        adjustment += cold_impact
        factors.append(f'å¯’å†·å¤©æ°£ ({cold_impact:+.1f})')

    elif temp_max >= 33:
        hot_impact = impacts.get('is_very_hot', {}).get('value', 1.2)
        adjustment += hot_impact
        factors.append(f'ç‚ç†±å¤©æ°£ ({hot_impact:+.1f})')

    # 2. é™é›¨èª¿æ•´
    if rain_prob in ['High', 'Very High']:
        rain_impact = impacts.get('is_heavy_rain', {}).get('value', -4.9)
        adjustment += rain_impact
        factors.append(f'å¤§é›¨é å ± ({rain_impact:+.1f})')

    return adjustment, factors

def predict_with_forecast(target_date, base_prediction):
    """ä½¿ç”¨å¤©æ°£é å ±ç”Ÿæˆèª¿æ•´å¾Œçš„é æ¸¬"""

    load_dotenv()
    conn = psycopg2.connect(os.getenv('DATABASE_URL'))

    # 1. ç²å–å¤©æ°£é å ±
    forecasts = fetch_weather_forecast()

    # 2. ç²å–å­¸ç¿’åˆ°çš„å½±éŸ¿
    impacts = get_learned_impacts(conn)

    # 3. æ‰¾åˆ°ç›®æ¨™æ—¥æœŸçš„é å ±
    target_forecast = None
    for f in forecasts:
        if f['date'] == target_date:
            target_forecast = f
            break

    conn.close()

    if not target_forecast:
        # æ²’æœ‰é å ±ï¼Œè¿”å›åŸºç¤é æ¸¬
        return {
            'date': target_date,
            'base_prediction': base_prediction,
            'final_prediction': base_prediction,
            'adjustment': 0,
            'factors': ['ç„¡å¤©æ°£é å ±']
        }

    # 4. è¨ˆç®—èª¿æ•´
    adjustment, factors = calculate_weather_adjustment(target_forecast, impacts)

    return {
        'date': target_date,
        'base_prediction': base_prediction,
        'final_prediction': base_prediction + adjustment,
        'adjustment': adjustment,
        'factors': factors,
        'forecast': target_forecast
    }

def main():
    """æ¸¬è©¦"""
    target_date = (datetime.now() + timedelta(days=1)).date()
    base_pred = 250

    result = predict_with_forecast(target_date, base_pred)

    print("=" * 60)
    print("Weather Forecast Prediction")
    print("=" * 60)
    print(f"Target Date: {result['date']}")
    print(f"Base Prediction: {result['base_prediction']:.0f}")
    print(f"Adjustment: {result['adjustment']:+.1f}")
    print(f"Final Prediction: {result['final_prediction']:.0f}")
    if result.get('forecast'):
        print(f"\nForecast: {result['forecast']['temp_min']}Â°C - {result['forecast']['temp_max']}Â°C, {result['forecast']['rain_prob']} rain")

if __name__ == '__main__':
    main()
```

---

## API è¨­è¨ˆ

### æ–°å¢ç«¯é»

#### `server.js` æ–°å¢è·¯ç”±

```javascript
// ============================================================
// Continuous Learning API Endpoints
// ============================================================

// ç²å–å­¸ç¿’æ‘˜è¦
app.get('/api/learning/summary', async (req, res) => {
    try {
        const result = await pool.query(`
            SELECT
                COUNT(*) as total_records,
                COUNT(CASE WHEN is_anomaly THEN 1 END) as anomalies,
                AVG(prediction_error) as avg_error,
                MAX(date) as latest_date
            FROM learning_records
        `);
        res.json(result.rows[0]);
    } catch (error) {
        res.status(500).json({ error: error.message });
    }
});

// ç²å–ç•¶å‰å¤©æ°£å½±éŸ¿åƒæ•¸
app.get('/api/learning/weather-impacts', async (req, res) => {
    try {
        const result = await pool.query(`
            SELECT * FROM current_weather_impacts
            ORDER BY ABS(parameter_value) DESC
        `);
        res.json(result.rows);
    } catch (error) {
        res.status(500).json({ error: error.message });
    }
});

// ç²å–ç•°å¸¸åˆ—è¡¨
app.get('/api/learning/anomalies', async (req, res) => {
    try {
        const limit = parseInt(req.query.limit) || 30;
        const result = await pool.query(`
            SELECT
                date,
                actual_attendance,
                final_prediction,
                prediction_error,
                is_very_cold,
                is_heavy_rain,
                ai_event_type
            FROM learning_records
            WHERE is_anomaly = TRUE
            ORDER BY date DESC
            LIMIT $1
        `, [limit]);
        res.json(result.rows);
    } catch (error) {
        res.status(500).json({ error: error.message });
    }
});

// è§¸ç™¼å­¸ç¿’æ›´æ–°
app.post('/api/learning/update', async (req, res) => {
    try {
        // èª¿ç”¨ Python å­¸ç¿’è…³æœ¬
        const { spawn } = require('child_process');
        const python = spawn('python', ['python/weather_impact_learner.py']);

        let output = '';
        python.stdout.on('data', (data) => { output += data.toString(); });

        python.on('close', (code) => {
            if (code === 0) {
                res.json({ success: true, message: 'Learning update complete' });
            } else {
                res.status(500).json({ success: false, message: 'Learning failed' });
            }
        });
    } catch (error) {
        res.status(500).json({ error: error.message });
    }
});

// ç²å–å¤©æ°£é å ±é æ¸¬
app.get('/api/learning/forecast-prediction/:date', async (req, res) => {
    try {
        const date = req.params.date;
        // èª¿ç”¨ Python é å ±é æ¸¬
        // ...
        res.json({ date, prediction: 250 });
    } catch (error) {
        res.status(500).json({ error: error.message });
    }
});
```

---

## éƒ¨ç½²ç­–ç•¥

### Cron Job é…ç½®

```bash
# ============================================================
# Railway Cron Job é…ç½®
# ============================================================

# æ¯å¤©å‡Œæ™¨ 12:30 åŸ·è¡Œå­¸ç¿’è…³æœ¬
# åœ¨ Railway ä¸Šè¨­ç½®ç‚º Scheduled Task

# æˆ–åœ¨ server.js ä¸­è¨­ç½®å®šæ™‚ä»»å‹™
```

#### `modules/learning-scheduler.js`

```javascript
/**
 * å­¸ç¿’èª¿åº¦å™¨
 * æ¯å¤©è‡ªå‹•åŸ·è¡Œå­¸ç¿’ä»»å‹™
 */

const cron = require('node-cron');
const { spawn } = require('child_process');

class LearningScheduler {
    constructor() {
        this.isRunning = false;
    }

    start() {
        console.log('ğŸ“š Starting Learning Scheduler...');

        // æ¯å¤©å‡Œæ™¨ 12:30 åŸ·è¡Œ
        cron.schedule('30 0 * * *', () => {
            this.runDailyLearning();
        });

        // æ¯é€±ä¸€å‡Œæ™¨ 1:00 åŸ·è¡Œå®Œæ•´å­¸ç¿’ (æ›´æ–°æ¨¡å‹)
        cron.schedule('0 1 * * 1', () => {
            this.runWeeklyLearning();
        });
    }

    async runDailyLearning() {
        if (this.isRunning) {
            console.log('âš ï¸ Learning already running');
            return;
        }

        this.isRunning = true;
        console.log('ğŸ”„ Running daily learning...');

        const python = spawn('python', ['python/continuous_learner.py']);

        python.stdout.on('data', (data) => {
            console.log(data.toString().trim());
        });

        python.stderr.on('data', (data) => {
            console.error(data.toString().trim());
        });

        python.on('close', (code) => {
            this.isRunning = false;
            if (code === 0) {
                console.log('âœ… Daily learning complete');
            } else {
                console.error(`âŒ Daily learning failed (code ${code})`);
            }
        });
    }

    async runWeeklyLearning() {
        console.log('ğŸ”„ Running weekly learning...');

        const python = spawn('python', ['python/weather_impact_learner.py']);

        python.on('close', (code) => {
            if (code === 0) {
                console.log('âœ… Weekly learning complete');
            }
        });
    }
}

module.exports = LearningScheduler;
```

---

## ç›£æ§èˆ‡è­¦å ±

### Dashboard æŒ‡æ¨™

```javascript
// å­¸ç¿’ç³»çµ±ç›£æ§æŒ‡æ¨™
const LEARNING_METRICS = {
    // æ•¸æ“šè³ªé‡
    totalRecords: 0,
    recentRecords: 0,           // éå» 30 å¤©
    anomaliesCount: 0,
    anomaliesRate: 0,            // ç•°å¸¸ç‡

    // æ¨¡å‹æ€§èƒ½
    avgError: 0,
    mae: 0,
    rmse: 0,
    mape: 0,

    // å¤©æ°£å½±éŸ¿
    weatherImpactParams: {},
    lastWeatherUpdate: null,

    // AI å› ç´ 
    aiEventAccuracy: 0,
    aiCorrectPredictions: 0,
    aiTotalPredictions: 0,

    // ç³»çµ±ç‹€æ…‹
    lastLearningRun: null,
    learningStatus: 'idle',      // idle, running, error
    databaseStatus: 'connected'
};
```

---

## å¯¦æ–½æ­¥é©Ÿ

### ç¬¬ 1 é€±ï¼šæ•¸æ“šåº«å’ŒåŸºç¤æ¶æ§‹

1. âœ… é‹è¡Œ migration `004_continuous_learning.sql`
2. âœ… å‰µå»º `python/continuous_learner.py`
3. âœ… å‰µå»º `modules/learning-scheduler.js`
4. âœ… æ¸¬è©¦æ¯æ—¥æ•¸æ“šè¨˜éŒ„

### ç¬¬ 2 é€±ï¼šç•°å¸¸æª¢æ¸¬

1. âœ… å‰µå»º `python/anomaly_detector.py`
2. âœ… å¯¦ç¾ç•°å¸¸åˆ†é¡é‚è¼¯
3. âœ… å‰µå»ºç•°å¸¸å ±å‘Š API
4. âœ… æ¸¬è©¦ç•°å¸¸æª¢æ¸¬

### ç¬¬ 3 é€±ï¼šå­¸ç¿’æ¨¡å‹

1. âœ… å‰µå»º `python/weather_impact_learner.py`
2. âœ… å¯¦ç¾è¿´æ­¸æ¨¡å‹è¨“ç·´
3. âœ… æ›´æ–°å¤©æ°£å½±éŸ¿åƒæ•¸è¡¨
4. âœ… é©—è­‰å­¸ç¿’æ•ˆæœ

### ç¬¬ 4 é€±ï¼šé å ±æ•´åˆ

1. âœ… å‰µå»º `python/forecast_predictor.py`
2. âœ… æ•´åˆå¤©æ°£é å ± API
3. âœ… å¯¦ç¾é æ¸¬èª¿æ•´é‚è¼¯
4. âœ… éƒ¨ç½²åˆ°ç”Ÿç”¢ç’°å¢ƒ

---

## æ•¸æ“šæµç¸½çµ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          å®Œæ•´æ•¸æ“šæµ                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ï¿½ï¿½ï¿½      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  HKO Weather  â”‚      â”‚  XGBoost       â”‚      â”‚  AI Service    â”‚ â”‚
â”‚  â”‚  (History)    â”‚      â”‚  Prediction    â”‚      â”‚  Analysis      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚          â”‚                       â”‚                       â”‚          â”‚
â”‚          â–¼                       â–¼                       â–¼          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                   Daily Prediction Process                     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                             â”‚                                       â”‚
â”‚                             â–¼                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚              daily_predictions Table                           â”‚ â”‚
â”‚  â”‚   - xgboost_base                                               â”‚ â”‚
â”‚  â”‚   - prediction_production                                      â”‚ â”‚
â”‚  â”‚   - prediction_experimental                                    â”‚ â”‚
â”‚  â”‚   - ai_factor                                                  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                             â”‚                                       â”‚
â”‚                             â–¼                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                  actual_data Table                             â”‚ â”‚
â”‚  â”‚   (ç”¨æˆ¶ä¸Šå‚³å¯¦éš›æ•¸æ“š)                                            â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                             â”‚                                       â”‚
â”‚                             â–¼                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚              Continuous Learner (Cron)                         â”‚ â”‚
â”‚  â”‚   1. è¨ˆç®—èª¤å·®                                                   â”‚ â”‚
â”‚  â”‚   2. åˆ†æå¤©æ°£                                                   â”‚ â”‚
â”‚  â”‚   3. åˆ†æ AI                                                    â”‚ â”‚
â”‚  â”‚   4. æª¢æ¸¬ç•°å¸¸                                                   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                             â”‚                                       â”‚
â”‚                             â–¼                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚              learning_records Table                            â”‚ â”‚
â”‚  â”‚   - prediction_error                                           â”‚ â”‚
â”‚  â”‚   - weather_conditions                                         â”‚ â”‚
â”‚  â”‚   - ai_factors                                                 â”‚ â”‚
â”‚  â”‚   - is_anomaly                                                 â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                             â”‚                                       â”‚
â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚          â–¼                  â–¼                  â–¼                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚  Weather      â”‚ â”‚  AI Event     â”‚ â”‚  Anomaly      â”‚            â”‚
â”‚  â”‚  Impact       â”‚ â”‚  Learning     â”‚ â”‚  Detection    â”‚            â”‚
â”‚  â”‚  Learner      â”‚ â”‚               â”‚ â”‚               â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚          â”‚                 â”‚                 â”‚                     â”‚
â”‚          â–¼                 â–¼                 â–¼                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚  weather_     â”‚ â”‚  ai_event_    â”‚ â”‚  anomaly_     â”‚            â”‚
â”‚  â”‚  impact_      â”‚ â”‚  learning     â”‚ â”‚  events       â”‚            â”‚
â”‚  â”‚  parameters   â”‚ â”‚               â”‚ â”‚               â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚          â”‚                 â”‚                 â”‚                     â”‚
â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                             â”‚                                       â”‚
â”‚                             â–¼                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                 é æ¸¬æ™‚ä½¿ç”¨                                      â”‚ â”‚
â”‚  â”‚   1. è®€å–å­¸ç¿’åˆ°çš„åƒæ•¸                                          â”‚ â”‚
â”‚  â”‚   2. ç²å–å¤©æ°£é å ±                                              â”‚ â”‚
â”‚  â”‚   3. èª¿æ•´åŸºç¤é æ¸¬                                              â”‚ â”‚
â”‚  â”‚   4. ç”Ÿæˆæœ€çµ‚é æ¸¬                                              â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## é æœŸæ•ˆæœ

### å­¸ç¿’å¾Œçš„é æ¸¬æµç¨‹

```
ä»Šå¤©æ˜¯ 2026-02-01

1. XGBoost åŸºç¤é æ¸¬: 250 äºº

2. æª¢æŸ¥å¤©æ°£é å ±:
   - æ˜å¤©æœ€ä½æº«: 8Â°C (å¯’å†·å¤©æ°£)
   - é™é›¨æ©Ÿç‡: High

3. æŸ¥è©¢å­¸ç¿’åˆ°çš„å½±éŸ¿:
   - å¯’å†·å¤©æ°£ (temp_min <= 12): å¹³å‡ -6.8 äºº
   - å¤§é›¨ (High): å¹³å‡ -4.9 äºº
   - ç¸½èª¿æ•´: -11.7 äºº

4. æœ€çµ‚é æ¸¬:
   - åŸºç¤: 250 äºº
   - èª¿æ•´: -11.7 äºº
   - æœ€çµ‚: 238 äºº

5. å¦‚æœæ˜å¤©å¯¦éš›æ˜¯ 240 äºº:
   - èª¤å·®: 2 äºº
   - ç„¡èª¿æ•´èª¤å·®: 10 äºº
   - å­¸ç¿’æ”¹å–„: 80% âœ…
```

---

## ç¸½çµ

é€™å€‹è‡ªå‹•å­¸ç¿’ç³»çµ±å°‡å¯¦ç¾ï¼š

| åŠŸèƒ½ | ç•¶å‰ç‹€æ…‹ | å¯¦ç¾å¾Œ |
|------|---------|--------|
| å¤©æ°£å½±éŸ¿è¿½è¹¤ | éœæ…‹ JSON | å‹•æ…‹æ•¸æ“šåº« |
| ç•°å¸¸æª¢æ¸¬ | âŒ ç„¡ | âœ… è‡ªå‹• |
| å¤©æ°£é å ±æ•´åˆ | å­˜åœ¨ä½†æœªä½¿ç”¨ | âœ… æ•´åˆåˆ°é æ¸¬ |
| AI å› ç´ é©—è­‰ | é›™è»Œé“ | âœ… è‡ªå‹•å­¸ç¿’ |
| æŒçºŒå­¸ç¿’ | âŒ ç„¡ | âœ… æ¯æ—¥è‡ªå‹• |

---

**ç‰ˆæœ¬**: 4.0.00
**ä½œè€…**: Ma Tsz Kiu
**æ—¥æœŸ**: 2026-01-18
